{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10403502,"sourceType":"datasetVersion","datasetId":6446585},{"sourceId":10766678,"sourceType":"datasetVersion","datasetId":6678889},{"sourceId":10799078,"sourceType":"datasetVersion","datasetId":6702359},{"sourceId":13228203,"sourceType":"datasetVersion","datasetId":8384882},{"sourceId":593517,"sourceType":"modelInstanceVersion","modelInstanceId":444160,"modelId":460651}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nlist_file = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        list_file.append(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T15:59:26.874920Z","iopub.execute_input":"2025-10-01T15:59:26.875185Z","iopub.status.idle":"2025-10-01T15:59:27.188747Z","shell.execute_reply.started":"2025-10-01T15:59:26.875166Z","shell.execute_reply":"2025-10-01T15:59:27.188123Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/training-data-cfm/X_test_m4HAPAP.csv\n/kaggle/input/training-data-cfm/y_train_or6m3Ta.csv\n/kaggle/input/training-data-cfm/X_train_N1UvY30.csv\n/kaggle/input/best_mod/pytorch/default/1/best_mod_cfm.pth\n/kaggle/input/small-dataset/small_X_test.csv\n/kaggle/input/small-dataset/small_X_train.csv\n/kaggle/input/small-dataset/small_y_train.csv\n/kaggle/input/execfiles/exec.py\n/kaggle/input/execfiles/train.py\n/kaggle/input/execfiles/model.py\n/kaggle/input/execfiles/load.py\n/kaggle/input/execfiles/report_end.py\n/kaggle/input/execfiles/__init__.py\n/kaggle/input/execfiles/loader.py\n/kaggle/input/optimization-cfm/small_X_test.csv\n/kaggle/input/optimization-cfm/small_X_train.csv\n/kaggle/input/optimization-cfm/small_y_train.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**Loader**","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/execfiles\")\n\nimport torch\nfrom model import AdvancedRNN, gru_lstm\nfrom train import train\nfrom loader import get_loaders\nfrom load import load_data\nfrom report_end import  make_predictions\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nimport os \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T15:59:27.190011Z","iopub.execute_input":"2025-10-01T15:59:27.190369Z","iopub.status.idle":"2025-10-01T15:59:27.865766Z","shell.execute_reply.started":"2025-10-01T15:59:27.190350Z","shell.execute_reply":"2025-10-01T15:59:27.865157Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"dict_feature_eng = dict(use_microstructure=True,\n                use_imbalance=True,\n                use_price_dynamics=True,\n                use_momentum=True,\n                momentum_windows=[5, 20],\n                use_flux=True,\n                use_directional=True,\n                use_time=True,\n                use_log=True,\n                corr_threshold=None)\n\ndict_load_data = dict(dummy = False, normalize=True, filter=True, print_shape= True, threshold = 10, dict_feature_eng = dict_feature_eng)\n\n\nloaded_data = load_data(**dict_load_data)\nX_train, y, X_test = loaded_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T19:04:07.204338Z","iopub.execute_input":"2025-10-01T19:04:07.204607Z","iopub.status.idle":"2025-10-01T19:04:37.381616Z","shell.execute_reply.started":"2025-10-01T19:04:07.204585Z","shell.execute_reply":"2025-10-01T19:04:37.380688Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3604020026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mloaded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict_load_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/942726306.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dummy, normalize, filter, threshold, dict_feature_eng, print_shape)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         return _unique_python(\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m\"\"\"Map values based on its position in uniques.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":127},{"cell_type":"markdown","source":"# Loader","metadata":{}},{"cell_type":"code","source":"dict_loaders = dict(batch_size=32, test_size=0.1, seed=42, shuffle = True)\n\ntrain_loader,val_loader,test_loader = get_loaders(loaded_data = loaded_data, **dict_loaders)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:11:34.843956Z","iopub.execute_input":"2025-10-01T17:11:34.844226Z","iopub.status.idle":"2025-10-01T17:11:36.369958Z","shell.execute_reply.started":"2025-10-01T17:11:34.844207Z","shell.execute_reply":"2025-10-01T17:11:36.369140Z"}},"outputs":[],"execution_count":98},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_params = dict(num_features= 16,\n                num_classes= 24,\n                embed_features= [0, 2, 3, 4],\n                num_embed_features= [6, 3, 2, 2],\n                encode_features= [1],\n                embedding_dim= 8,\n                hidden_dim= 256,  # renomm√© d_hidden -> hidden_dim\n                dropout= 0.15,\n                rnn_type= \"LSTM\",\n                attention= True,\n                use_transformer= True,\n                nhead= 4,\n                num_transformer_layers= 2,\n                device= device)\n\nmodel = AdvancedRNN(**model_params)\nif \"/kaggle/input/best_mod/pytorch/default/1/best_mod_cfm.pth\" in list_file:\n    state_dict = torch.load(\"/kaggle/input/best_mod/pytorch/default/1/best_mod_cfm.pth\", map_location='cuda')  # ou 'cpu'\n    model.load_state_dict(state_dict)\nmodel.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:00:23.952045Z","iopub.execute_input":"2025-10-01T16:00:23.952750Z","iopub.status.idle":"2025-10-01T16:00:24.316759Z","shell.execute_reply.started":"2025-10-01T16:00:23.952726Z","shell.execute_reply":"2025-10-01T16:00:24.316130Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"AdvancedRNN(\n  (embeddings): ModuleList(\n    (0): Embedding(6, 8)\n    (1): Embedding(3, 8)\n    (2-3): 2 x Embedding(2, 8)\n  )\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=44, out_features=44, bias=True)\n        )\n        (linear1): Linear(in_features=44, out_features=88, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n        (linear2): Linear(in_features=88, out_features=44, bias=True)\n        (norm1): LayerNorm((44,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((44,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.15, inplace=False)\n        (dropout2): Dropout(p=0.15, inplace=False)\n      )\n    )\n  )\n  (rnn): LSTM(44, 256, batch_first=True, bidirectional=True)\n  (attention_weights): Linear(in_features=512, out_features=1, bias=True)\n  (fc): Sequential(\n    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (1): Linear(in_features=512, out_features=256, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=0.15, inplace=False)\n    (4): Linear(in_features=256, out_features=128, bias=True)\n    (5): ReLU()\n    (6): Dropout(p=0.15, inplace=False)\n    (7): Linear(in_features=128, out_features=24, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"training_params =  dict(\n                    lr= 6e-5,\n                    weight_decay= 3e-4,\n                    gamma= 0.6,\n                    step_size= 5,\n                    num_epochs= 100,\n                    early_stop_n= 10,\n                    patience= 10,\n                    device= device, \n                    scheduler= {\n                        \"mode\": \"min\",\n                        \"factor\": 0.6,\n                        \"patience\": 3,\n                        \"verbose\": True\n                    })\n\n# === Optimiser === #\noptimizer = Adam(model.parameters(), lr=training_params[\"lr\"], weight_decay=training_params[\"weight_decay\"])\n\n# === Scheduler === #\nscheduler = ReduceLROnPlateau(optimizer, **training_params[\"scheduler\"])\n\n# === Training === #\ntrain(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    num_epochs=training_params[\"num_epochs\"],\n    device=training_params[\"device\"],\n    patience=training_params[\"patience\"],\n    n=training_params[\"early_stop_n\"]\n)\n# Save Model\nMODEL_OUT = '/kaggle/working/'\ntorch.save(model.state_dict(), os.path.join(MODEL_OUT,'best_mod_cfm_after_feng.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T15:59:43.982702Z","iopub.status.idle":"2025-10-01T15:59:43.982956Z","shell.execute_reply.started":"2025-10-01T15:59:43.982821Z","shell.execute_reply":"2025-10-01T15:59:43.982832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Make Predictions","metadata":{}},{"cell_type":"code","source":"Y = make_predictions(model,test_loader)\nprint(Y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:11:22.383787Z","iopub.execute_input":"2025-10-01T16:11:22.384101Z","iopub.status.idle":"2025-10-01T16:11:23.082605Z","shell.execute_reply.started":"2025-10-01T16:11:22.384081Z","shell.execute_reply":"2025-10-01T16:11:23.081965Z"}},"outputs":[{"name":"stdout","text":"     eqt_code_cat\n0               7\n1               3\n2              19\n3              19\n4              22\n..            ...\n811            22\n812            15\n813            10\n814            17\n815             7\n\n[816 rows x 1 columns]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\n\n\n# === Hyperparam√®tres === #\nnum_features = 16\nnum_classes = 24\nembed_features = [0, 2, 3, 4]\nnum_embed_features = [6, 3, 2, 2]\nencode_features = [1]\n\nembedding_dim = 8\nd_hidden = 256\nnum_layers = 1\ndropout = 0.15\nrnn_type = 'LSTM'\nattention = True\nuse_transformer = True\nnhead = 4\nnum_transformer_layers = 2\n\n\n# === D√©tection du device === #\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# === Initialisation du mod√®le === #\nmodel = AdvancedRNN(\n    num_features=num_features,\n    num_classes=num_classes,              # renomm√©\n    embed_features=embed_features,\n    num_embed_features=num_embed_features,\n    encode_features=encode_features,\n    embedding_dim=embedding_dim,\n    hidden_dim=d_hidden,                  # renomm√©\n    dropout=dropout,\n    rnn_type=rnn_type,\n    attention=attention,\n    use_transformer=use_transformer,\n    nhead=nhead,\n    num_transformer_layers=num_transformer_layers,\n    device=device\n)\nif \"/kaggle/input/best_mod/pytorch/default/1/best_mod_cfm.pth\" in list_file:\n    state_dict = torch.load(\"/kaggle/input/best_mod/pytorch/default/1/best_mod_cfm.pth\", map_location='cuda')  # ou 'cpu'\n    model.load_state_dict(state_dict)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:16:41.161031Z","iopub.execute_input":"2025-10-01T17:16:41.161308Z","iopub.status.idle":"2025-10-01T17:16:41.197169Z","shell.execute_reply.started":"2025-10-01T17:16:41.161289Z","shell.execute_reply":"2025-10-01T17:16:41.196569Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\n# Optimisation\n\nlr = 1e-4\nweight_decay = 3e-4\ngamma = 0.6\nstep_size = 5\nnum_epochs = 10\nearly_stop_n = 10  # patience pour l'early stopping\npatience = 10\n\n\n# === Optimiseur et scheduler === #\noptimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n# scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\nscheduler = ReduceLROnPlateau(optimizer,mode='min',factor= gamma,patience=3)\n\n# === Entra√Ænement === #\ntrain(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    num_epochs=num_epochs,\n    device=device,\n    patience = patience, \n    n=early_stop_n  # nombre d'epochs sans am√©lioration avant arr√™t\n)\nMODEL_OUT = '/kaggle/working/'\ntorch.save(model.state_dict(), os.path.join(MODEL_OUT,'best_mod_cfm.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:44:07.560408Z","iopub.execute_input":"2025-10-01T17:44:07.560701Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üîπ Training on device: cuda\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                       \r","output_type":"stream"},{"name":"stdout","text":"üìå Epoch 2: Train Loss: 0.4476, Train Acc: 0.8415\n‚úÖ Validation: Loss: 0.3816, Accuracy: 0.8694\n‚ö†Ô∏è Early stopping patience: 1/10\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 3612/4427 [01:07<00:15, 53.45it/s, Train Loss=1595.5532, Train Acc=0.6886]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print (model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T15:59:43.989029Z","iopub.status.idle":"2025-10-01T15:59:43.989271Z","shell.execute_reply.started":"2025-10-01T15:59:43.989160Z","shell.execute_reply":"2025-10-01T15:59:43.989173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_predictions(model, X_test, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n    all_predictions = []  \n    all_probabilities = [] \n\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        for batch in X_test:\n            # V√©rifie le type du batch\n            if isinstance(batch, (list, tuple)):\n                batch_inputs = batch[0]  # Prend le premier √©l√©ment\n            else:\n                batch_inputs = batch\n\n            batch_inputs = batch_inputs.to(device, dtype=torch.float32)  # OK maintenant\n\n            outputs = model(batch_inputs)\n            probabilities = torch.softmax(outputs, dim=1)\n            predicted_classes = torch.argmax(probabilities, dim=1)\n\n            all_predictions.append(predicted_classes.cpu().numpy())\n            all_probabilities.append(probabilities.cpu().numpy())\n\n    all_predictions = np.concatenate(all_predictions)\n    all_probabilities = np.concatenate(all_probabilities)\n\n    df_prediction = pd.DataFrame({\"eqt_code_cat\": all_predictions})\n    df_prob = pd.DataFrame(all_probabilities, columns=[f\"class_{i}_prob\" for i in range(all_probabilities.shape[1])])\n    df_prob[\"predicted_class\"] = all_predictions\n    df_prob[\"max_prob\"] = df_prob[[f\"class_{i}_prob\" for i in range(all_probabilities.shape[1])]].max(axis=1)\n\n    sorted_probs = np.sort(all_probabilities, axis=1)[:, ::-1]\n    df_prob[\"second_max_prob\"] = sorted_probs[:, 1]\n    df_prob[\"max_minus_second\"] = df_prob[\"max_prob\"] - df_prob[\"second_max_prob\"]\n    df_prob[\"entropy\"] = entropy(all_probabilities, axis=1)\n\n    df_prediction.to_csv(\"/kaggle/working/y_predict.csv\", index=False)\n    df_prob.to_csv(\"/kaggle/working/proba_details.csv\", index=False)\n\n    return df_prediction, df_prob\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:21:09.537277Z","iopub.execute_input":"2025-10-01T17:21:09.537792Z","iopub.status.idle":"2025-10-01T17:21:09.546233Z","shell.execute_reply.started":"2025-10-01T17:21:09.537755Z","shell.execute_reply":"2025-10-01T17:21:09.545568Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\n\ndef prepare_pseudo_labels(df_prob, X_unlabeled, model, threshold=0.9):\n    \"\"\"\n    G√©n√®re un dataset pseudo-√©tiquet√© √† partir des pr√©dictions d'un mod√®le.\n    \n    df_prob : DataFrame avec colonnes de probas par classe et indicateurs\n    X_unlabeled : donn√©es d'entr√©e non √©tiquet√©es (Tensor ou DataFrame)\n    model : mod√®le entra√Æn√©\n    threshold : seuil de confiance pour accepter un pseudo-label\n    \n    Retour :\n    df_pseudo : DataFrame pr√™t pour l'ajout √† l'entra√Ænement\n    \"\"\"\n    \n    # Filtrer sur la confiance\n    confident_mask = df_prob['max_prob'] >= threshold\n    confident_indices = df_prob[confident_mask].index\n\n    print(f\"Nombre d'√©chantillons ajout√©s : {len(confident_indices)} sur {len(df_prob)}\")\n\n    # Extraire les pseudo-labels et indicateurs\n    pseudo_labels = df_prob.loc[confident_indices, 'predicted_class'].values\n    confidences = df_prob.loc[confident_indices, 'max_prob'].values\n    entropies = df_prob.loc[confident_indices, 'entropy'].values\n    second_probs = df_prob.loc[confident_indices, 'second_max_prob'].values\n    margins = df_prob.loc[confident_indices, 'max_minus_second'].values\n\n    # Construire DataFrame pseudo-label\n    df_pseudo = pd.DataFrame({\n        'pseudo_label': pseudo_labels,\n        'max_prob': confidences,\n        'entropy': entropies,\n        'second_max_prob': second_probs,\n        'max_minus_second': margins\n    })\n\n    # Ajouter les features correspondantes\n    X_pseudo_labeled = X_unlabeled[confident_indices]\n    return X_pseudo_labeled, df_pseudo\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:51:08.651920Z","iopub.execute_input":"2025-10-01T16:51:08.652639Z","iopub.status.idle":"2025-10-01T16:51:08.658146Z","shell.execute_reply.started":"2025-10-01T16:51:08.652607Z","shell.execute_reply":"2025-10-01T16:51:08.657486Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"X_pseudo_labeled, df_pseudo = prepare_pseudo_labels(df_prob, X_test, model, threshold=0.9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:11:14.850445Z","iopub.execute_input":"2025-10-01T17:11:14.850997Z","iopub.status.idle":"2025-10-01T17:11:14.858491Z","shell.execute_reply.started":"2025-10-01T17:11:14.850971Z","shell.execute_reply":"2025-10-01T17:11:14.857891Z"}},"outputs":[{"name":"stdout","text":"Nombre d'√©chantillons ajout√©s : 256 sur 816\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"df_prediction, df_prob = make_predictions(model,test_loader)\ndf_prob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:21:14.205769Z","iopub.execute_input":"2025-10-01T17:21:14.206067Z","iopub.status.idle":"2025-10-01T17:21:33.288484Z","shell.execute_reply.started":"2025-10-01T17:21:14.206047Z","shell.execute_reply":"2025-10-01T17:21:33.287710Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"       class_0_prob  class_1_prob  class_2_prob  class_3_prob  class_4_prob  \\\n0      2.070337e-04  7.738247e-04  4.830919e-04  2.585734e-05  1.308414e-04   \n1      4.412778e-08  2.255851e-05  2.160316e-07  9.951594e-01  2.492029e-06   \n2      1.054914e-06  1.066540e-02  9.119313e-05  5.757163e-09  1.592373e-07   \n3      1.594730e-08  7.332956e-03  1.648885e-10  1.001064e-12  4.009720e-10   \n4      5.968463e-05  1.883935e-09  4.276681e-09  6.677072e-07  1.206044e-02   \n...             ...           ...           ...           ...           ...   \n81595  7.779440e-01  1.891168e-07  7.907412e-07  6.687896e-05  1.519985e-02   \n81596  7.573255e-01  3.507045e-07  3.264645e-07  5.245494e-07  1.669574e-05   \n81597  1.107603e-05  8.617907e-01  2.817413e-05  9.838719e-07  1.893947e-06   \n81598  1.672865e-06  2.373340e-08  3.677909e-07  2.178252e-05  1.331505e-03   \n81599  8.331047e-06  1.916150e-03  3.553368e-02  2.805793e-01  1.625701e-04   \n\n       class_5_prob  class_6_prob  class_7_prob  class_8_prob  class_9_prob  \\\n0      4.807984e-04  2.322775e-04  4.292259e-01  4.899747e-04  6.212350e-04   \n1      2.653640e-03  8.523249e-07  2.406180e-07  4.678523e-05  3.255874e-06   \n2      8.509778e-07  5.466239e-02  5.843077e-04  1.036412e-05  2.621825e-07   \n3      4.842547e-12  9.804125e-01  2.295031e-08  1.823334e-08  6.589534e-10   \n4      3.110668e-08  5.311274e-08  5.571531e-08  4.567823e-08  1.168293e-06   \n...             ...           ...           ...           ...           ...   \n81595  9.265303e-07  8.264483e-07  2.290279e-05  3.726136e-05  6.986754e-02   \n81596  5.588258e-09  2.074131e-06  2.268885e-06  5.215336e-07  1.874029e-02   \n81597  1.248610e-06  1.018275e-01  2.552255e-04  2.886380e-04  9.956712e-06   \n81598  2.445391e-04  5.039130e-09  9.885269e-10  4.288259e-06  1.015929e-07   \n81599  1.869460e-02  2.789036e-05  6.889849e-04  6.541463e-01  1.059582e-05   \n\n       ...  class_19_prob  class_20_prob  class_21_prob  class_22_prob  \\\n0      ...   1.694874e-05   6.464120e-06   4.876687e-05   5.520727e-07   \n1      ...   4.285978e-08   6.418047e-05   1.590437e-04   1.356402e-05   \n2      ...   9.036809e-01   2.233715e-08   1.364520e-07   2.711414e-07   \n3      ...   1.115199e-03   1.495563e-12   3.057469e-11   9.666078e-11   \n4      ...   3.251912e-07   1.191801e-05   3.533346e-04   9.804578e-01   \n...    ...            ...            ...            ...            ...   \n81595  ...   2.189299e-06   8.851662e-04   9.598112e-02   7.773886e-03   \n81596  ...   2.742100e-07   2.675837e-04   1.786072e-01   2.553474e-02   \n81597  ...   3.449767e-04   3.791425e-07   6.074677e-07   4.927076e-07   \n81598  ...   2.387266e-07   6.460229e-02   8.122064e-02   5.500914e-05   \n81599  ...   7.125800e-06   6.414358e-05   6.364399e-05   7.876807e-06   \n\n       class_23_prob  predicted_class  max_prob  second_max_prob  \\\n0       7.643536e-02                7  0.429226         0.223948   \n1       4.758763e-08                3  0.995159         0.002654   \n2       1.563360e-02               19  0.903681         0.054662   \n3       1.500369e-08                6  0.980412         0.011077   \n4       1.835905e-08               22  0.980458         0.012060   \n...              ...              ...       ...              ...   \n81595   2.028980e-07                0  0.777944         0.095981   \n81596   5.412899e-08                0  0.757325         0.178607   \n81597   1.635285e-04                1  0.861791         0.101828   \n81598   1.467882e-07               10  0.850694         0.081221   \n81599   8.566665e-04                8  0.654146         0.280579   \n\n       max_minus_second   entropy  \n0              0.205277  1.456735  \n1              0.992506  0.036676  \n2              0.849018  0.443194  \n3              0.969336  0.113541  \n4              0.968397  0.116063  \n...                 ...       ...  \n81595          0.681963  0.848491  \n81596          0.578718  0.766592  \n81597          0.759963  0.527349  \n81598          0.769474  0.543030  \n81599          0.373567  0.897366  \n\n[81600 rows x 29 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_0_prob</th>\n      <th>class_1_prob</th>\n      <th>class_2_prob</th>\n      <th>class_3_prob</th>\n      <th>class_4_prob</th>\n      <th>class_5_prob</th>\n      <th>class_6_prob</th>\n      <th>class_7_prob</th>\n      <th>class_8_prob</th>\n      <th>class_9_prob</th>\n      <th>...</th>\n      <th>class_19_prob</th>\n      <th>class_20_prob</th>\n      <th>class_21_prob</th>\n      <th>class_22_prob</th>\n      <th>class_23_prob</th>\n      <th>predicted_class</th>\n      <th>max_prob</th>\n      <th>second_max_prob</th>\n      <th>max_minus_second</th>\n      <th>entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.070337e-04</td>\n      <td>7.738247e-04</td>\n      <td>4.830919e-04</td>\n      <td>2.585734e-05</td>\n      <td>1.308414e-04</td>\n      <td>4.807984e-04</td>\n      <td>2.322775e-04</td>\n      <td>4.292259e-01</td>\n      <td>4.899747e-04</td>\n      <td>6.212350e-04</td>\n      <td>...</td>\n      <td>1.694874e-05</td>\n      <td>6.464120e-06</td>\n      <td>4.876687e-05</td>\n      <td>5.520727e-07</td>\n      <td>7.643536e-02</td>\n      <td>7</td>\n      <td>0.429226</td>\n      <td>0.223948</td>\n      <td>0.205277</td>\n      <td>1.456735</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.412778e-08</td>\n      <td>2.255851e-05</td>\n      <td>2.160316e-07</td>\n      <td>9.951594e-01</td>\n      <td>2.492029e-06</td>\n      <td>2.653640e-03</td>\n      <td>8.523249e-07</td>\n      <td>2.406180e-07</td>\n      <td>4.678523e-05</td>\n      <td>3.255874e-06</td>\n      <td>...</td>\n      <td>4.285978e-08</td>\n      <td>6.418047e-05</td>\n      <td>1.590437e-04</td>\n      <td>1.356402e-05</td>\n      <td>4.758763e-08</td>\n      <td>3</td>\n      <td>0.995159</td>\n      <td>0.002654</td>\n      <td>0.992506</td>\n      <td>0.036676</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.054914e-06</td>\n      <td>1.066540e-02</td>\n      <td>9.119313e-05</td>\n      <td>5.757163e-09</td>\n      <td>1.592373e-07</td>\n      <td>8.509778e-07</td>\n      <td>5.466239e-02</td>\n      <td>5.843077e-04</td>\n      <td>1.036412e-05</td>\n      <td>2.621825e-07</td>\n      <td>...</td>\n      <td>9.036809e-01</td>\n      <td>2.233715e-08</td>\n      <td>1.364520e-07</td>\n      <td>2.711414e-07</td>\n      <td>1.563360e-02</td>\n      <td>19</td>\n      <td>0.903681</td>\n      <td>0.054662</td>\n      <td>0.849018</td>\n      <td>0.443194</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.594730e-08</td>\n      <td>7.332956e-03</td>\n      <td>1.648885e-10</td>\n      <td>1.001064e-12</td>\n      <td>4.009720e-10</td>\n      <td>4.842547e-12</td>\n      <td>9.804125e-01</td>\n      <td>2.295031e-08</td>\n      <td>1.823334e-08</td>\n      <td>6.589534e-10</td>\n      <td>...</td>\n      <td>1.115199e-03</td>\n      <td>1.495563e-12</td>\n      <td>3.057469e-11</td>\n      <td>9.666078e-11</td>\n      <td>1.500369e-08</td>\n      <td>6</td>\n      <td>0.980412</td>\n      <td>0.011077</td>\n      <td>0.969336</td>\n      <td>0.113541</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.968463e-05</td>\n      <td>1.883935e-09</td>\n      <td>4.276681e-09</td>\n      <td>6.677072e-07</td>\n      <td>1.206044e-02</td>\n      <td>3.110668e-08</td>\n      <td>5.311274e-08</td>\n      <td>5.571531e-08</td>\n      <td>4.567823e-08</td>\n      <td>1.168293e-06</td>\n      <td>...</td>\n      <td>3.251912e-07</td>\n      <td>1.191801e-05</td>\n      <td>3.533346e-04</td>\n      <td>9.804578e-01</td>\n      <td>1.835905e-08</td>\n      <td>22</td>\n      <td>0.980458</td>\n      <td>0.012060</td>\n      <td>0.968397</td>\n      <td>0.116063</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>81595</th>\n      <td>7.779440e-01</td>\n      <td>1.891168e-07</td>\n      <td>7.907412e-07</td>\n      <td>6.687896e-05</td>\n      <td>1.519985e-02</td>\n      <td>9.265303e-07</td>\n      <td>8.264483e-07</td>\n      <td>2.290279e-05</td>\n      <td>3.726136e-05</td>\n      <td>6.986754e-02</td>\n      <td>...</td>\n      <td>2.189299e-06</td>\n      <td>8.851662e-04</td>\n      <td>9.598112e-02</td>\n      <td>7.773886e-03</td>\n      <td>2.028980e-07</td>\n      <td>0</td>\n      <td>0.777944</td>\n      <td>0.095981</td>\n      <td>0.681963</td>\n      <td>0.848491</td>\n    </tr>\n    <tr>\n      <th>81596</th>\n      <td>7.573255e-01</td>\n      <td>3.507045e-07</td>\n      <td>3.264645e-07</td>\n      <td>5.245494e-07</td>\n      <td>1.669574e-05</td>\n      <td>5.588258e-09</td>\n      <td>2.074131e-06</td>\n      <td>2.268885e-06</td>\n      <td>5.215336e-07</td>\n      <td>1.874029e-02</td>\n      <td>...</td>\n      <td>2.742100e-07</td>\n      <td>2.675837e-04</td>\n      <td>1.786072e-01</td>\n      <td>2.553474e-02</td>\n      <td>5.412899e-08</td>\n      <td>0</td>\n      <td>0.757325</td>\n      <td>0.178607</td>\n      <td>0.578718</td>\n      <td>0.766592</td>\n    </tr>\n    <tr>\n      <th>81597</th>\n      <td>1.107603e-05</td>\n      <td>8.617907e-01</td>\n      <td>2.817413e-05</td>\n      <td>9.838719e-07</td>\n      <td>1.893947e-06</td>\n      <td>1.248610e-06</td>\n      <td>1.018275e-01</td>\n      <td>2.552255e-04</td>\n      <td>2.886380e-04</td>\n      <td>9.956712e-06</td>\n      <td>...</td>\n      <td>3.449767e-04</td>\n      <td>3.791425e-07</td>\n      <td>6.074677e-07</td>\n      <td>4.927076e-07</td>\n      <td>1.635285e-04</td>\n      <td>1</td>\n      <td>0.861791</td>\n      <td>0.101828</td>\n      <td>0.759963</td>\n      <td>0.527349</td>\n    </tr>\n    <tr>\n      <th>81598</th>\n      <td>1.672865e-06</td>\n      <td>2.373340e-08</td>\n      <td>3.677909e-07</td>\n      <td>2.178252e-05</td>\n      <td>1.331505e-03</td>\n      <td>2.445391e-04</td>\n      <td>5.039130e-09</td>\n      <td>9.885269e-10</td>\n      <td>4.288259e-06</td>\n      <td>1.015929e-07</td>\n      <td>...</td>\n      <td>2.387266e-07</td>\n      <td>6.460229e-02</td>\n      <td>8.122064e-02</td>\n      <td>5.500914e-05</td>\n      <td>1.467882e-07</td>\n      <td>10</td>\n      <td>0.850694</td>\n      <td>0.081221</td>\n      <td>0.769474</td>\n      <td>0.543030</td>\n    </tr>\n    <tr>\n      <th>81599</th>\n      <td>8.331047e-06</td>\n      <td>1.916150e-03</td>\n      <td>3.553368e-02</td>\n      <td>2.805793e-01</td>\n      <td>1.625701e-04</td>\n      <td>1.869460e-02</td>\n      <td>2.789036e-05</td>\n      <td>6.889849e-04</td>\n      <td>6.541463e-01</td>\n      <td>1.059582e-05</td>\n      <td>...</td>\n      <td>7.125800e-06</td>\n      <td>6.414358e-05</td>\n      <td>6.364399e-05</td>\n      <td>7.876807e-06</td>\n      <td>8.566665e-04</td>\n      <td>8</td>\n      <td>0.654146</td>\n      <td>0.280579</td>\n      <td>0.373567</td>\n      <td>0.897366</td>\n    </tr>\n  </tbody>\n</table>\n<p>81600 rows √ó 29 columns</p>\n</div>"},"metadata":{}}],"execution_count":122},{"cell_type":"code","source":"df_prediction.to_csv(\"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:22:06.845216Z","iopub.execute_input":"2025-10-01T17:22:06.845503Z","iopub.status.idle":"2025-10-01T17:22:06.898684Z","shell.execute_reply.started":"2025-10-01T17:22:06.845484Z","shell.execute_reply":"2025-10-01T17:22:06.898096Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"df_prediction[df_prob['max_prob'] < x_high_1] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:14:44.344028Z","iopub.execute_input":"2025-10-01T17:14:44.344597Z","iopub.status.idle":"2025-10-01T17:14:44.349133Z","shell.execute_reply.started":"2025-10-01T17:14:44.344571Z","shell.execute_reply":"2025-10-01T17:14:44.348532Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"x_high_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:15:37.215313Z","iopub.execute_input":"2025-10-01T17:15:37.215566Z","iopub.status.idle":"2025-10-01T17:15:37.220347Z","shell.execute_reply.started":"2025-10-01T17:15:37.215548Z","shell.execute_reply":"2025-10-01T17:15:37.219664Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"0.6"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"df_prediction.to_csv(\"test_rapid60.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T17:14:46.149337Z","iopub.execute_input":"2025-10-01T17:14:46.150058Z","iopub.status.idle":"2025-10-01T17:14:46.202661Z","shell.execute_reply.started":"2025-10-01T17:14:46.150036Z","shell.execute_reply":"2025-10-01T17:14:46.201903Z"}},"outputs":[],"execution_count":108}]}