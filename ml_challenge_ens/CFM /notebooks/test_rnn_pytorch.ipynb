{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import polars as pl\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  Bidirectional, GRU, Dense, Dropout,LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGRUModel(nn.Module):\n",
    "    def __init__(self, num_unique_venues, num_unique_actions, embedding_dim, gru_units, num_classes):\n",
    "        super(MyGRUModel, self).__init__()\n",
    "\n",
    "        # Embeddings for categorical variables\n",
    "        self.venue_embedding = nn.Embedding(num_unique_venues, embedding_dim)\n",
    "        self.action_embedding = nn.Embedding(num_unique_actions, embedding_dim)\n",
    "        self.trade_embedding = nn.Embedding(2, embedding_dim)\n",
    "\n",
    "        # GRU with multiple layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim * 3 + 18,\n",
    "            hidden_size=gru_units,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        # Multi-Head Attention\n",
    "        self.attention_heads = 4\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=gru_units * 2,  # GRU output is bidirectional\n",
    "            num_heads=self.attention_heads,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Dense layers for classification\n",
    "        self.fc1 = nn.Linear(gru_units * 2 + 8, 128)  # Added room for global stats\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "        # Batch normalization and dropout\n",
    "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract embeddings for venue, action, and trade\n",
    "        venue_emb = self.venue_embedding(x[:, :, 0].long())\n",
    "        action_emb = self.action_embedding(x[:, :, 1].long())\n",
    "        trade_emb = self.trade_embedding(x[:, :, 2].long())\n",
    "\n",
    "        # Extract continuous features (price, volumes, etc.)\n",
    "        continuous_features = x[:, :, 3:]  # Ensure dimensions match\n",
    "        features = torch.cat((venue_emb, action_emb, trade_emb, continuous_features), dim=-1)\n",
    "\n",
    "        # Pass data through GRU\n",
    "        gru_out, _ = self.gru(features)\n",
    "\n",
    "        # Multi-Head Attention\n",
    "        attn_output, _ = self.attention(gru_out, gru_out, gru_out)\n",
    "\n",
    "        # Global statistics\n",
    "        mean_stats = torch.mean(gru_out, dim=1)\n",
    "        std_stats = torch.std(gru_out, dim=1)\n",
    "        global_stats = torch.cat((mean_stats, std_stats), dim=-1)\n",
    "\n",
    "        # Combine attention output and global stats\n",
    "        combined_features = torch.cat((attn_output.mean(dim=1), global_stats), dim=-1)\n",
    "\n",
    "        # Pass the combined features through dense layers\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        output = self.fc3(x)  # Final output layer for classification\n",
    "        return output\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "embedding_dim = 8\n",
    "gru_units = 64\n",
    "num_classes = 24\n",
    "\n",
    "# Initialize the model\n",
    "model = MyGRUModel(\n",
    "    num_unique_venues=6,\n",
    "    num_unique_actions=3,\n",
    "    embedding_dim=embedding_dim,\n",
    "    gru_units=gru_units,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "# Move the model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prepare the data\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "targets = torch.tensor(Y, dtype=torch.long).to(device)  # Use long for labels in classification\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print the model configuration\n",
    "print(\"Modified GRU-based model configuration is OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = X_train.shape[0]\n",
    "epochs = (10_000 * 1000) // num_observations\n",
    "for epoch in range(epochs):  # Example with 10,000 epochs\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(batch_inputs)  # Pass the data through the model\n",
    "        loss = criterion(outputs, batch_targets.argmax(dim=1))  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the weights\n",
    "    print(f'Epoch [{epoch+1}/{str(epochs)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des différents fichiers dans l'environnement \n",
    "X_test = pd.read_csv(\"X_test_m4HAPAP.csv\")\n",
    "X_train = pd.read_csv(\"X_train_N1UvY30.csv\")\n",
    "y_train = pd.read_csv(\"y_train_or6m3Ta.csv\")\n",
    "num_classes = 24\n",
    "Y= to_categorical(y_train['eqt_code_cat'], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables catégorielles à encoder\n",
    "categorical_columns = ['venue', 'action', 'side']\n",
    "\n",
    "# Variables numériques\n",
    "numeric_columns = ['price', 'bid', 'ask', 'bid_size', 'ask_size', 'flux']\n",
    "\n",
    "# Encoding\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.merge(y_train, on = 'obs_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_col='eqt_code_cat'\n",
    "cols=['price', 'bid', 'ask', 'bid_size', 'ask_size', 'flux']\n",
    "threshold=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>order_id</th>\n",
       "      <th>action</th>\n",
       "      <th>side</th>\n",
       "      <th>price</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>trade</th>\n",
       "      <th>flux</th>\n",
       "      <th>eqt_code_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079995</th>\n",
       "      <td>160799</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>735</td>\n",
       "      <td>261</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079996</th>\n",
       "      <td>160799</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>735</td>\n",
       "      <td>361</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079997</th>\n",
       "      <td>160799</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>735</td>\n",
       "      <td>361</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079998</th>\n",
       "      <td>160799</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>735</td>\n",
       "      <td>361</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079999</th>\n",
       "      <td>160799</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>635</td>\n",
       "      <td>361</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16080000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          obs_id  venue  order_id  action  side  price   bid   ask  bid_size  \\\n",
       "0              0      4         0       0     0   0.30  0.00  0.01       100   \n",
       "1              0      4         1       0     1  -0.17  0.00  0.01       100   \n",
       "2              0      4         2       1     0   0.28  0.00  0.01       100   \n",
       "3              0      4         3       0     0   0.30  0.00  0.01       100   \n",
       "4              0      4         4       1     0   0.37  0.00  0.01       100   \n",
       "...          ...    ...       ...     ...   ...    ...   ...   ...       ...   \n",
       "16079995  160799      4        61       1     0   1.32  0.01  0.06       735   \n",
       "16079996  160799      0        70       0     0   0.06  0.01  0.06       735   \n",
       "16079997  160799      4        71       0     0   1.26  0.01  0.06       735   \n",
       "16079998  160799      4        72       0     0   1.26  0.01  0.06       735   \n",
       "16079999  160799      4        73       0     1   0.00  0.01  0.06       635   \n",
       "\n",
       "          ask_size  trade  flux  eqt_code_cat  \n",
       "0                1  False   100            10  \n",
       "1                1  False   100            10  \n",
       "2                1  False  -100            10  \n",
       "3                1  False   100            10  \n",
       "4                1  False  -100            10  \n",
       "...            ...    ...   ...           ...  \n",
       "16079995       261  False  -100             5  \n",
       "16079996       361  False   100             5  \n",
       "16079997       361  False   100             5  \n",
       "16079998       361  False   100             5  \n",
       "16079999       361  False     1             5  \n",
       "\n",
       "[16080000 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = X_train\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.groupby(group_col)[cols].agg(['mean', 'std'])\n",
    "stats.columns = ['_'.join(col).strip() for col in stats.columns] \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_std</th>\n",
       "      <th>bid_mean</th>\n",
       "      <th>bid_std</th>\n",
       "      <th>ask_mean</th>\n",
       "      <th>ask_std</th>\n",
       "      <th>bid_size_mean</th>\n",
       "      <th>bid_size_std</th>\n",
       "      <th>ask_size_mean</th>\n",
       "      <th>ask_size_std</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eqt_code_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.326864</td>\n",
       "      <td>244.311979</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.106592</td>\n",
       "      <td>1119.964755</td>\n",
       "      <td>1211.561051</td>\n",
       "      <td>1147.836754</td>\n",
       "      <td>1204.579320</td>\n",
       "      <td>0.068706</td>\n",
       "      <td>176.911762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294431</td>\n",
       "      <td>244.142359</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.033359</td>\n",
       "      <td>0.071947</td>\n",
       "      <td>0.861021</td>\n",
       "      <td>216.918185</td>\n",
       "      <td>212.234866</td>\n",
       "      <td>201.423791</td>\n",
       "      <td>314.203573</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>99.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.982058</td>\n",
       "      <td>11.604307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>1.022583</td>\n",
       "      <td>10.290731</td>\n",
       "      <td>186.419969</td>\n",
       "      <td>187.646382</td>\n",
       "      <td>189.073709</td>\n",
       "      <td>210.479808</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>97.038877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125475</td>\n",
       "      <td>3.482658</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.143525</td>\n",
       "      <td>3.245651</td>\n",
       "      <td>308.127230</td>\n",
       "      <td>506.450328</td>\n",
       "      <td>305.982279</td>\n",
       "      <td>446.357861</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>107.867757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.853382</td>\n",
       "      <td>8.199992</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.883976</td>\n",
       "      <td>8.025556</td>\n",
       "      <td>662.953563</td>\n",
       "      <td>799.700871</td>\n",
       "      <td>662.598113</td>\n",
       "      <td>869.794211</td>\n",
       "      <td>-0.117772</td>\n",
       "      <td>163.018573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.189307</td>\n",
       "      <td>345.440584</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.606434</td>\n",
       "      <td>7.807343</td>\n",
       "      <td>236.740885</td>\n",
       "      <td>230.588653</td>\n",
       "      <td>237.603064</td>\n",
       "      <td>228.282298</td>\n",
       "      <td>0.083909</td>\n",
       "      <td>105.894553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.966658</td>\n",
       "      <td>33.013562</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>3.977365</td>\n",
       "      <td>30.846413</td>\n",
       "      <td>175.042066</td>\n",
       "      <td>190.151062</td>\n",
       "      <td>188.398333</td>\n",
       "      <td>259.891263</td>\n",
       "      <td>-0.013784</td>\n",
       "      <td>115.483682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.999544</td>\n",
       "      <td>345.605859</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.033275</td>\n",
       "      <td>1.090260</td>\n",
       "      <td>15.229392</td>\n",
       "      <td>172.683225</td>\n",
       "      <td>187.889848</td>\n",
       "      <td>174.378119</td>\n",
       "      <td>188.870987</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>101.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.357141</td>\n",
       "      <td>244.475910</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.032336</td>\n",
       "      <td>1.011080</td>\n",
       "      <td>10.080935</td>\n",
       "      <td>244.277054</td>\n",
       "      <td>369.764408</td>\n",
       "      <td>232.671263</td>\n",
       "      <td>288.548581</td>\n",
       "      <td>0.050042</td>\n",
       "      <td>206.055396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.404159</td>\n",
       "      <td>244.326799</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.090635</td>\n",
       "      <td>1.528992</td>\n",
       "      <td>868.008145</td>\n",
       "      <td>1373.397123</td>\n",
       "      <td>849.786031</td>\n",
       "      <td>1423.427002</td>\n",
       "      <td>0.209633</td>\n",
       "      <td>176.114298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.332778</td>\n",
       "      <td>244.243380</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>1.382313</td>\n",
       "      <td>410.276401</td>\n",
       "      <td>523.071085</td>\n",
       "      <td>428.250384</td>\n",
       "      <td>573.743543</td>\n",
       "      <td>0.286036</td>\n",
       "      <td>143.924767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.683449</td>\n",
       "      <td>9.785410</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>0.724180</td>\n",
       "      <td>9.477508</td>\n",
       "      <td>281.187058</td>\n",
       "      <td>558.365077</td>\n",
       "      <td>266.068804</td>\n",
       "      <td>257.893943</td>\n",
       "      <td>0.044387</td>\n",
       "      <td>118.718634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.228660</td>\n",
       "      <td>488.404070</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>-0.169555</td>\n",
       "      <td>4.199544</td>\n",
       "      <td>256.040387</td>\n",
       "      <td>327.411327</td>\n",
       "      <td>261.294633</td>\n",
       "      <td>267.790361</td>\n",
       "      <td>-0.044721</td>\n",
       "      <td>142.300952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.386597</td>\n",
       "      <td>23.042622</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.129817</td>\n",
       "      <td>3.418622</td>\n",
       "      <td>22.907708</td>\n",
       "      <td>166.850510</td>\n",
       "      <td>214.854556</td>\n",
       "      <td>157.079015</td>\n",
       "      <td>174.223530</td>\n",
       "      <td>-0.016770</td>\n",
       "      <td>107.969165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.007084</td>\n",
       "      <td>5.701263</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.027508</td>\n",
       "      <td>-0.369246</td>\n",
       "      <td>10.034551</td>\n",
       "      <td>230.177081</td>\n",
       "      <td>399.628924</td>\n",
       "      <td>221.356406</td>\n",
       "      <td>266.003776</td>\n",
       "      <td>-0.124300</td>\n",
       "      <td>111.915126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.386021</td>\n",
       "      <td>16.732446</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.026708</td>\n",
       "      <td>1.436356</td>\n",
       "      <td>16.561654</td>\n",
       "      <td>261.332903</td>\n",
       "      <td>257.733894</td>\n",
       "      <td>248.033697</td>\n",
       "      <td>256.509570</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>228.259072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.127587</td>\n",
       "      <td>2.777547</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.129464</td>\n",
       "      <td>2.634154</td>\n",
       "      <td>1170.997325</td>\n",
       "      <td>1397.119718</td>\n",
       "      <td>1185.719821</td>\n",
       "      <td>1483.621631</td>\n",
       "      <td>-0.212397</td>\n",
       "      <td>226.220626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.309197</td>\n",
       "      <td>4.656790</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.315452</td>\n",
       "      <td>4.636813</td>\n",
       "      <td>817.278288</td>\n",
       "      <td>798.424187</td>\n",
       "      <td>806.591906</td>\n",
       "      <td>814.204309</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>129.830071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.326964</td>\n",
       "      <td>244.264093</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>-0.048392</td>\n",
       "      <td>2.121450</td>\n",
       "      <td>601.103134</td>\n",
       "      <td>603.996503</td>\n",
       "      <td>599.688887</td>\n",
       "      <td>613.001509</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>132.612188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.241377</td>\n",
       "      <td>14.248378</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.049762</td>\n",
       "      <td>-0.663385</td>\n",
       "      <td>17.336061</td>\n",
       "      <td>161.994030</td>\n",
       "      <td>736.884628</td>\n",
       "      <td>168.921460</td>\n",
       "      <td>753.047067</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>168.498143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.243013</td>\n",
       "      <td>3.800776</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.259998</td>\n",
       "      <td>3.683240</td>\n",
       "      <td>383.020975</td>\n",
       "      <td>338.981122</td>\n",
       "      <td>390.431154</td>\n",
       "      <td>629.404418</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>130.601779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.086238</td>\n",
       "      <td>2.082460</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>2.669395</td>\n",
       "      <td>486.147688</td>\n",
       "      <td>1113.577934</td>\n",
       "      <td>475.613857</td>\n",
       "      <td>470.048140</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>138.019596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.201270</td>\n",
       "      <td>488.588304</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>-0.023712</td>\n",
       "      <td>0.809487</td>\n",
       "      <td>736.370879</td>\n",
       "      <td>698.732063</td>\n",
       "      <td>739.482807</td>\n",
       "      <td>730.215557</td>\n",
       "      <td>-0.091358</td>\n",
       "      <td>147.091466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.588023</td>\n",
       "      <td>244.257833</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.043474</td>\n",
       "      <td>0.307246</td>\n",
       "      <td>5.746615</td>\n",
       "      <td>162.781849</td>\n",
       "      <td>168.557503</td>\n",
       "      <td>164.422849</td>\n",
       "      <td>177.823414</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>96.966137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price_mean   price_std  bid_mean   bid_std  ask_mean    ask_std  \\\n",
       "eqt_code_cat                                                                    \n",
       "0               0.326864  244.311979  0.000027  0.006988  0.010293   0.106592   \n",
       "1               0.294431  244.142359 -0.000108  0.033359  0.071947   0.861021   \n",
       "2               0.982058   11.604307  0.000307  0.034648  1.022583  10.290731   \n",
       "3               0.125475    3.482658  0.000557  0.021087  0.143525   3.245651   \n",
       "4               0.853382    8.199992  0.000032  0.008687  0.883976   8.025556   \n",
       "5               1.189307  345.440584  0.000355  0.022169  0.606434   7.807343   \n",
       "6               3.966658   33.013562  0.000153  0.047259  3.977365  30.846413   \n",
       "7               1.999544  345.605859  0.000250  0.033275  1.090260  15.229392   \n",
       "8               1.357141  244.475910  0.000066  0.032336  1.011080  10.080935   \n",
       "9               0.404159  244.326799 -0.000118  0.006757  0.090635   1.528992   \n",
       "10              0.332778  244.243380 -0.000003  0.010934  0.049908   1.382313   \n",
       "11              0.683449    9.785410 -0.000118  0.018579  0.724180   9.477508   \n",
       "12              1.228660  488.404070 -0.000205  0.024505 -0.169555   4.199544   \n",
       "13              3.386597   23.042622  0.001819  0.129817  3.418622  22.907708   \n",
       "14             -0.007084    5.701263  0.000328  0.027508 -0.369246  10.034551   \n",
       "15              1.386021   16.732446 -0.000101  0.026708  1.436356  16.561654   \n",
       "16              0.127587    2.777547  0.000025  0.006446  0.129464   2.634154   \n",
       "17              0.309197    4.656790  0.000030  0.007067  0.315452   4.636813   \n",
       "18              0.326964  244.264093 -0.000118  0.007781 -0.048392   2.121450   \n",
       "19             -0.241377   14.248378  0.000057  0.049762 -0.663385  17.336061   \n",
       "20              0.243013    3.800776  0.000075  0.013093  0.259998   3.683240   \n",
       "21              0.086238    2.082460  0.000026  0.011394  0.000814   2.669395   \n",
       "22              1.201270  488.588304 -0.000042  0.008339 -0.023712   0.809487   \n",
       "23              0.588023  244.257833  0.000817  0.043474  0.307246   5.746615   \n",
       "\n",
       "              bid_size_mean  bid_size_std  ask_size_mean  ask_size_std  \\\n",
       "eqt_code_cat                                                             \n",
       "0               1119.964755   1211.561051    1147.836754   1204.579320   \n",
       "1                216.918185    212.234866     201.423791    314.203573   \n",
       "2                186.419969    187.646382     189.073709    210.479808   \n",
       "3                308.127230    506.450328     305.982279    446.357861   \n",
       "4                662.953563    799.700871     662.598113    869.794211   \n",
       "5                236.740885    230.588653     237.603064    228.282298   \n",
       "6                175.042066    190.151062     188.398333    259.891263   \n",
       "7                172.683225    187.889848     174.378119    188.870987   \n",
       "8                244.277054    369.764408     232.671263    288.548581   \n",
       "9                868.008145   1373.397123     849.786031   1423.427002   \n",
       "10               410.276401    523.071085     428.250384    573.743543   \n",
       "11               281.187058    558.365077     266.068804    257.893943   \n",
       "12               256.040387    327.411327     261.294633    267.790361   \n",
       "13               166.850510    214.854556     157.079015    174.223530   \n",
       "14               230.177081    399.628924     221.356406    266.003776   \n",
       "15               261.332903    257.733894     248.033697    256.509570   \n",
       "16              1170.997325   1397.119718    1185.719821   1483.621631   \n",
       "17               817.278288    798.424187     806.591906    814.204309   \n",
       "18               601.103134    603.996503     599.688887    613.001509   \n",
       "19               161.994030    736.884628     168.921460    753.047067   \n",
       "20               383.020975    338.981122     390.431154    629.404418   \n",
       "21               486.147688   1113.577934     475.613857    470.048140   \n",
       "22               736.370879    698.732063     739.482807    730.215557   \n",
       "23               162.781849    168.557503     164.422849    177.823414   \n",
       "\n",
       "              flux_mean    flux_std  \n",
       "eqt_code_cat                         \n",
       "0              0.068706  176.911762  \n",
       "1              0.002690   99.000094  \n",
       "2              0.034213   97.038877  \n",
       "3             -0.007455  107.867757  \n",
       "4             -0.117772  163.018573  \n",
       "5              0.083909  105.894553  \n",
       "6             -0.013784  115.483682  \n",
       "7              0.008646  101.708000  \n",
       "8              0.050042  206.055396  \n",
       "9              0.209633  176.114298  \n",
       "10             0.286036  143.924767  \n",
       "11             0.044387  118.718634  \n",
       "12            -0.044721  142.300952  \n",
       "13            -0.016770  107.969165  \n",
       "14            -0.124300  111.915126  \n",
       "15             0.068670  228.259072  \n",
       "16            -0.212397  226.220626  \n",
       "17             0.213228  129.830071  \n",
       "18             0.067993  132.612188  \n",
       "19             0.075470  168.498143  \n",
       "20             0.013033  130.601779  \n",
       "21             0.034306  138.019596  \n",
       "22            -0.091358  147.091466  \n",
       "23             0.017488   96.966137  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(obs_with_outliers)]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_std\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Appliquer la fonction sur X_train\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mremove_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meqt_code_cat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbid_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mask_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflux\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 22\u001b[0m, in \u001b[0;36mremove_outliers\u001b[0;34m(df, group_col, cols, threshold)\u001b[0m\n\u001b[1;32m     19\u001b[0m stats\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(col)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mcolumns]  \u001b[38;5;66;03m# Flatten multi-index columns\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Joindre les stats au DataFrame initial\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Calculer un masque booléen pour détecter les lignes avec des outliers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m outlier_flags \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     (np\u001b[38;5;241m.\u001b[39mabs(df[col] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m threshold \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_std\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols\n\u001b[1;32m     28\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10841\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10842\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:737\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    734\u001b[0m right_join_keys: \u001b[38;5;28mlist\u001b[39m[ArrayLike]\n\u001b[1;32m    735\u001b[0m left_join_keys: \u001b[38;5;28mlist\u001b[39m[ArrayLike]\n\u001b[0;32m--> 737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    739\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m    740\u001b[0m     right: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m    741\u001b[0m     how: JoinHow \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    742\u001b[0m     on: IndexLabel \u001b[38;5;241m|\u001b[39m AnyArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    743\u001b[0m     left_on: IndexLabel \u001b[38;5;241m|\u001b[39m AnyArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    744\u001b[0m     right_on: IndexLabel \u001b[38;5;241m|\u001b[39m AnyArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m     left_index: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    746\u001b[0m     right_index: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    747\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    748\u001b[0m     suffixes: Suffixes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_y\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    749\u001b[0m     indicator: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    750\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    751\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     _left \u001b[38;5;241m=\u001b[39m _validate_operand(left)\n\u001b[1;32m    753\u001b[0m     _right \u001b[38;5;241m=\u001b[39m _validate_operand(right)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols_to_check = ['price', 'bid', 'ask', 'bid_size', 'ask_size', 'flux']\n",
    "\n",
    "def remove_outliers(df, group_col, cols, threshold=7):\n",
    "    \"\"\"\n",
    "    Supprime toutes les lignes d'un `obs_id` si au moins une valeur est un outlier\n",
    "    selon les statistiques calculées par `group_col`.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Le DataFrame d'entrée.\n",
    "        group_col (str): La colonne pour grouper les calculs de moyenne et d'écart-type.\n",
    "        cols (list): Les colonnes sur lesquelles appliquer la logique de suppression des outliers.\n",
    "        threshold (float): Le seuil d'écart-type pour définir les outliers.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Le DataFrame sans les `obs_id` ayant des outliers.\n",
    "    \"\"\"\n",
    "    # Calcul des moyennes et écarts-types par group_col\n",
    "    stats = df.groupby(group_col)[cols].agg(['mean', 'std'])\n",
    "    stats.columns = ['_'.join(col).strip() for col in stats.columns]  # Flatten multi-index columns\n",
    "\n",
    "    # Joindre les stats au DataFrame initial\n",
    "    df = df.merge(stats, on=group_col, how='left')\n",
    "\n",
    "    # Calculer un masque booléen pour détecter les lignes avec des outliers\n",
    "    outlier_flags = [\n",
    "        (np.abs(df[col] - df[f\"{col}_mean\"]) > threshold * df[f\"{col}_std\"])\n",
    "        for col in cols\n",
    "    ]\n",
    "    outlier_mask = np.logical_or.reduce(outlier_flags)  # Une seule condition True suffit\n",
    "\n",
    "    # Identifier les `obs_id` contenant au moins un outlier\n",
    "    obs_with_outliers = df.loc[outlier_mask, 'obs_id'].unique()\n",
    "\n",
    "    # Supprimer tous les `obs_id` contenant des outliers\n",
    "    return df[~df['obs_id'].isin(obs_with_outliers)].drop(columns=[f\"{col}_mean\" for col in cols] + [f\"{col}_std\" for col in cols])\n",
    "\n",
    "\n",
    "# Appliquer la fonction sur X_train\n",
    "X_train = remove_outliers(X_train, group_col='eqt_code_cat', cols=['price', 'bid', 'ask', 'bid_size', 'ask_size', 'flux'], threshold=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/s4t1bsn973dfhyz_6q842jr00000gn/T/ipykernel_43763/1641231859.py:45: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=group_col, y=feature, data=df, ax=axes[i], palette=\"Set2\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/seaborn/_base.py:1768\u001b[0m, in \u001b[0;36mcategorical_order\u001b[0;34m(vector, order)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1768\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[38;5;241m.\u001b[39mcategories\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:2898\u001b[0m, in \u001b[0;36mCategoricalAccessor.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2898\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:2907\u001b[0m, in \u001b[0;36mCategoricalAccessor._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype):\n\u001b[0;32m-> 2907\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .cat accessor with a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .cat accessor with a 'category' dtype",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Exemple d'utilisation\u001b[39;00m\n\u001b[1;32m     56\u001b[0m features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbid_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m ]\n\u001b[0;32m---> 59\u001b[0m \u001b[43mplot_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExample Label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meqt_code_cat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 45\u001b[0m, in \u001b[0;36mplot_sample\u001b[0;34m(df, features, label, group_col, name)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Tracer chaque feature\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features):\n\u001b[0;32m---> 45\u001b[0m     \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSet2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     axes[i]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m     47\u001b[0m     axes[i]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValeur\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/seaborn/categorical.py:1619\u001b[0m, in \u001b[0;36mboxplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, dodge, width, gap, whis, linecolor, linewidth, fliersize, hue_norm, native_scale, log_scale, formatter, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mvar_types\u001b[38;5;241m.\u001b[39mget(p\u001b[38;5;241m.\u001b[39morient) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m native_scale:\n\u001b[1;32m   1617\u001b[0m     p\u001b[38;5;241m.\u001b[39mscale_categorical(p\u001b[38;5;241m.\u001b[39morient, order\u001b[38;5;241m=\u001b[39morder, formatter\u001b[38;5;241m=\u001b[39mformatter)\n\u001b[0;32m-> 1619\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;66;03m# Deprecations to remove in v0.14.0.\u001b[39;00m\n\u001b[1;32m   1622\u001b[0m hue_order \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39m_palette_without_hue_backcompat(palette, hue_order)\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/seaborn/_base.py:1134\u001b[0m, in \u001b[0;36mVectorPlotter._attach\u001b[0;34m(self, obj, allowed_types, log_scale)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m                 order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1134\u001b[0m             seed_data \u001b[38;5;241m=\u001b[39m \u001b[43mcategorical_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         converter\u001b[38;5;241m.\u001b[39mupdate_units(seed_data)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# -- Set numerical axis scales\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# First unpack the log_scale argument\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/seaborn/_base.py:1771\u001b[0m, in \u001b[0;36mcategorical_order\u001b[0;34m(vector, order)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     order \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m-> 1771\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable_type(vector) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1774\u001b[0m         order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(order)\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/series.py:2407\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAPeCAYAAACiLrs2AAAAP3RFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMS5wb3N0MSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8kixA/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC/2UlEQVR4nOzdeVyU5f7/8fewuwFugCjuqbmjJmllZh5wLVu01FIzs0VNxUw9mVsebbMsc0mPS+cox9Kj1lfJQEqttMyF3E1zLQVcQVHZ5v790Y85joDOwIww8Ho+HvN4MNf9mWs+wz3b/Znrum6TYRiGAAAAAAAAACdwK+wEAAAAAAAAUHxRfAIAAAAAAIDTUHwCAAAAAACA01B8AgAAAAAAgNNQfAIAAAAAAIDTUHwCAAAAAACA01B8AgAAAAAAgNNQfAIAAAAAAIDTUHwCAAAAAACA01B8AoAiZuPGjTKZTNq4cWNhpwIAAAAABUbxCYBNlixZIpPJlOtl7NixTrnPLVu2aNKkSbp06ZJT+gcAAAAAOJ9HYScAwLVMmTJFtWrVsmpr3LixU+5ry5Ytmjx5sgYMGCB/f3+n3EdR1K5dO127dk1eXl6FnQoAAAAAFBjFJwB26dy5s1q1alXYaRRIamqqypQpU9hp5HD9+nV5eXnJzc1NPj4+hZ0OAAAAADgE0+4AONTXX3+tBx54QGXKlFG5cuXUtWtX7du3zypm9+7dGjBggGrXri0fHx8FBQVp4MCBOn/+vCVm0qRJGj16tCSpVq1alil+x48f1/Hjx2UymbRkyZIc928ymTRp0iSrfkwmk/bv368+ffqofPnyuv/++y3bly5dqpYtW6pUqVKqUKGCnn76aZ06dcqqz6tXr+rgwYM6d+7cbR9/+/bt1bhxY+3YsUNt27ZVqVKlVKtWLc2bN88qLntdp+XLl2v8+PGqWrWqSpcurZSUlDzXfPr555/VpUsXlS9fXmXKlFHTpk310UcfWcUcPHhQTz75pCpUqCAfHx+1atVKX3311W3zBgAAAABnYeQTALskJyfnKMJUqlRJkvTvf/9b/fv3V0REhN555x1dvXpVc+fO1f33369du3apZs2akqTY2FgdPXpUzz33nIKCgrRv3z7Nnz9f+/bt008//SSTyaTHH39cv/32m/7zn//oww8/tNxH5cqVdfbsWbvz7tmzp+666y5NmzZNhmFIkv7xj3/ozTffVK9evTRo0CCdPXtWs2bNUrt27bRr1y7LVL9t27bpoYce0sSJE60KW3m5ePGiunTpol69eql379764osv9PLLL8vLy0sDBw60in3rrbfk5eWl1157TWlpaXlOtYuNjVW3bt1UpUoVDR8+XEFBQTpw4IDWrl2r4cOHS5L27dun++67T1WrVtXYsWNVpkwZffHFF+rRo4f++9//6rHHHrP7/wYAAAAABUXxCYBdOnbsmKPNMAxduXJFr776qgYNGqT58+dbtvXv31/169fXtGnTLO2vvPKKRo0aZdXHvffeq969e+uHH37QAw88oKZNm6pFixb6z3/+ox49elgKV5LyVXxq1qyZoqKiLNdPnDihiRMnaurUqfr73/9uaX/88ccVGhqqOXPmWLXb4/Tp05oxY4YiIyMlSS+++KLCwsI0btw4Pfvss/L09LTEXr9+Xdu3b1epUqXy7C8rK0svvviiqlSpovj4eKv1r7ILaZI0fPhwVa9eXb/88ou8vb0l/fW/vv/++zVmzBiKTwAAAAAKBcUnAHaZPXu26tWrl6M9NjZWly5dUu/eva1GRrm7uyssLEzfffedpe3GQsv169d15coV3XvvvZKknTt36oEHHnB43i+99JLV9VWrVslsNqtXr15W+QYFBemuu+7Sd999Zyk+tW/f3qrIczseHh568cUXLde9vLz04osv6uWXX9aOHTssj1X6qzh3q8KTJO3atUvHjh3Thx9+mGPhdZPJJEm6cOGCvv32W02ZMkWXL1/W5cuXLTERERGaOHGi/vzzT1WtWtXmxwEAAAAAjkDxCYBdWrduneuC44cPH5YkdejQIdfb+fr6Wv6+cOGCJk+erOXLlyspKckqLjk52YHZ/s/NZ+g7fPiwDMPQXXfdlWv8jaOT7BUcHJxjQfPsgt3x48etik8355Wb33//XdKtzyp45MgRGYahN998U2+++WauMUlJSRSfAAAAANxxFJ8AOITZbJb017pPQUFBObZ7ePzv7aZXr17asmWLRo8erebNm6ts2bIym83q1KmTpZ9byR7tc7OsrKw8b3Pz6CKz2SyTyaSvv/5a7u7uOeLLli172zwc4XajnmyV/X977bXXFBERkWtM3bp1HXJfAAAAAGAPik8AHKJOnTqSpICAgFzXhcp28eJFxcXFafLkyZowYYKlPXvk1I3yKjKVL19eknTp0iWr9hMnTtiVr2EYqlWrVq7TCAvi9OnTSk1NtRr99Ntvv0mS1dpVtsr+3+7duzfP/23t2rUl/TVi61b/fwAAAAC409wKOwEAxUNERIR8fX01bdo0ZWRk5NievUh49iijm9dQmjlzZo7bZBdvbi4y+fr6qlKlStq8ebNV+5w5c2zO9/HHH5e7u7smT56cIxfDMHT+/HnL9atXr+rgwYM5zvKXl8zMTH366aeW6+np6fr0009VuXJltWzZ0uYcs7Vo0UK1atXSzJkzc/wvsnMPCAhQ+/bt9emnn+rMmTM5+sjPIu0AAAAA4AiMfALgEL6+vpo7d66effZZtWjRQk8//bQqV66skydPat26dbrvvvv0ySefyNfXV+3atdO7776rjIwMVa1aVTExMTp27FiOPrMLNW+88YaefvppeXp6qnv37ipTpowGDRqkt99+W4MGDVKrVq20efNmy+giW9SpU0dTp07VuHHjdPz4cfXo0UPlypXTsWPHtHr1ag0ePFivvfaaJGnbtm166KGHNHHiRE2aNOm2fQcHB+udd97R8ePHVa9ePX3++eeKj4/X/Pnz87WWlJubm+bOnavu3burefPmeu6551SlShUdPHhQ+/bt0zfffCPpr8Xg77//fjVp0kQvvPCCateurcTERG3dulV//PGHfv31V7vvGwAAAAAKiuITAIfp06ePgoOD9fbbb+u9995TWlqaqlatqgceeEDPPfecJS4qKkrDhg3T7NmzZRiGwsPD9fXXXys4ONiqv3vuuUdvvfWW5s2bp/Xr18tsNuvYsWMqU6aMJkyYoLNnz2rlypX64osv1LlzZ3399dcKCAiwOd+xY8eqXr16+vDDDzV58mRJUkhIiMLDw/XII4/k+/9Qvnx5ffbZZxo2bJgWLFigwMBAffLJJ3rhhRfy3WdERIS+++47TZ48WTNmzJDZbFadOnWs+mzYsKG2b9+uyZMna8mSJTp//rwCAgIUGhpqNcURAAAAAO4kk2HP+cMBALfUvn17nTt3Tnv37i3sVAAAAACgSGDNJwAAAAAAADgNxScAAAAAAAA4DcUnAAAAAAAAOA3FJwBwoI0bN7LeE4AibfPmzerevbuCg4NlMpm0Zs2a295m48aNatGihby9vVW3bl0tWbLE6XkCAIDig+ITAABACZKamqpmzZpp9uzZNsUfO3ZMXbt21UMPPaT4+HiNGDFCgwYN0jfffOPkTAEAQHHB2e4AAABKKJPJpNWrV6tHjx55xowZM0br1q2zGtX59NNP69KlS1q/fv0dyBIAALg6j8JOwNWYzWadPn1a5cqVk8lkKux0AABAHgzD0OXLlxUcHCw3NwZ759fWrVvVsWNHq7aIiAiNGDEiz9ukpaUpLS3Nct1sNuvChQuqWLEi358AACjCnPX9ieKTnU6fPq2QkJDCTgMAANjo1KlTqlatWmGn4bISEhIUGBho1RYYGKiUlBRdu3ZNpUqVynGb6dOna/LkyXcqRQAA4GCO/v5E8clO5cqVk/TXjvD19S3kbAAAQF5SUlIUEhJi+ezGnTNu3DhFRkZaricnJ6t69ep8fwIAoIhz1vcnik92yh4q7uvry5cnAABcANO8CiYoKEiJiYlWbYmJifL19c111JMkeXt7y9vbO0c7358AAHANjv7+xAIIAAAAyFObNm0UFxdn1RYbG6s2bdoUUkYAAMDVUHwCAAAoQa5cuaL4+HjFx8dLko4dO6b4+HidPHlS0l9T5vr162eJf+mll3T06FG9/vrrOnjwoObMmaMvvvhCI0eOLIz0AQCAC6L4BAAAUIJs375doaGhCg0NlSRFRkYqNDRUEyZMkCSdOXPGUoiSpFq1amndunWKjY1Vs2bNNGPGDP3zn/9UREREoeQPAABcj8kwDKOwk3AlKSkp8vPzU3JyMmsWAABQhPGZXXSwLwAAcA3O+sxm5BMAAAAAAACchrPdAUVMZmamYmJilJSUpICAAIWHh8vDg5cqAAAAAMA1cUQLFCFRUVGKjo6W2Wy2auvSpYv69OlTiJkBAAAAAJA/FJ+AIiIqKkpr166Vn5+fevbsqRYtWmjnzp1asWKF1q5dK0kUoAAAAAAALoc1n4AiIDMzU9HR0fLz89OHH36o69eva82aNbp+/bo+/PBD+fn5KTo6WpmZmYWdKgAAAAAAdmHkE1AExMTEyGw2q3r16ho0aFCOaXeNGjXSnj17FBMToy5duhRipgAAAAAA2IfiE1AEJCUlSZL27NmT67S7PXv2WMUBAAAAAOAqKD4BRUCFChUkSaVKldKsWbMsZ7fr0KGD2rVrpxdffFHXrl2zxAEAAAAA4CpY8wkoAtzc/nopGoaR6/bs9uw4AAAAAABcBUeyQBFw7tw5SdL169c1bNgwxcXF6cKFC4qLi9OwYcN0/fp1qzgAAAAAAFwF0+6AIiAgIECS1LRpU+3du1cLFy60bHNzc1OTJk20Z88eSxwAAAAAAK6C4hNQBISHhysqKkonTpzQP//5T3377bdKSkpSQECAOnTooJEjR8rNzU3h4eGFnSoAAAAAAHYpMtPuNm/erO7duys4OFgmk0lr1qyx2j5gwACZTCarS6dOnaxiLly4oL59+8rX11f+/v56/vnndeXKFauY3bt364EHHpCPj49CQkL07rvvOvuhAbfl4eGhLl26KDk5WSNHjpS3t7ceeeQReXt7a+TIkUpOTlaXLl0sC5EDAAAAAOAqisyRbGpqqpo1a6aBAwfq8ccfzzWmU6dOWrx4seW6t7e31fa+ffvqzJkzio2NVUZGhp577jkNHjxYUVFRkqSUlBSFh4erY8eOmjdvnvbs2aOBAwfK399fgwcPdt6DA2zQp08fSVJ0dHSOaXfdunWzbAcAAAAAwJUUmeJT586d1blz51vGeHt7KygoKNdtBw4c0Pr16/XLL7+oVatWkqRZs2apS5cuev/99xUcHKxly5YpPT1dixYtkpeXlxo1aqT4+Hh98MEHFJ9QJPTp00e9evVSTEyMZdpdeHh4kRvxlJmZWeRzBAAAAAAUDS51tLhx40YFBASofPny6tChg6ZOnaqKFStKkrZu3Sp/f39L4UmSOnbsKDc3N/3888967LHHtHXrVrVr105eXl6WmIiICL3zzju6ePGiypcvn+M+09LSlJaWZrmekpLixEcI/G8KXlEVFRWl6Ohomc1mq7YuXbowOgsAAAAAkEORWfPpdjp16qR//etfiouL0zvvvKNNmzapc+fOysrKkiQlJCTkOBOYh4eHKlSooISEBEtMYGCgVUz29eyYm02fPl1+fn6WS0hIiKMfGuAyoqKitHbtWpUrV06DBg3SnDlzNGjQIJUrV05r1661THEFAAAAACCby4x8evrppy1/N2nSRE2bNlWdOnW0ceNGPfzww06733HjxikyMtJyPSUlhQIUSqTMzExFR0fLz89Ps2bNskyz69Chg9q1a6dhw4YpOjpavXr1YgoeAAAAAMDCZUY+3ax27dqqVKmSjhw5IkkKCgpSUlKSVUxmZqYuXLhgWScqKChIiYmJVjHZ1/NaS8rb21u+vr5WF6AkiomJkdlsVs+ePXMUlzw8PPTkk0/KbDYrJiamkDIEAAAAABRFLlt8+uOPP3T+/HlVqVJFktSmTRtdunRJO3bssMR8++23MpvNCgsLs8Rs3rxZGRkZlpjY2FjVr18/1/WeAPxPdnG3RYsWuW4PDQ21igMAAAAAQCpCxacrV64oPj5e8fHxkqRjx44pPj5eJ0+e1JUrVzR69Gj99NNPOn78uOLi4vToo4+qbt26ioiIkCTdfffd6tSpk1544QVt27ZNP/74o4YOHaqnn35awcHBkv46k5iXl5eef/557du3T59//rk++ugjq2l1AHKXvabazp07c92+a9cuqzgAAAAAAKQiVHzavn27QkNDLaMnIiMjFRoaqgkTJsjd3V27d+/WI488onr16un5559Xy5Yt9f3338vb29vSx7Jly9SgQQM9/PDD6tKli+6//37Nnz/fst3Pz08xMTE6duyYWrZsqVGjRmnChAkaPHjwHX+8gKsJDw+Xm5ubVqxYoczMTKttmZmZWrlypdzc3BQeHl5IGQIAAAAAiiKTYRhGYSfhSlJSUuTn56fk5GTWf0KJk322Oz8/Pz355JMKDQ3Vrl27tHLlSiUnJ6tbt27q06dPYacJAJL4zC5K2BcAALgGZ31mc0oqADbLLixFR0dr4cKFlnY3NzcKTwAAAACAXFF8AmCXPn36qFevXoqJiVFSUpICAgIUHh6e4wx4AAAAAABIFJ8A5IOHh4e6dOlS2GkAAAAAAFxAkVlwHAAAAAAAAMUPxScAAAAAAAA4DcUnAAAAAAAAOA3FJwAAAAAAADgNxScAAAAAAAA4DcUnAAAAAAAAOA3FJwAAAAAAADgNxScAAAAAAAA4DcUnAAAAAAAAOA3FJwAAAAAAADgNxScAAAAAAAA4DcUnAAAAAAAAOA3FJwAAAAAAADgNxScAAAAAAAA4DcUnAAAAAAAAOA3FJwAAAAAAADgNxScAAAAAAAA4DcUnAACAEmb27NmqWbOmfHx8FBYWpm3btt0yfubMmapfv75KlSqlkJAQjRw5UtevX79D2QIAAFdH8QkAAKAE+fzzzxUZGamJEydq586datasmSIiIpSUlJRrfFRUlMaOHauJEyfqwIEDWrhwoT7//HP9/e9/v8OZAwAAV1Vkik+bN29W9+7dFRwcLJPJpDVr1li2ZWRkaMyYMWrSpInKlCmj4OBg9evXT6dPn7bqo2bNmjKZTFaXt99+2ypm9+7deuCBB+Tj46OQkBC9++67d+LhAQAAFAkffPCBXnjhBT333HNq2LCh5s2bp9KlS2vRokW5xm/ZskX33Xef+vTpo5o1ayo8PFy9e/e+7WgpAACAbEWm+JSamqpmzZpp9uzZObZdvXpVO3fu1JtvvqmdO3dq1apVOnTokB555JEcsVOmTNGZM2csl2HDhlm2paSkKDw8XDVq1NCOHTv03nvvadKkSZo/f75THxsAAEBRkJ6erh07dqhjx46WNjc3N3Xs2FFbt27N9TZt27bVjh07LMWmo0ePKjo6Wl26dLkjOQMAANfnUdgJZOvcubM6d+6c6zY/Pz/FxsZatX3yySdq3bq1Tp48qerVq1vay5Urp6CgoFz7WbZsmdLT07Vo0SJ5eXmpUaNGio+P1wcffKDBgwc77sEAAAAUQefOnVNWVpYCAwOt2gMDA3Xw4MFcb9OnTx+dO3dO999/vwzDUGZmpl566aVbTrtLS0tTWlqa5XpKSopjHgAAAHBJRWbkk72Sk5NlMpnk7+9v1f7222+rYsWKCg0N1XvvvafMzEzLtq1bt6pdu3by8vKytEVEROjQoUO6ePHinUodAADAZWzcuFHTpk3TnDlzLCPQ161bp7feeivP20yfPl1+fn6WS0hIyB3MGAAAFDVFZuSTPa5fv64xY8aod+/e8vX1tbS/+uqratGihSpUqKAtW7Zo3LhxOnPmjD744ANJUkJCgmrVqmXVV/YvfwkJCSpfvnyO++KXOwAAUFxUqlRJ7u7uSkxMtGpPTEzMc+T4m2++qWeffVaDBg2SJDVp0kSpqakaPHiw3njjDbm55fwtc9y4cYqMjLRcT0lJoQAFAEAJ5nLFp4yMDPXq1UuGYWju3LlW2278ktO0aVN5eXnpxRdf1PTp0+Xt7Z2v+5s+fbomT55coJwBAACKAi8vL7Vs2VJxcXHq0aOHJMlsNisuLk5Dhw7N9TZXr17NUWByd3eXJBmGkettvL298/3dCwAAFD8uNe0uu/B04sQJxcbGWo16yk1YWJgyMzN1/PhxSVJQUFCuv/Rlb8vNuHHjlJycbLmcOnWq4A8EAACgkERGRmrBggX67LPPdODAAb388stKTU3Vc889J0nq16+fxo0bZ4nv3r275s6dq+XLl+vYsWOKjY3Vm2++qe7du1uKUAAAALfiMiOfsgtPhw8f1nfffaeKFSve9jbx8fFyc3NTQECAJKlNmzZ64403lJGRIU9PT0lSbGys6tevn+uUO4lf7gAAQPHy1FNP6ezZs5owYYISEhLUvHlzrV+/3rIUwcmTJ61GOo0fP14mk0njx4/Xn3/+qcqVK6t79+76xz/+UVgPAQAAuBiTkdd46TvsypUrOnLkiCQpNDRUH3zwgR566CFVqFBBVapU0ZNPPqmdO3dq7dq1VmdoqVChgry8vLR161b9/PPPeuihh1SuXDlt3bpVI0eOVOfOnfXZZ59J+muR8vr16ys8PFxjxozR3r17NXDgQH344Yc2n+0uJSVFfn5+Sk5Ovu3IKwAAUHj4zC462BcAALgGZ31mF5ni08aNG/XQQw/laO/fv78mTZqUY6HwbN99953at2+vnTt36pVXXtHBgweVlpamWrVq6dlnn1VkZKTVyKXdu3dryJAh+uWXX1SpUiUNGzZMY8aMsTlPvjwBAOAa+MwuOtgXAAC4hmJffHIVfHkCAMA18JlddLAvAABwDc76zHapBccBAAAAAADgWig+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+AQAAAAAAwGmKTPFp8+bN6t69u4KDg2UymbRmzRqr7YZhaMKECapSpYpKlSqljh076vDhw1YxFy5cUN++feXr6yt/f389//zzunLlilXM7t279cADD8jHx0chISF69913nf3QAAAAAAAASqwiU3xKTU1Vs2bNNHv27Fy3v/vuu/r44481b948/fzzzypTpowiIiJ0/fp1S0zfvn21b98+xcbGau3atdq8ebMGDx5s2Z6SkqLw8HDVqFFDO3bs0HvvvadJkyZp/vz5Tn98AAAAAAAAJZHJMAyjsJO4mclk0urVq9WjRw9Jf416Cg4O1qhRo/Taa69JkpKTkxUYGKglS5bo6aef1oEDB9SwYUP98ssvatWqlSRp/fr16tKli/744w8FBwdr7ty5euONN5SQkCAvLy9J0tixY7VmzRodPHjQptxSUlLk5+en5ORk+fr6Ov7BAwAAh+Azu+hgXwAA4Bqc9ZldZEY+3cqxY8eUkJCgjh07Wtr8/PwUFhamrVu3SpK2bt0qf39/S+FJkjp27Cg3Nzf9/PPPlph27dpZCk+SFBERoUOHDunixYu53ndaWppSUlKsLgAAAAAAALCNSxSfEhISJEmBgYFW7YGBgZZtCQkJCggIsNru4eGhChUqWMXk1seN93Gz6dOny8/Pz3IJCQkp+AMCAAAAAAAoIVyi+FSYxo0bp+TkZMvl1KlThZ0SAAAAAACAy3CJ4lNQUJAkKTEx0ao9MTHRsi0oKEhJSUlW2zMzM3XhwgWrmNz6uPE+bubt7S1fX1+rCwAAAAAAAGzjEsWnWrVqKSgoSHFxcZa2lJQU/fzzz2rTpo0kqU2bNrp06ZJ27Nhhifn2229lNpsVFhZmidm8ebMyMjIsMbGxsapfv77Kly9/hx4NAAAAAABAyVFkik9XrlxRfHy84uPjJf21yHh8fLxOnjwpk8mkESNGaOrUqfrqq6+0Z88e9evXT8HBwZYz4t19993q1KmTXnjhBW3btk0//vijhg4dqqefflrBwcGSpD59+sjLy0vPP/+89u3bp88//1wfffSRIiMjC+lRAwAAAAAAFG8ehZ1Atu3bt+uhhx6yXM8uCPXv319LlizR66+/rtTUVA0ePFiXLl3S/fffr/Xr18vHx8dym2XLlmno0KF6+OGH5ebmpieeeEIff/yxZbufn59iYmI0ZMgQtWzZUpUqVdKECRM0ePDgO/dAAQAAAAAAShCTYRhGYSfhSlJSUuTn56fk5GTWfwIAoAjjM7voYF8AAOAanPWZXWSm3QEAAAAAAKD4ofgEAAAAAAAAp6H4BAAAAAAAAKeh+AQAAAAAAACnofgEAAAAAAAAp6H4BAAAAAAAAKeh+AQAAAAAAACnofgEAAAAAAAAp6H4BAAAUMLMnj1bNWvWlI+Pj8LCwrRt27Zbxl+6dElDhgxRlSpV5O3trXr16ik6OvoOZQsAAFydR2EnAAAAgDvn888/V2RkpObNm6ewsDDNnDlTEREROnTokAICAnLEp6en629/+5sCAgK0cuVKVa1aVSdOnJC/v/+dTx4AALgkik8AAAAlyAcffKAXXnhBzz33nCRp3rx5WrdunRYtWqSxY8fmiF+0aJEuXLigLVu2yNPTU5JUs2bNO5kyAABwcUy7AwAAKCHS09O1Y8cOdezY0dLm5uamjh07auvWrbne5quvvlKbNm00ZMgQBQYGqnHjxpo2bZqysrLyvJ+0tDSlpKRYXQAAQMlF8QkAAKCEOHfunLKyshQYGGjVHhgYqISEhFxvc/ToUa1cuVJZWVmKjo7Wm2++qRkzZmjq1Kl53s/06dPl5+dnuYSEhDj0cQAAANdC8QkAAAB5MpvNCggI0Pz589WyZUs99dRTeuONNzRv3rw8bzNu3DglJydbLqdOnbqDGQMAgKKGNZ8AAABKiEqVKsnd3V2JiYlW7YmJiQoKCsr1NlWqVJGnp6fc3d0tbXfffbcSEhKUnp4uLy+vHLfx9vaWt7e3Y5MHAAAui5FPAAAAJYSXl5datmypuLg4S5vZbFZcXJzatGmT623uu+8+HTlyRGaz2dL222+/qUqVKrkWngAAAG5G8QkAAKAEiYyM1IIFC/TZZ5/pwIEDevnll5Wammo5+12/fv00btw4S/zLL7+sCxcuaPjw4frtt9+0bt06TZs2TUOGDCmshwAAAFwM0+4AAABKkKeeekpnz57VhAkTlJCQoObNm2v9+vWWRchPnjwpN7f//T4ZEhKib775RiNHjlTTpk1VtWpVDR8+XGPGjCmshwAAAFyMyTAMo7CTcCUpKSny8/NTcnKyfH19CzsdAACQBz6ziw72BQAArsFZn9l2TbvLyMhQnTp1dODAAYclAAAAAAAAgOLLruKTp6enrl+/7qxcAAAAAAAAUMzYveD4kCFD9M477ygzM9MZ+QAAAAAAAKAYsbv49Msvv2jVqlWqXr26IiIi9Pjjj1tdnKVmzZoymUw5LtlnWmnfvn2ObS+99JJVHydPnlTXrl1VunRpBQQEaPTo0RTRAAAAAAAAnMjus935+/vriSeecEYut/TLL78oKyvLcn3v3r3629/+pp49e1raXnjhBU2ZMsVyvXTp0pa/s7Ky1LVrVwUFBWnLli06c+aM+vXrJ09PT02bNu3OPAgAAAAAAIASxu7i0+LFi52Rx21VrlzZ6vrbb7+tOnXq6MEHH7S0lS5dWkFBQbnePiYmRvv379eGDRsUGBio5s2b66233tKYMWM0adIkeXl5OTV/AAAAAACAksjuaXdFQXp6upYuXaqBAwfKZDJZ2pctW6ZKlSqpcePGGjdunK5evWrZtnXrVjVp0kSBgYGWtoiICKWkpGjfvn13NH8AAAAAAICSwu6RT7Vq1bIq+Nzs6NGjBUrIFmvWrNGlS5c0YMAAS1ufPn1Uo0YNBQcHa/fu3RozZowOHTqkVatWSZISEhKsCk+SLNcTEhLyvK+0tDSlpaVZrqekpDjwkQAAAAAAABRvdhefRowYYXU9IyNDu3bt0vr16zV69GhH5XVLCxcuVOfOnRUcHGxpGzx4sOXvJk2aqEqVKnr44Yf1+++/q06dOvm+r+nTp2vy5MkFyhcAAAAAAKCksrv4NHz48FzbZ8+ere3btxc4ods5ceKENmzYYBnRlJewsDBJ0pEjR1SnTh0FBQVp27ZtVjGJiYmSlOc6UZI0btw4RUZGWq6npKQoJCQkv+kDAAAAAACUKA5b86lz587673//66ju8rR48WIFBASoa9eut4yLj4+XJFWpUkWS1KZNG+3Zs0dJSUmWmNjYWPn6+qphw4Z59uPt7S1fX1+rCwAAAAAAAGxj98invKxcuVIVKlRwVHe5MpvNWrx4sfr37y8Pj/+l/vvvvysqKkpdunRRxYoVtXv3bo0cOVLt2rVT06ZNJUnh4eFq2LChnn32Wb377rtKSEjQ+PHjNWTIEHl7ezs1bwAAAAAAgJLK7uJTaGio1YLjhmEoISFBZ8+e1Zw5cxya3M02bNigkydPauDAgVbtXl5e2rBhg2bOnKnU1FSFhIToiSee0Pjx4y0x7u7uWrt2rV5++WW1adNGZcqUUf/+/TVlyhSn5gwAAAAAAFCS2V186tGjh9V1Nzc3Va5cWe3bt1eDBg0clVeuwsPDZRhGjvaQkBBt2rTptrevUaOGoqOjnZEaAAAAAAAAcmF38WnixInOyAMAAAAAAADFUL4WHP/99981fvx49e7d27KA99dff619+/Y5NDkAAAAAAAC4NruLT5s2bVKTJk30888/a9WqVbpy5Yok6ddff2VUFAAAAAAAAKzYXXwaO3aspk6dqtjYWHl5eVnaO3TooJ9++smhyQEAAAAAAMC12V182rNnjx577LEc7QEBATp37pxDkgIAAAAAAEDxYHfxyd/fX2fOnMnRvmvXLlWtWtUhSQEAAAAAAKB4sLv49PTTT2vMmDFKSEiQyWSS2WzWjz/+qNdee039+vVzRo4AAAAAAABwUXYXn6ZNm6YGDRooJCREV65cUcOGDdWuXTu1bdtW48ePd0aOAAAAAAAAcFEe9t7Ay8tLCxYs0Jtvvqm9e/fqypUrCg0N1V133eWM/AAAAAAAAODC7C4+ZatevbqqV6/uyFwAAAAAAABQzNhUfIqMjLS5ww8++CDfyQAAAAAAAKB4san4tGvXLps6M5lMBUoGAAAAAAAAxYtNxafvvvvO2XkAAAAAAACgGLL7bHcAAAAAAACArfK14Pj27dv1xRdf6OTJk0pPT7fatmrVKockBgAAAAAAANdn98in5cuXq23btjpw4IBWr16tjIwM7du3T99++638/PyckSMAAAAAAABclN3Fp2nTpunDDz/U//3f/8nLy0sfffSRDh48qF69eql69erOyBEAAAAAAAAuyu7i0++//66uXbtKkry8vJSamiqTyaSRI0dq/vz5Dk8QAAAAAAAArsvu4lP58uV1+fJlSVLVqlW1d+9eSdKlS5d09epVx2YHAAAAAAAAl2Zz8Sm7yNSuXTvFxsZKknr27Knhw4frhRdeUO/evfXwww87J0sAAAAAAAC4JJvPdte0aVPdc8896tGjh3r27ClJeuONN+Tp6aktW7boiSee0Pjx452WKAAAAAAAAFyPzcWnTZs2afHixZo+fbr+8Y9/6IknntCgQYM0duxYZ+YHAAAAAAAAF2bztLsHHnhAixYt0pkzZzRr1iwdP35cDz74oOrVq6d33nlHCQkJzswTAAAAAAAALsjuBcfLlCmj5557Tps2bdJvv/2mnj17avbs2apevboeeeQRZ+QoSZo0aZJMJpPVpUGDBpbt169f15AhQ1SxYkWVLVtWTzzxhBITE636OHnypLp27arSpUsrICBAo0ePVmZmptNyBgAAAAAAKOlsnnaXm7p16+rvf/+7atSooXHjxmndunWOyitXjRo10oYNGyzXPTz+l/7IkSO1bt06rVixQn5+fho6dKgef/xx/fjjj5KkrKwsde3aVUFBQdqyZYvOnDmjfv36ydPTU9OmTXNq3gAAAAAAACVVvotPmzdv1qJFi/Tf//5Xbm5u6tWrl55//nlH5paDh4eHgoKCcrQnJydr4cKFioqKUocOHSRJixcv1t13362ffvpJ9957r2JiYrR//35t2LBBgYGBat68ud566y2NGTNGkyZNkpeXl1NzBwAAAAAAKInsmnZ3+vRpTZs2TfXq1VP79u115MgRffzxxzp9+rQWLFige++911l5SpIOHz6s4OBg1a5dW3379tXJkyclSTt27FBGRoY6duxoiW3QoIGqV6+urVu3SpK2bt2qJk2aKDAw0BITERGhlJQU7du3L8/7TEtLU0pKitUFAAAAAAAAtrF55FPnzp21YcMGVapUSf369dPAgQNVv359Z+ZmJSwsTEuWLFH9+vV15swZTZ48WQ888ID27t2rhIQEeXl5yd/f3+o2gYGBloXQExISrApP2duzt+Vl+vTpmjx5smMfDAAAAAAAQAlhc/HJ09NTK1euVLdu3eTu7u7MnHLVuXNny99NmzZVWFiYatSooS+++EKlSpVy2v2OGzdOkZGRluspKSkKCQlx2v0BAAAAAAAUJzZPu/vqq6/06KOPFkrhKTf+/v6qV6+ejhw5oqCgIKWnp+vSpUtWMYmJiZY1ooKCgnKc/S77em7rSGXz9vaWr6+v1QUAAMCVzZ49WzVr1pSPj4/CwsK0bds2m263fPlymUwm9ejRw7kJAgCAYsWuNZ+KkitXruj3339XlSpV1LJlS3l6eiouLs6y/dChQzp58qTatGkjSWrTpo327NmjpKQkS0xsbKx8fX3VsGHDO54/AABAYfj8888VGRmpiRMnaufOnWrWrJkiIiKsviPl5vjx43rttdf0wAMP3KFMAQBAceEyxafXXntNmzZt0vHjx7VlyxY99thjcnd3V+/eveXn56fnn39ekZGR+u6777Rjxw4999xzatOmjWUR9PDwcDVs2FDPPvusfv31V33zzTcaP368hgwZIm9v70J+dAAAAHfGBx98oBdeeEHPPfecGjZsqHnz5ql06dJatGhRnrfJyspS3759NXnyZNWuXfsOZgsAAIoDm9d8Kmx//PGHevfurfPnz6ty5cq6//779dNPP6ly5cqSpA8//FBubm564oknlJaWpoiICM2ZM8dye3d3d61du1Yvv/yy2rRpozJlyqh///6aMmVKYT0kAACAOyo9PV07duzQuHHjLG1ubm7q2LGj5QzBuZkyZYoCAgL0/PPP6/vvv7/t/aSlpSktLc1ynbMFAwBQsrlM8Wn58uW33O7j46PZs2dr9uzZecbUqFFD0dHRjk4NAADAJZw7d05ZWVm5ngH44MGDud7mhx9+0MKFCxUfH2/z/XC2YAAAcCOXmXYHAACAO+vy5ct69tlntWDBAlWqVMnm240bN07JycmWy6lTp5yYJQAAKOpcZuQTAAAACqZSpUpyd3fP9QzAuZ399/fff9fx48fVvXt3S5vZbJYkeXh46NChQ6pTp06O23l7e7OmJgAAsGDkEwAAQAnh5eWlli1bWp0h2Gw2Ky4uznKG4Bs1aNBAe/bsUXx8vOXyyCOP6KGHHlJ8fLxCQkLuZPoAAMBFMfIJJUpmZqZiYmKUlJSkgIAAhYeHy8ODlwEAoOSIjIxU//791apVK7Vu3VozZ85UamqqnnvuOUlSv379VLVqVU2fPl0+Pj5q3Lix1e39/f0lKUc7AABAXjjqRokRFRWl6Ohoy3SB7LYuXbqoT58+hZgZAAB3zlNPPaWzZ89qwoQJSkhIUPPmzbV+/XrLIuQnT56UmxuD4wEAgOOYDMMwCjsJV5KSkiI/Pz8lJyfL19e3sNOBjaKiorR27Vr5+fmpZ8+eatGihXbu3KkVK1YoOTlZ3bp1owAFAMUMn9lFB/sCAADX4KzPbH7WQrGXmZmp6Oho+fn5adasWerQoYP8/f3VoUMHzZo1S35+foqOjlZmZmZhpwoAAAAAQLFD8QnFXkxMjMxms3r27JljfScPDw89+eSTMpvNiomJKaQMAQAAAAAovig+odhLSkqSJLVo0SLX7aGhoVZxAAAAAADAcSg+odgLCAiQJO3cuTPX7bt27bKKAwAAAAAAjkPxCcVeeHi43NzctGLFihzrOmVmZmrlypVyc3NTeHh4IWUIAAAAAEDxRfEJxZ6Hh4e6dOmi5ORkDRs2THFxcbpw4YLi4uI0bNgwJScnq0uXLjnWgwIAAAAAAAXH0TZKhD59+kiSoqOjtXDhQku7m5ubunXrZtkOAAAAAAAci+ITSow+ffqoV69eiomJUVJSkgICAhQeHs6IJwAAAAAAnIijbpQo2VPwAAAAAADAncGaTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGpcpPk2fPl333HOPypUrp4CAAPXo0UOHDh2yimnfvr1MJpPV5aWXXrKKOXnypLp27arSpUsrICBAo0ePVmZm5p18KAAAAAAAACWGR2EnYKtNmzZpyJAhuueee5SZmam///3vCg8P1/79+1WmTBlL3AsvvKApU6ZYrpcuXdryd1ZWlrp27aqgoCBt2bJFZ86cUb9+/eTp6alp06bd0ceD4uPIkSOaMGGC5fqUKVNUt27dQswIAAAAAICiw2QYhlHYSeTH2bNnFRAQoE2bNqldu3aS/hr51Lx5c82cOTPX23z99dfq1q2bTp8+rcDAQEnSvHnzNGbMGJ09e1ZeXl63vd+UlBT5+fkpOTlZvr6+Dns8uDMyMzMVExOjpKQkBQQEKDw8XB4e+a/B9unTJ89tUVFR+e4XAFBwfGYXHewLAABcg7M+s11m2t3NkpOTJUkVKlSwal+2bJkqVaqkxo0ba9y4cbp69apl29atW9WkSRNL4UmSIiIilJKSon379uV6P2lpaUpJSbG6wDVFRUVpwIABWrp0qWJiYrR06VINGDAg30WiWxWebNkOALCf2WzW/v37tWXLFu3fv19ms7mwUwIAAMBtuMy0uxuZzWaNGDFC9913nxo3bmxp79Onj2rUqKHg4GDt3r1bY8aM0aFDh7Rq1SpJUkJCglXhSZLlekJCQq73NX36dE2ePNlJjwR3SlRUlNauXSs/Pz/17NlTLVq00M6dO7VixQqtXbtWkn3FoiNHjtgcxxQ8AHCMbdu2admyZTp79qylrXLlyurbt69at25diJkBAADgVlxy2t3LL7+sr7/+Wj/88IOqVauWZ9y3336rhx9+WEeOHFGdOnU0ePBgnThxQt98840l5urVqypTpoyio6PVuXPnHH2kpaUpLS3Ncj0lJUUhISEMG3chmZmZGjBggMqVK6dZs2ZZTbPLzMzUsGHDdPnyZS1ZssTmKXj2FKqYfgcABbdt2zZ99NFHCg0N1aOPPqqQkBCdOnVKX375pXbt2qXhw4fnKEAx1avoYF8AAOAamHb3/w0dOlRr167Vd999d8vCkySFhYVJ+t8olaCgICUmJlrFZF8PCgrKtQ9vb2/5+vpaXeBaYmJiZDab1bNnzxzFJQ8PDz355JMym82KiYkppAxdT2ZmpqKjo7VkyRJFR0dzxkgATmU2m7Vs2TKFhobq1Vdf1eHDh7V8+XIdPnxYr776qkJDQ7Vs2TKm4AEAABRRLjPtzjAMDRs2TKtXr9bGjRtVq1at294mPj5eklSlShVJUps2bfSPf/zDsti0JMXGxsrX11cNGzZ0Wu4oXElJSZKkFi1a5Lo9NDTUKg63FhUVpejoaKuDvKioKHXp0oV1rgA4xcGDB3X27FnVq1dPAwcOzPH+06ZNG509e1YHDx7k8xwAAKAIcpni05AhQxQVFaUvv/xS5cqVs6zR5Ofnp1KlSun333+3HABXrFhRu3fv1siRI9WuXTs1bdpUkhQeHq6GDRvq2Wef1bvvvquEhASNHz9eQ4YMkbe3d2E+PDhRdqFx586d6tChQ47tu3btsopD3hy9dparcfTZEgHY5tKlS5KkH3/8Mdf3nx9//NEqDgAAAEWLy0y7mzt3rpKTk9W+fXtVqVLFcvn8888lSV5eXtqwYYPCw8PVoEEDjRo1Sk888YT+7//+z9KHu7u71q5dK3d3d7Vp00bPPPOM+vXrpylTphTWw8IdEB4eLjc3N61YsSLH9LDMzEytXLlSbm5uCg8PL9D9hISEFOj2RV32VDs/Pz/NmjVLHTp0kL+/vzp06KBZs2bJz8+vWE/Bc/TZEgHYrly5cpKkMmXK5Pr+U6ZMGas4AAAAFC0u85P97dZFDwkJ0aZNm27bT40aNRQdHe2otOACPDw81KVLF61du1bDhg3Tk08+qdDQUO3atUsrV65UcnKyunXrVuARLKdOnXJQxkWTLWtnLVy4UDExMerSpUshZekcJX3EF1DYTpw4IUmqWLGi3Nysfzdzc3NTxYoVlZqaqhMnTqhJkyaFkSIAAABuwWWKT0BBZBcGoqOjtXDhQku7m5ubunXrRuHABiV17aybR3xlF946dOigdu3aadiwYYqOjlavXr3yVcDM7bnHaCrA2rlz5yT9VeT/4IMP9Mgjj1jOdvfVV19Ziv/ZcQAAAChaKD6hxOjTp4969epVItfsMZvNOnjwoC5duiR/f381aNAgx+iB2ympa2c5c8RXXkXPPn36UIACbpD9vtKhQwft3r1bkyZNsmyrXLmyOnTooLi4uGL3/gMAAFBcFP+jbuAG2VPwSpJt27bp3//+t86fP29pq1ixop599lm1bt3a5n7Cw8MVFRWlFStWqF27dlaFGEeunVXUOGvE1+1G21GAAv4n+/1n+/bt+uijj3TkyBFLMb1u3boaPnx4sXz/AQAAKC5cZsFxoCj54IMPHBrnLNu2bdPMmTOtCk+SdP78ec2cOVPbtm2zua/swl1ycrKGDRumuLg4XbhwQXFxcRo2bJiSk5PVpUuXYjeS7MYRX7nJz4gvW6d5Mh0U+MuN7z/Dhw/XmTNn1KBBA505c0bDhw8vtu8/AAAAxQXf0oB8CAoKcmicM5jNZn366aeSJF9fX/Xq1cuyUPYXX3yhlJQUffrpp2rVqpXNU/BK4tpZJXXEF1DUlMT3HwAAgOKC4hOQT1FRUbc82CnsKVN79+7VtWvXVKZMGX3yySc5Fsp++eWXlZqaqr1796pp06Y291vS1s66U2dLBHB7Je39BwAAoLjg2xpQAFFRUUpISNDo0aOVlZUld3d3vffee4U64inb999/L0l5LpT9+OOP69///re+//57u4pP2bcvSWtnlfQRF5mZmRzsAwAAAMg3jh6AAgoKCtK///1vh/U3atQonTlzxnK9SpUqmjFjht39pKWlSZIqVaqU6/bKlStbxdmjJBYjSuqIi6ioKEVHR8tsNlu1denSpdgX3VD08HwEAABwTcX7qKkYMZvNOnjwoOXsPg0aNLB5nR64jtwOns6cOZOvM5/Vr19f27dv1xdffKHmzZtbPV/MZrNWrFhhibNHST74c3NzU82aNeXv7y9/f/9i/xqMiorS2rVr5evrq/vvv1+BgYFKTEzUDz/8oLVr10piUXTcOdnPRz8/P/Xs2dOyht2KFSt4PgIAABRxJsMwjMJOwpWkpKTIz89PycnJ8vX1vSP3uW3bNi1btkxnz561tFWuXFl9+/ZV69at70gOyJujCoO2HDTZU4DKzMxU//79ZRiGmjdvrh49eigkJESnTp3SmjVrFB8fL5PJpM8++8zm0Tu3OvjLXvuouB78OfJ1aM//qLDWDsvMzNSAAQPk4+Oj0qVL69y5c5ZtlSpV0tWrV3X9+nUtWbKk2I/+cpTr16/rk08+0dmzZ1W5cmUNHTpUPj4+hZ2WS8h+PpYrV06zZs3KsfD/sGHDdPny5RzPx8L4zEbu2BcAALgGZ31mc8RQxG3btk0fffSRmjVrphYtWigjI0Oenp5KTEzURx99pOHDh1OAKkSOKkiMGjXK5jhbp+B5eHioa9euWrt2rX799VfFx8dbtplMJklS165dbS4cZGZmKjo6Wn5+flYHf9kLmA8bNkzR0dHq1atXsStGbNu2TTNnzpSXl5dVe3JysmbOnKkRI0YUu9dhTEyMzGazrl69qszMTKttKSkpSk9Pt8SVpPW/8mv8+PE6evSo5fqpU6c0cOBA1a5dW1OnTi3EzFxD9vMxrzXsnnzySS1cuJDnIwAAQBFVvI4Qixmz2axly5apcuXK2r17t9U0Jzc3N1WuXFnLli1Tq1ativ30n6IouyDh6elp1X7p0iW7CxI3rvHkiLhs2SNs1q1bl2ObvaOUSurBn9ls1qJFiyRJjRo1yjGCbNeuXVq0aFGxex0mJiZa/s7rcd8ch9zdXHi60dGjRzV+/HgKULeRlJQkSWrRokWu20NDQ63iAAAAULQUnyOlYujgwYM6e/askpKSdPPsSMMwlJSUpLNnz+rgwYOFlGHJdWNBIiMjw2pb9vVFixZZFQzt9eCDD+Y/wRvUrVtXFStWtGqrWLGi6tata1c/JfXgb//+/UpJSVH9+vU1atQo3XXXXfLx8dFdd92lUaNGqV69ekpJSdH+/fsLO1WHyn7PCQwM1MiRI5WRkaGdO3cqIyNDI0eOVEBAgFUccnf9+vU8C0/Zjh49quvXr9+hjFxT9vNt586dMpvN2r9/v7Zs2aL9+/fLbDZbiqHZcQAAAChaGPlUhN24xkqzZs302GOPWUYerF692jKN6sY43BnZBYlbyS5ING7c2K6+p0yZYikMvfjiizpy5IgmTJiQrzyzp22GhoZq2LBhlufPl19+afe0zRsP/jp06JBje3E9+MsuKj3xxBOW6zeu7/XEE09o+vTp+drXRVnp0qUlSRcvXtSIESN04cIFy7YKFSroypUrVnHI3Ycffmhz3Lhx45ycjesKDw9XVFSUoqKitHr1ap0/f96yrWLFirp27Zrc3NwUHh5eiFkCAAAgLxSfirAjR45I+mvkwYgRI7Rhwwb9+OOPCggI0IgRI/T6668rKSlJR44cUbt27Qo5W+fIbVpYYS3AfKO9e/faHGdvQWLlypUaO3as1fX8yJ62GRoaqqFDhyoqKkqJiYkKDAzU0KFD9cknn9g1bTP74G/FihVq27atvv32WyUlJSkgIEAdOnTQypUri9TBn6PPEHno0CHNnTtXFy9etLSVL19eDz30kCPSLXKy/1fp6elWhSdJVteL01RDZ9izZ49D40oqDw8PhYaGaseOHUpLS1PZsmWVlZUld3d3Xbp0SVlZWWrZsmWxW28OAACguOBbmhM46qA3+yD32rVrGjhwYI5T25ctW9YqrrDydJa81iPq06dPoRegbjeNxt64G+3evdshZ4zLnrZZoUIFDRw40NK+Z88ebdiwQfXr17dM22zYsOFt+/Pw8FCXLl20du1aq/4kaenSpZL+WkeqKBz8OfLMdA0bNtSaNWv03//+N8e2ixcvatWqVZa44qRBgwYOjQMKwmw26+TJkzKZTMrKyrKMvMtmMpl08uRJmc3mIvU5VpTNnj1b7733nhISEtSsWTPNmjUrz/fHBQsW6F//+pflh5eWLVtq2rRpxe5ECwAAwHkK/yixmHHkQW/2Kbhzm95lNpst7fk5Vbcj83SG2xVf8luAclTB7dq1aw6Nc4ZLly5J+mvETm6y27PjiovsqYYNGzZUenq6rl+/Lh8fHwUEBOTrDJHOKMLUqFFDJ06csCnOXkW9qIySJzMzUzExMZaRkuHh4XYXqbOL6dkqVqxoeR2dP39ehmHYVUwv6T7//HNFRkZq3rx5CgsL08yZMxUREaFDhw7lOnV648aN6t27t9q2bSsfHx+98847Cg8P1759+1S1atVCeAQAAMDVUHxyoOyD3psX4D179my+DnrbtGmjH3/80aa4/OSZPR2rIOsAOYOto37sLUA5suB286nnCxo3ZcoUm9Z1mjJlik39SVKZMmUcGpeZmZnrWfNutG7dOvXq1avQRj9lTzU0mUzat2+fpT0tLU3Jyclyc3Oz+wyRu3fvtjkur8XYb5aVleXQuGzbtm3TZ599lmNqYP/+/e1+jtt6IoODBw+qadOmdvXtDEV1im5JFxUVpejo6Bwjd7t06WLXCM/Tp09b/p4/f75l5K8kXblyRYMHD7bEUXy6vQ8++EAvvPCCnnvuOUnSvHnztG7dOi1atMhq2ne2ZcuWWV3/5z//qf/+97+Ki4tTv3797kjOAADAtfFzuINkH/TmdeYnwzC0bNkyu85+ZsvICHviJOt1gF555RV9+eWXmjhxor788ku98sorCg0NtTtPV5BdcAsJCdHkyZO1aNEiTZ48WSEhIfroo4+0bds2u/qztXBha5ytZ56z5wx127dvd2jc+vXrb3tmM8MwtH79epv6u1luZ7CyV/boiLxuazab7T5D5IoVKxwaJ9k+2syeUWnbtm3TzJkzc0zDvXjxombOnGn3c9zW/39ReK+41RTd4iwzM1PR0dFasmSJoqOjbS523ylRUVFau3atypUrp0GDBmnOnDkaNGiQypUrp7Vr19pVHPzqq68kSVWrVpWXl5cWLVqk6dOna9GiRfLy8lJwcLBVHPKWnp6uHTt2qGPHjpY2Nzc3dezYUVu3brWpj6tXryojI0MVKlRwVpoAAKCYYeSTg9w8JSA39k4J+O6772yOe+yxx2yKzc7T09NTgwYNsrSfOnVKgwYNUnBwcL6nLqSnp2vp0qWWRa2feeYZeXl52dWHM9xYcIuMjLQUhO666y5FRkbqgw8+sHs0zMmTJx0aJ0kjRozQzJkzb7ndHocPH3ZonK0HJVu3blW3bt1sis22bds2LV261OrMjZUqVdIzzzxj14gde/aLrc/vpKQkh8ZJyrFeTUHjzGbzLZ87kjRz5kwtXbrU5uf45cuXHRrnLEV9iq6zOGpEkbNkF8b8/Pz04Ycf6ttvv9WaNWsUEBCgDz/8UCNHjlR0dLTNIyWzpzBfvHhRAwYMsLRnr2FXqlQpqzjk7dy5c8rKylJgYKBVe2BgoM2F+TFjxig4ONiqgHWztLQ0paWlWa7f7gyxAACgeKP45CBTp061Oc7WA6HU1FSHxkn/G0lx4xSGG2W327sO0IwZM7Rjxw7L9ewDgpYtW2rUqFF29eVo2QW3oUOH6plnnsmxfdKkSZo0aZJdBTdHT5sym81atGjRLWMWLVpkV4Hsjz/+cGicMwpu0v9G7NxcqExJSdHMmTM1YsQImwtQq1evtjmuU6dONsWmp6c7NM4ZbB3VtG3bNt177702xTprf0t/FepGjx6tjIwMeXp66r333st1nZnbceYU3X//+986f/68pa1ixYp69tlni8SaeNkjinx9fXX//fcrMDBQiYmJ+uGHH7R27VpJ+R/15agfEWJiYmQ2m1WjRg0NGjQoR5GsUaNG2rNnj2JiYtSlS5fb9ufv76/U1FRdvXo11+3ZRSd/f3+7c4V93n77bS1fvlwbN2685ZqT06dP1+TJk+9gZgAAoCgrOj/jIgdPT0+HxklS6dKlHRon5Sw83WjHjh2aMWOGzX05Q3YhbeLEiblunzRpklVcYdi/f/9tfxVOSUnR/v37be7T0dOmnDEN68ai283Fm+zrixYtsrlPZ4zWcdb6TI708ccfOzROcs60X0nq27evRowYoYyMDElSRkaGRowYob59+9rVj7NkF0NvLDxJ0vnz5/M1fdHRskcUlS5dWikpKYqOjtbixYsVHR2tlJQUlS5dOt9T8GbMmKEBAwZow4YNlh8QBgwYkK/38OyRgLt3787x+jWbzdqzZ49V3O2MGzfOoXElWaVKleTu7q7ExESr9sTERAUFBd3ytu+//77efvttxcTE3Hatt3Hjxik5OdlyOXXqVIFzBwAArqvEFp9mz56tmjVrysfHR2FhYYV+QJEbW4eo2zOU/ZtvvnFoXPbaEbeyY8eOQh0VYusv4YX5i/mNi2M7Is4ZHL3OleScohscw9GL6kt/FZ5utS5eYRegbJ2+WJjrXGWPKMprBNDVq1dlNpsVExNjV7+O/hGhUqVKDo374osvHBpXknl5eally5aKi4uztJnNZsXFxd3yBCbvvvuu3nrrLa1fv16tWrW67f14e3vL19fX6gIAAEquEll8yj7F8MSJE7Vz5041a9ZMERERdq3Z4qp+/fVXh8bduPaGI+KcwZ4pkYXlyy+/dGicMzhjBJArFN3gGElJSTYtWF+Y78OOXqTfGW4erVLQOMk5PyI4eqTk5s2bHRpX0kVGRmrBggX67LPPdODAAb388stKTU21nP2uX79+VqPI3nnnHb355ptatGiRatasqYSEBCUkJNi8Lh0AAECJLD7deIrhhg0bat68eSpduvRt19wB4FiuUHSDY9i6YL69C+s70u1GPdkb5wyxsbEOjZOc8yPC8uXLHRoHx3rqqaf0/vvva8KECWrevLni4+O1fv16yyLkJ0+e1JkzZyzxc+fOVXp6up588klVqVLFcnn//fcL6yEAAAAXU+IWHM/+hffGX/TsPcUwAADFVeXKlfX0009r+fLltz2LK1zX0KFDNXTo0Fy3bdy40er68ePHnZ8QAAAo1kpc8cneUwzf6lTBx48ft/lMYTfasGGD5Qwx1apVU82aNQvc5w8//HDb/q5fv+7wPm8WFBSkGjVq6MSJE0pISChwf87IMT/9OaPPkpCjM/p0VH/F+XV4J/vLT5/lypVTgwYNVLZsWV25ckUHDx60WgSe57h9/VWqVEnnzp3L0Z6f5/gDDzwgb29vHThwQM2aNVNaWpq+//57u3LM7TletmxZlS5dWlevXs0xVcuZz/EKFSrYfXsAAAA4nsm43SIcxczp06dVtWpVbdmyxWphzddff12bNm3Szz//bBU/adKkXE8VnJycrJkzZ+ZasLJHgwYNNGHCBMv1KVOmFKhPR/dHjv9T1B63K+TojD7JseTm6Iw+XeFxk2P++xsxYoT8/PyUnJzMgteFLCUlhX0BAIALcNZndokrPqWnp6t06dJauXKlevToYWnv37+/Ll26lGNtmdxGPoWEhCg5OVkXLlyw/Co7Z84cm3MYOHCgTb9G29PnK6+8ctv+rl+/bte6Vrb06egcndGnI/pzRp8lIUdn9Omo/ngdFu7r0M3NTTVr1tTx48dzLDrNc9z2/qpVqyaz2Sw3N7cco4Ty+xyvUaOGgoODdfr0aZ04ccLuHIvSc7xChQoUPIoIik8AALgGik8OFBYWptatW2vWrFmS/jrbTvXq1TV06FCNHTv2lrfNa0f06dPH5vuPioqyKc4V+iRHx/RJjo7p0xVydEaf5OiYPsmx6PaZ3/4oeBQd7AsAAFyDsz6zS+TZ7m53imEAOX388ccOjUPJYuv7K+/Dd56to4rsGX3UrFkzh8YBAADAtZXI4tPtTjGcH48//rhD45wlICDAoXG2Tq2wZwoGiqZKlSrJze3Wbxlubm6qVKnSHcoIruThhx92aJwk+fv7OzTOFUyZMsWhcdJf/x8vL69bxnh5edn1fxw+fLhD4wAAAODaSmTxSfrrFMMnTpxQWlqafv75Z4WFhRWovxvXj3JEnLM0btzYoXE+Pj6qXbv2LWNq165tWXekMNh634WZozPcrlBkb5wkLV26NM94Nzc3LV261Oa+nKEkFiNchZubm0aMGHHLmBEjRtj1fGzRooVD45zxmnG0unXrOjQu25IlS/IsQHl5eWnJkiV29ecKnw0AAAC4c0ps8cnRPDw81K1bt1vGdOvWTR4eHncoo9z169fPoXGSNHXq1DwPMmrXrq2pU6fa3Jcz2Hpqe1vjXEXVqlUdGpdt6dKl+vjjj+Xt7S2TySRvb299/PHHhV54kqR69eo5NM5VuEqBtXXr1hoxYoTKlStn1e7r66sRI0aodevWdvXn6Pez243+sTfOWW63RpKt6zLdbMmSJZozZ458fX3l4eEhX19fzZkzx+7CU7ai/tkAAACAO6dwKyHFTPaCqGvXrrVqN5lM6tq1q10LpjqLl5eXWrZsqR07duQZ07JlS7sPrqZOnarr16/rk08+0dmzZ1W5cmUNHTo0Xwe7Pj4+NhWCCvtAuqhr27atPv/8c5vi7FWpUiUtXrw4P2k5laenp0PjXMUHH3xgdfa1W8XZqlSpUrp27ZpNcfZo3bq1WrVqpYMHD+rSpUvy9/dXgwYN8jWayNHvZxUqVNDp06dtiitsUVFROnLkiCZMmGBpmzJlit0jnm7m7++vefPmFTQ9C0d+NgAAAMB1UXxysD59+qhXr16KiYlRUlKSAgICFB4eXugjnm40atQozZgxI9cDtpYtW2rUqFH56tfHx0evvfZaQdPT+++/r6FDh9oUh7xVrFjRoXGuwNb1porbulTZa/akp6fnGWPvmj1hYWHauHGjTXH2cnNzU8OGDe2+XW4c+X5Wo0YNm4pPNWrUsCtHZ6lbt26+RzndSY74bChbtqyuXLliUxwAAACKnqJTESlGPDw81KVLl8JO45ZGjRql9PR0LV26VImJiQoMDNQzzzxT6NNJpL9GFXh4eCgzMzPPGA8PjyIx+qAos/X/U5j/x4cfflhxcXE2xdmiUaNG+vLLLyUpx3PoxuuNGjXKR7ZF25IlSzRgwIBcC1D5WbMnJCTEoXHO5Kj3s/bt22vr1q02xeHOevLJJ216Dj/55JPOTwYAAAB2o/hUgnl5eWngwIGFnUau/vWvf6lfv365FqA8PDz0r3/9qxCyci3VqlVzaJwzOPrsiw0bNpSvr69SUlLyjPH19bVr1I27u7uysrJsiitsS5Ys0aVLlzR27FhdvXpVpUuX1ttvv52vBdb//e9/2xzXuXNnu/t3NEe8nzVq1Oi20w1Lly5dLIuXRd2JEyccGgcAAIA7i+ITiqx//etfunDhgl5//XVdv35dPj4+evfddxnxZKMbT7XerFkzhYaGWqZm7dq1S7/++qslrrCmMF69etWhcW5ubho4cKBmzpyZYw2h7OsDBw60a30hHx8fpaam2hRXFDh6zZ6SxM3NTS+++KJmzpyZZ8zgwYML9Wx3JVX2+5Wj4gAAAHBnUXxCkVahQgX985//LOw0cihTpoxNBYkyZcrcgWxyl5iYKOmvaVGnT5+2OiirXLmyqlatqj///NMSVxhMJpPl71tNk7sx7nayz6i2bNkynT171tLu5+envn372n1GtSpVqujIkSM2xRVX5cqVU7Vq1WQYhkwmk/744w9dvny5sNNyiuznz9KlS3Xu3DlLe+XKlfP1/IFjXLp0yaFxAAAAuLMoPqHY8/b2Vlpamk1xtgoODtbhw4dtiisKPvzwwxxnFxszZkxhp6WGDRtqzZo1Cg4OVnp6utXBfvYi2qdPn7Z7cWpHnlHtnnvusan4dM8999jdt6sIDAzUU089pZCQEJ06dUpLly4ttsUnybHPHziGYRiWv00mU57Xb2wHAABA0UHxCcXee++9p1dffdWmOFu1bNnSpuJTy5Ytbe7T0e6++27t3btXp06d0tWrV60KOFeuXNGff/5piSss2Ws0nT59Ws2bN1e3bt0sUwPj4+MVHx9v9xpN2Rx1RrWIiAj95z//sSmuOLnxgP7IkSOaNGlSnnHFkaOeP660ZlhRVqFCBZ0/f17SX+tuPfjggwoICFBSUpI2bdpkGYnKtGwAAICiieITir1KlSrJzc1NZrM5zxg3NzdVqlTJ5j6rV6/u0DhniIyMtCzAPHjwYNWuXVtPPvmkVq5cqaNHj1rFFZYb12jav3+/4uPjLduyz1Rm7xpNjvbbb7/ZHNe4cWMnZ3Pn1KhRQ8ePH7cpDnn78MMPbSp+f/jhh3cgG9fVpEkTbdy4UZKUmpqq6OjoPOMAAABQ9DCHACXC0qVL8yxguLm5aenSpXb1Z09BorD4+Piodu3alutHjx7Vu+++a1V4ql27dqEvlJ29xo6fn59Vu5+fn0aMGFHoa+zs27fPoXGuom3btg6NK6myi9+3Ym/xuyTy9PR0aBwAAADuLEY+ocTIXkB49OjRSk9Pl5eXl957770CHfSFhYXpl19+sRpV5ebmplatWmnbtm2OSLtApk6dqvHjx1sVnLLVrl1bU6dOLYSscirKa+xkL1ru7e2tuXPn6ttvv1VSUpICAgLUoUMHvfzyy0pLS7Na3Px2WrRooZ07d9oUV1g6deqk//znP7dcQ8dkMqlTp053MCvXtHTpUj3zzDO5jr7MT/G7JAoMDHRoHAAAAO4sik8oUSpVqqTFixcXuJ/shbIvXbqkRYsWacOGDZaCRMeOHTVt2jRLXGGbOnWqrl+/rk8++URnz55V5cqVNXTo0EIf8XQzR62x42jJycmS/hqJ5eXlpS5duli2mc1m+fr66uzZs5Y4W7hC8cnDw0Ndu3bV2rVr84zp2rWrPDz4GLGFM4rfJUl4eLiioqLk4+MjT09Pq9ebv7+/0tPTdf36dYWHhxdilgAAAMgLRw1APmQvlH3o0CF99NFHevTRR/XQQw/p1KlT+uijj/Tbb7/ZtVB2mTJlLAvm3i4uP3x8fPTaa6/l67YlXXaRLikpSTNmzNCjjz5qOevbl19+aRnxZE8xz5bCU3Zchw4d7E/aQfr06SNJio6OzjG6r0uXLpbtsI2jit8lkYeHh7p06aK1a9fK19dXXbp0sSw4/sMPP+jq1avq1q0bxVAAAIAiim9pQD7cuFD23r17tWvXLsu27DVH7Fkou379+jYVJOrXr5+/hJFv9evX144dOyT9ta7Tjfs6e1H07DhbpaenS5IqVqxoOYPXjbLbs+MKU58+fdSrVy/FxMRYRveFh4dzkI877sZi6I0Ljru5ualbt24UQwEAAIowjh6AfGrdurW6deuWY1pSRkaGunXrZtdC2UOHDrWcme52cbizblz76Ob1j7Kv27v2UVBQkPbu3avz58+refPmCgwMVEZGhjw9PZWYmGg5619QUJDDHkdBZI86AQobxVAAAADXxLc1IJ+2bduW53o4a9euVd26dW0uQGWfmS63hcGzFYUz05VEN659lJGRYbUt+7q9ax8988wz2rBhg9zc3PTHH39Yik2SVLlyZbm5uclsNuuZZ55xyGMAihOKoQAAAK6n8E8lBbggs9msOXPm3DJmzpw5uZ7dKi9Tp05V7dq1c91WlM5MVxL16dNH3bp1k8lksmo3mUz5mu7j5eWlli1bymw26+LFi7r33nvVt29f3Xvvvbpw4YLMZrNatmxpNa0PAAAAAFwVI5+AfNi9e7dlPZ4yZcrowQcfVGBgoBITE7Vp0yalpqYqPT1du3fvVvPmzW3u11XOTFcSOXq6z6hRozRjxgzt2LFDP/30k3766SfLtpYtW2rUqFGOSh0AAAAAChXFJyAf1q1bJ0lyd3dXqVKlrBa/rVSpkq5fv66srCytW7fOruKTxJnpijJHT/cZNWqU0tPTtXTpUiUmJiowMFDPPPMMI54AAAAAFCsUn4B8OHPmjCQpKytLKSkpVttSUlKUlZVlFQfkxcvLy6bF5gEAAADAVVF8AvKhVKlSlr8bNmyoxx57TCEhITp16pRWr15tWUD6xjgAAAAAAEoiFhwH8qFOnTqWv81mswzDsFxuXGT8xjgAAAAAAEoilyg+HT9+XM8//7xq1aqlUqVKqU6dOpo4caJlwefsGJPJlONy4yK+krRixQo1aNBAPj4+atKkidVaPYCt/P39LX/v3r1bkyZN0vPPP69JkyZp9+7ducYBAAAAAFASucS0u4MHD8psNuvTTz9V3bp1tXfvXr3wwgtKTU3V+++/bxW7YcMGNWrUyHK9YsWKlr+3bNmi3r17a/r06erWrZuioqLUo0cP7dy5U40bN75jjweuz83NtrqtrXEAAAAAABRXLnFk3KlTJy1evFjh4eGqXbu2HnnkEb322mtatWpVjtiKFSsqKCjIcvH09LRs++ijj9SpUyeNHj1ad999t9566y21aNFCn3zyyZ18ODa7MXdHxMFxGjZsKEkqX758rtuz27PjAAAAAAAoqVxi5FNukpOTVaFChRztjzzyiK5fv6569erp9ddf1yOPPGLZtnXrVkVGRlrFR0REaM2aNXneT1pamtLS0izXbz6zmTPVqFFDR44csSkOd1bDhg3l6+urixcvqnnz5goMDFRGRoY8PT2VmJio+Ph4+fr6UnwCAAAAAJR4LjHy6WZHjhzRrFmz9OKLL1raypYtqxkzZmjFihVat26d7r//fvXo0UNfffWVJSYhIUGBgYFWfQUGBiohISHP+5o+fbr8/Pwsl5CQEMc/oDy89tprDo2D47i5uWngwIGSpP379+ubb77Rt99+q2+++Ub79++XJA0cOJBpdwAAAACAEq9Qj4zHjh2b6yLhN14OHjxodZs///xTnTp1Us+ePfXCCy9Y2itVqqTIyEiFhYXpnnvu0dtvv61nnnlG7733XoFyHDdunJKTky2XU6dOFag/e/zwww8OjYNjtW7dWiNGjJCvr69Vu6+vr0aMGKHWrVsXUmYAAAAAABQdhTrtbtSoURowYMAtY2rXrm35+/Tp03rooYfUtm1bzZ8//7b9h4WFKTY21nI9KChIiYmJVjGJiYkKCgrKsw9vb295e3vf9r6cISkpSdJfhbVz587l2J7dnh2HO69169Zq1aqVDh48qEuXLsnf318NGjRgxBMAAAAAAP9foRafKleurMqVK9sU++eff+qhhx5Sy5YttXjxYpsO7uPj41WlShXL9TZt2iguLk4jRoywtMXGxqpNmzZ2534nBAQESJJ69Oihe++9V++8847Onz+vihUrasyYMdq6dasWLlxoiUPhcHNzY20nAAAAAADy4BILjv/5559q3769atSooffff19nz561bMsetfTZZ5/Jy8tLoaGhkqRVq1Zp0aJF+uc//2mJHT58uB588EHNmDFDXbt21fLly7V9+3abRlEVhvDwcEVFRWnFihVq166dJk+ebNmWmZmplStXys3NTeHh4YWYJQAAAAAAQN5covgUGxurI0eO6MiRI6pWrZrVNsMwLH+/9dZbOnHihDw8PNSgQQN9/vnnevLJJy3b27Ztq6ioKI0fP15///vfddddd2nNmjVq3LjxHXss9vDw8FCXLl20du1aDRs2TE8++aRCQ0O1a9curVy5UsnJyerWrZs8PFxiNwIAAAAAgBLIZNxYvcFtpaSkyM/PT8nJyTkWmnaWqKgoRUdHy2w2W9rc3NzUpUsX9enT547kAACAqymMz2zkjn0BAIBrcNZnNkNmXECfPn3Uq1cvxcTEKCkpSQEBAQoPD2fEEwAAAAAAKPKoXriI7Cl4AAAAAAAAroTzwQMAAAAAAMBpKD4BAACUMLNnz1bNmjXl4+OjsLAwbdu27ZbxK1asUIMGDeTj46MmTZooOjr6DmUKAACKA4pPAAAAJcjnn3+uyMhITZw4UTt37lSzZs0UERGhpKSkXOO3bNmi3r176/nnn9euXbvUo0cP9ejRQ3v37r3DmQMAAFfF2e7sxNlaAABwDXxm5y4sLEz33HOPPvnkE0mS2WxWSEiIhg0bprFjx+aIf+qpp5Samqq1a9da2u699141b95c8+bNs+k+2RcAALgGznZXRGTX6lJSUgo5EwAAcCvZn9X8zvY/6enp2rFjh8aNG2dpc3NzU8eOHbV169Zcb7N161ZFRkZatUVERGjNmjV53k9aWprS0tIs15OTkyXx/QkAgKLOWd+fKD7Z6fLly5KkkJCQQs4EAADY4vLly/Lz8yvsNIqEc+fOKSsrS4GBgVbtgYGBOnjwYK63SUhIyDU+ISEhz/uZPn26Jk+enKOd708AALiG8+fPO/T7E8UnOwUHB+vUqVMqV66cTCZTnnEpKSkKCQnRqVOnHDZUzRX6JEdyLEp9ukKOzuiTHMmxuPdpa3+GYejy5csKDg4u8H3CPuPGjbMaLXXp0iXVqFFDJ0+epBBYyJzxGof92A9FB/ui6GBfFA3JycmqXr26KlSo4NB+KT7Zyc3NTdWqVbM53tfX1+EvHFfokxyLZn/O6JMci26f5Fg0+3NGn66QozP6tKU/Ch3WKlWqJHd3dyUmJlq1JyYmKigoKNfbBAUF2RUvSd7e3vL29s7R7ufnxwFFEeGM1zjsx34oOtgXRQf7omhwc3Ps+ek42x0AAEAJ4eXlpZYtWyouLs7SZjabFRcXpzZt2uR6mzZt2ljFS1JsbGye8QAAADdj5BMAAEAJEhkZqf79+6tVq1Zq3bq1Zs6cqdTUVD333HOSpH79+qlq1aqaPn26JGn48OF68MEHNWPGDHXt2lXLly/X9u3bNX/+/MJ8GAAAwIVQfHISb29vTZw4Mdch58W5T3Ikx6LUpyvk6Iw+yZEci3ufzsixJHnqqad09uxZTZgwQQkJCWrevLnWr19vWVT85MmTVkPt27Ztq6ioKI0fP15///vfddddd2nNmjVq3LixzffJPis62BdFA/uh6GBfFB3si6LBWfvBZHD+YQAAAAAAADgJaz4BAAAAAADAaSg+AQAAAAAAwGkoPgEAAAAAAMBpKD4BAAAAAADAaSg+Ocns2bNVs2ZN+fj4KCwsTNu2bct3X5s3b1b37t0VHBwsk8mkNWvWFCi36dOn65577lG5cuUUEBCgHj166NChQwXqc+7cuWratKl8fX3l6+urNm3a6Ouvvy5Qnzd6++23ZTKZNGLEiHz3MWnSJJlMJqtLgwYNCpTXn3/+qWeeeUYVK1ZUqVKl1KRJE23fvj3f/dWsWTNHjiaTSUOGDMlXf1lZWXrzzTdVq1YtlSpVSnXq1NFbb72lgp5n4PLlyxoxYoRq1KihUqVKqW3btvrll19svv3tntOGYWjChAmqUqWKSpUqpY4dO+rw4cP57m/VqlUKDw9XxYoVZTKZFB8fX6AcMzIyNGbMGDVp0kRlypRRcHCw+vXrp9OnT+c7x0mTJqlBgwYqU6aMypcvr44dO+rnn3/Od443e+mll2QymTRz5sx89zdgwIAcz81OnToVOMcDBw7okUcekZ+fn8qUKaN77rlHJ0+ezHefub2GTCaT3nvvvXz1d+XKFQ0dOlTVqlVTqVKl1LBhQ82bN69AjzsxMVEDBgxQcHCwSpcurU6dOt3yOW7L+/b169c1ZMgQVaxYUWXLltUTTzyhxMTEfPc3f/58tW/fXr6+vjKZTLp06dItH/Pt+rxw4YKGDRum+vXrq1SpUqpevbpeffVVJScn5zvHF198UXXq1FGpUqVUuXJlPfroozp48OAt84Tz2PvdZ8WKFWrQoIF8fHzUpEkTRUdH36FMiz979sWCBQv0wAMPqHz58pbPn4J8b8X/5Pd4YPny5TKZTOrRo4dzEyxB7N0Xly5d0pAhQ1SlShV5e3urXr16vEc5gL37YebMmZbvDSEhIRo5cqSuX79+h7ItvvJTX9i4caNatGghb29v1a1bV0uWLLH7fik+OcHnn3+uyMhITZw4UTt37lSzZs0UERGhpKSkfPWXmpqqZs2aafbs2Q7Jb9OmTRoyZIh++uknxcbGKiMjQ+Hh4UpNTc13n9WqVdPbb7+tHTt2aPv27erQoYMeffRR7du3r8D5/vLLL/r000/VtGnTAvfVqFEjnTlzxnL54Ycf8t3XxYsXdd9998nT01Nff/219u/frxkzZqh8+fL57vOXX36xyi82NlaS1LNnz3z1984772ju3Ln65JNPdODAAb3zzjt69913NWvWrHznKEmDBg1SbGys/v3vf2vPnj0KDw9Xx44d9eeff9p0+9s9p9999119/PHHmjdvnn7++WeVKVNGEREReX7Y3K6/1NRU3X///XrnnXdse4C36fPq1avauXOn3nzzTe3cuVOrVq3SoUOH9Mgjj+SrP0mqV6+ePvnkE+3Zs0c//PCDatasqfDwcJ09ezbffWZbvXq1fvrpJwUHB98yzpb+OnXqZPUc/c9//lOgPn///Xfdf//9atCggTZu3Kjdu3frzTfflI+PT777vDG/M2fOaNGiRTKZTHriiSfy1V9kZKTWr1+vpUuX6sCBAxoxYoSGDh2qr776Kl85GoahHj166OjRo/ryyy+1a9cu1ahRQx07dszzfdiW9+2RI0fq//7v/7RixQpt2rRJp0+f1uOPP57v/q5evapOnTrp73//e56P054+T58+rdOnT+v999/X3r17tWTJEq1fv17PP/98vnNs2bKlFi9erAMHDuibb76RYRgKDw9XVlaWTTnDcez97rNlyxb17t1bzz//vHbt2qUePXqoR48e2rt37x3OvPixd19s3LhRvXv31nfffaetW7cqJCRE4eHhNn+mI3f5PR44fvy4XnvtNT3wwAN3KNPiz959kZ6err/97W86fvy4Vq5cqUOHDmnBggWqWrXqHc68eLF3P0RFRWns2LGaOHGiDhw4oIULF+rzzz+3+XsJ8mZvfeHYsWPq2rWrHnroIcXHx2vEiBEaNGiQvvnmG/vu2IDDtW7d2hgyZIjlelZWlhEcHGxMnz69wH1LMlavXl3gfm6UlJRkSDI2bdrk0H7Lly9v/POf/yxQH5cvXzbuuusuIzY21njwwQeN4cOH57uviRMnGs2aNStQPjcaM2aMcf/99zusv9wMHz7cqFOnjmE2m/N1+65duxoDBw60anv88ceNvn375junq1evGu7u7sbatWut2lu0aGG88cYbdvd383PabDYbQUFBxnvvvWdpu3TpkuHt7W385z//sbu/Gx07dsyQZOzatatAOeZm27ZthiTjxIkTDukvOTnZkGRs2LChQDn+8ccfRtWqVY29e/caNWrUMD788MN899e/f3/j0Ucften2tvb51FNPGc8884xD+7zZo48+anTo0CHf/TVq1MiYMmWKVZs9z/eb+zx06JAhydi7d6+lLSsry6hcubKxYMECm/q8+X370qVLhqenp7FixQpLzIEDBwxJxtatW+3u70bfffedIcm4ePGiTbnZ0me2L774wvDy8jIyMjIc0t+vv/5qSDKOHDliV64oOHu/+/Tq1cvo2rWrVVtYWJjx4osvOjXPkqCg30MzMzONcuXKGZ999pmzUiwR8rMfMjMzjbZt2xr//Oc/C/yZi/+xd1/MnTvXqF27tpGenn6nUiwR7N0PQ4YMyfH9LTIy0rjvvvucmmdJY8t36ddff91o1KiRVdtTTz1lRERE2HVfjHxysPT0dO3YsUMdO3a0tLm5ualjx47aunVrIWaWt+wpDxUqVHBIf1lZWVq+fLlSU1PVpk2bAvU1ZMgQde3a1er/WRCHDx9WcHCwateurb59+95yas/tfPXVV2rVqpV69uypgIAAhYaGasGCBQ7JU/rrubR06VINHDhQJpMpX320bdtWcXFx+u233yRJv/76q3744Qd17tw533llZmYqKysrx8iUUqVKFWgkWbZjx44pISHBap/7+fkpLCysyL6GpL9eRyaTSf7+/gXuKz09XfPnz5efn5+aNWuW737MZrOeffZZjR49Wo0aNSpwXtJfv5AHBASofv36evnll3X+/PkC5bdu3TrVq1dPERERCggIUFhYWIGnFt8oMTFR69aty3N0jS3atm2rr776Sn/++acMw9B3332n3377TeHh4fnqLy0tTZKsXkNubm7y9va2+TV08/v2jh07lJGRYfW6adCggapXr27T68bRnwO29pmcnCxfX195eHgUuL/U1FQtXrxYtWrVUkhISD4yRn7l57vP1q1bc3y2R0REFOn3eVfgiO+hV69eVUZGhkPfD0qa/O6HKVOmKCAgoECfWbCWn33x1VdfqU2bNhoyZIgCAwPVuHFjTZs2jVG1BZCf/dC2bVvt2LHDMjXv6NGjio6OVpcuXe5IzvgfR31mU3xysHPnzikrK0uBgYFW7YGBgUpISCikrPJmNps1YsQI3XfffWrcuHGB+tqzZ4/Kli0rb29vvfTSS1q9erUaNmyY7/6WL1+unTt3avr06QXKK1tYWJhlmsfcuXN17NgxPfDAA7p8+XK++jt69Kjmzp2ru+66S998841efvllvfrqq/rss88cku+aNWt06dIlDRgwIN99jB07Vk8//bQaNGggT09PhYaGasSIEerbt2+++yxXrpzatGmjt956S6dPn1ZWVpaWLl2qrVu36syZM/nuN1v268RVXkPSX2vtjBkzRr1795avr2+++1m7dq3Kli0rHx8fffjhh4qNjVWlSpXy3d8777wjDw8Pvfrqq/nu40adOnXSv/71L8XFxemdd97Rpk2b1Llz53x/GUtKStKVK1f09ttvq1OnToqJidFjjz2mxx9/XJs2bXJIzp999pnKlSuX5/QzW8yaNUsNGzZUtWrV5OXlpU6dOmn27Nlq165dvvrLLgqNGzdOFy9eVHp6ut555x398ccfNr2GcnvfTkhIkJeXV47ipy2vG0d+DtjT57lz5/TWW29p8ODBBepvzpw5Klu2rMqWLauvv/5asbGx8vLycsjjgG3y890nISHBpd7nXYUjvoeOGTNGwcHBDvvhryTKz3744YcftHDhQof+kIn87YujR49q5cqVysrKUnR0tN58803NmDFDU6dOvRMpF0v52Q99+vTRlClTdP/998vT01N16tRR+/btmXZXCPL6zE5JSdG1a9ds7uf2PzWiWBsyZIj27t3rkBEr9evXV3x8vJKTk7Vy5Ur1799fmzZtylcB6tSpUxo+fLhiY2NvufaLPW4c7dO0aVOFhYWpRo0a+uKLL/L1C5PZbFarVq00bdo0SVJoaKj27t2refPmqX///gXOd+HChercufNt1+m5lS+++ELLli1TVFSUGjVqZJmjGxwcXKAc//3vf2vgwIGqWrWq3N3d1aJFC/Xu3Vs7duzId5+uKiMjQ7169ZJhGJo7d26B+sqeR33u3DktWLBAvXr10s8//6yAgAC7+9qxY4c++ugj7dy5M98j52729NNPW/5u0qSJmjZtqjp16mjjxo16+OGH7e7PbDZLkh599FGNHDlSktS8eXNt2bJF8+bN04MPPljgnBctWqS+ffsW6H1k1qxZ+umnn/TVV1+pRo0a2rx5s4YMGZLvgzNPT0+tWrVKzz//vCpUqCB3d3d17NhRnTt3tulkAI5833ZGf7b0mZKSoq5du6phw4aaNGlSgfrr27ev/va3v+nMmTN6//331atXL/34448O++wASpK3335by5cv18aNG3kN3UGXL1/Ws88+qwULFhToRyc4htlsVkBAgObPny93d3e1bNlSf/75p9577z1NnDixsNMrMTZu3Khp06Zpzpw5CgsL05EjRzR8+HC99dZbevPNNws7PeQDxScHq1Spktzd3XOcYSgxMVFBQUGFlFXuhg4dqrVr12rz5s2qVq1agfvz8vJS3bp1Jf21COwvv/yijz76SJ9++qndfe3YsUNJSUlq0aKFpS0rK0ubN2/WJ598orS0NLm7uxcoX39/f9WrV09HjhzJ1+2rVKmSo7B2991367///W+B8pKkEydOaMOGDVq1alWB+hk9erRl9JP0V8HgxIkTmj59eoGKT3Xq1NGmTZuUmpqqlJQUValSRU899ZRq165doHwlWV4niYmJqlKliqU9MTFRzZs3L3D/jpRdeDpx4oS+/fbbAo16kqQyZcqobt26qlu3ru69917dddddWrhwocaNG2d3X99//72SkpJUvXp1S1tWVpZGjRqlmTNn6vjx4wXKVZJq166tSpUq6ciRI/kqPlWqVEkeHh65vo4cUQj5/vvvdejQIX3++ef57uPatWv6+9//rtWrV6tr166S/ipex8fH6/3338/3yICWLVtaivXp6emqXLmywsLC1KpVq1veLq/37aCgIKWnp+vSpUtWo59u99nj6M8BW/q8fPmyOnXqpHLlymn16tXy9PQsUH9+fn7y8/PTXXfdpXvvvVfly5fX6tWr1bt3b4c8Htxefr77BAUFucR3JVdTkO+h77//vt5++21t2LDBISd5Kcns3Q+///67jh8/ru7du1vasn+g8fDw0KFDh1SnTh3nJl1M5ec1UaVKFXl6eloda9x9991KSEhQeno6o2vzIT/74c0339Szzz6rQYMGSfrrOCY1NVWDBw/WG2+8ITc3JnHdKXl9Zvv6+qpUqVI298MeczAvLy+1bNlScXFxljaz2ay4uLgCr3/kKIZhaOjQoVq9erW+/fZb1apVyyn3YzabLWub2Ovhhx/Wnj17FB8fb7m0atVKffv2VXx8fIELT9Jfp0///fffrQoc9rjvvvtynPb7t99+U40aNQqc2+LFixUQEGA52M2vq1ev5nhjdnd3t3yhKagyZcqoSpUqunjxor755hs9+uijBe6zVq1aCgoKsnoNpaSk6Oeffy4yryHpf4Wnw4cPa8OGDapYsaLD76Mgr6Fnn31Wu3fvtnoNBQcHa/To0fafmSIPf/zxh86fP5/v15CXl5fuuecep72OFi5cqJYtWxZo3ayMjAxlZGQ47XXk5+enypUr6/Dhw9q+fXuer6HbvW+3bNlSnp6eVq+bQ4cO6eTJk7m+bpzxOWBLnykpKQoPD5eXl5e++uqrW46syE+OhmHIMIx8v26QP/n57tOmTRureEmKjY0tUu/zrii/30PfffddvfXWW1q/fv1ti+C4PXv3Q4MGDXJ8733kkUcsI6JZxy7/8vOauO+++3TkyBGrz/nffvtNVapUofCUT/nZD3kdx0iyaaQ4HMdhn9l2LU8Omyxfvtzw9vY2lixZYuzfv98YPHiw4e/vbyQkJOSrv8uXLxu7du0ydu3aZUgyPvjgA2PXrl02nVUrNy+//LLh5+dnbNy40Thz5ozlcvXq1Xz1ZxiGMXbsWGPTpk3GsWPHjN27dxtjx441TCaTERMTk+8+b1bQs92NGjXK2Lhxo3Hs2DHjxx9/NDp27GhUqlTJSEpKyld/27ZtMzw8PIx//OMfxuHDh41ly5YZpUuXNpYuXZrvHA3jrzM/VK9e3RgzZkyB+jGMv85OVrVqVWPt2rXGsWPHjFWrVhmVKlUyXn/99QL1u379euPrr782jh49asTExBjNmjUzwsLCbD4ryO2e02+//bbh7+9vfPnll8bu3buNRx991KhVq5Zx7dq1fPV3/vx5Y9euXca6desMScby5cuNXbt2GWfOnMlXjunp6cYjjzxiVKtWzYiPj7d6HaWlpdnd35UrV4xx48YZW7duNY4fP25s377deO655wxvb2+rM6LZ+7hvdruz3d2qv8uXLxuvvfaasXXrVuPYsWPGhg0bjBYtWhh33XWXcf369XznuGrVKsPT09OYP3++cfjwYWPWrFmGu7u78f333xfocScnJxulS5c25s6dm2c/tvb34IMPGo0aNTK+++474+jRo8bixYsNHx8fY86cOfnu84svvjC+++474/fffzfWrFlj1KhRw3j88cfz7M+W9+2XXnrJqF69uvHtt98a27dvN9q0aWO0adMm3/2dOXPG2LVrl7FgwQJDkrF582Zj165dxvnz5/PVZ3JyshEWFmY0adLEOHLkiFVMZmam3f39/vvvxrRp04zt27cbJ06cMH788Ueje/fuRoUKFYzExMQ8/5dwjtt993n22WeNsWPHWuJ//PFHw8PDw3j//feNAwcOGBMnTjQ8PT2NPXv2FNZDKDbs3Rdvv/224eXlZaxcudLqtXb58uXCegjFgr374Wac7c5x7N0XJ0+eNMqVK2cMHTrUOHTokLF27VojICDAmDp1amE9hGLB3v0wceJEo1y5csZ//vMfyzFHnTp1jF69ehXWQyg2bvc9dezYscazzz5riT969KhRunRpY/To0caBAweM2bNnG+7u7sb69evtul+KT04ya9Yso3r16oaXl5fRunVr46effsp3X9mnub750r9//3z1l1tfkozFixfnO8eBAwcaNWrUMLy8vIzKlSsbDz/8sEMLT4ZR8OLTU089ZVSpUsXw8vIyqlatajz11FMFPh33//3f/xmNGzc2vL29jQYNGhjz588vUH+GYRjffPONIck4dOhQgftKSUkxhg8fblSvXt3w8fExateubbzxxht5Fkhs9fnnnxu1a9c2vLy8jKCgIGPIkCHGpUuXbL797Z7TZrPZePPNN43AwEDD29vbePjhh2/5/7hdf4sXL851+8SJE/PV57Fjx/J8HX333Xd293ft2jXjscceM4KDgw0vLy+jSpUqxiOPPGJs27atQP/Hm92u+HSr/q5evWqEh4cblStXNjw9PY0aNWoYL7zwwm2L6rbkuHDhQqNu3bqGj4+P0axZM2PNmjUF7vPTTz81SpUqZdPz8nb9nTlzxhgwYIARHBxs+Pj4GPXr1zdmzJhhmM3mfPf50UcfGdWqVTM8PT2N6tWrG+PHj7/l69KW9+1r164Zr7zyilG+fHmjdOnSxmOPPZZngdWW/iZOnGjXZ8Xt+szrfyLJOHbsmN39/fnnn0bnzp2NgIAAw9PT06hWrZrRp08f4+DBg3n+H+Fct/ru8+CDD+Z4b/riiy+MevXqGV5eXkajRo2MdevW3eGMiy979kWNGjXs/oyEbex9TdyI4pNj2bsvtmzZYoSFhRne3t5G7dq1jX/84x+5/lAC+9izHzIyMoxJkyYZderUMXx8fIyQkBDjlVdeMS5evHjnEy9mbvc9tX///saDDz6Y4zbNmzc3vLy8jNq1a+erdmAyDMasAQAAAAAAwDlY8wkAAAAAAABOQ/EJAAAAAAAATkPxCQAAAAAAAE5D8QkAAAAAAABOQ/EJAAAAAAAATkPxCQAAAAAAAE5D8QkAAAAAAABOQ/EJAAAAAAAATkPxCQBuoX379hoxYkRhpwEAAAAALoviE4AiacmSJfL39y/sNIqU48ePy2QyKT4+vrBTAQAAAACbUXwCAAAAAACA01B8AuAUZrNZ06dPV61atVSqVCk1a9ZMK1eutGyPjo5WvXr1VKpUKT300ENasmSJTCaTLl26pI0bN+q5555TcnKyTCaTTCaTJk2adNv7TEtL05gxYxQSEiJvb2/VrVtXCxcutGzftGmTWrduLW9vb1WpUkVjx45VZmamZXtqaqr69eunsmXLqkqVKpoxY0au9/Haa6+patWqKlOmjMLCwrRx40ab/y8//vij2rdvr9KlS6t8+fKKiIjQxYsXJUnr16/X/fffL39/f1WsWFHdunXT77//brltrVq1JEmhoaEymUxq3769zfcLAAAAAIWF4hMAp5g+fbr+9a9/ad68edq3b59GjhypZ555Rps2bdKpU6f0+OOPq3v37oqPj9egQYM0duxYy23btm2rmTNnytfXV2fOnNGZM2f02muv3fY++/Xrp//85z/6+OOPdeDAAX366acqW7asJOnPP/9Uly5ddM899+jXX3/V3LlztXDhQk2dOtVy+9GjR2vTpk368ssvFRMTo40bN2rnzp1W9zF06FBt3bpVy5cv1+7du9WzZ0916tRJhw8fvm1+8fHxevjhh9WwYUNt3bpVP/zwg7p3766srCxJfxW/IiMjtX37dsXFxcnNzU2PPfaYzGazJGnbtm2SpA0bNujMmTNatWrVbe8TAAAAAAqbyTAMo7CTAFC8pKWlqUKFCtqwYYPatGljaR80aJCuXr2qmjVr6ssvv9S+ffss28aOHat33nlHFy9elL+/v5YsWaIRI0bo0qVLNt3nb7/9pvr16ys2NlYdO3bMsf2NN97Qf//7Xx04cEAmk0mSNGfOHI0ZM0bJycm6evWqKlasqKVLl6pnz56SpAsXLqhatWoaPHiwZs6cqZMnT6p27do6efKkgoODLX137NhRrVu31rRp026ZY58+fXTy5En98MMPNj2mc+fOqXLlytqzZ48aN26s48ePq1atWtq1a5eaN29uUx8AAAAAUNg8CjsBAMXPkSNHdPXqVf3tb3+zak9PT1doaKiuXbumsLAwq203FqnyIz4+Xu7u7nrwwQdz3X7gwAG1adPGUniSpPvuu09XrlzRH3/8oYsXLyo9Pd0qrwoVKqh+/fqW63v27FFWVpbq1atn1XdaWpoqVqxoU47Zha3cHD58WBMmTNDPP/+sc+fOWUY8nTx5Uo0bN75t/wAAAABQFFF8AuBwV65ckSStW7dOVatWtdrm7e2tV1991eH3WapUKYf3ebMrV67I3d1dO3bskLu7u9W27Ol9t3K7HLt3764aNWpowYIFCg4OltlsVuPGjZWenl6gvAEAAACgMLHmEwCHa9iwoby9vXXy5EnVrVvX6hISEqK7777bsn5Rtp9++snqupeXl2UtJFs0adJEZrNZmzZtynX73Xffra1bt+rGmcY//vijypUrp2rVqqlOnTry9PTUzz//bNl+8eJF/fbbb5broaGhysrKUlJSUo7HFRQUdNscmzZtqri4uFy3nT9/XocOHdL48eP18MMP6+6777YsRJ7Ny8tLkuz6vwAAAABAYaP4BMDhypUrp9dee00jR47UZ599pt9//107d+7UrFmz9Nlnn+mll17S4cOHNXr0aB06dEhRUVFasmSJVR81a9bUlStXFBcXp3Pnzunq1au3vM+aNWuqf//+GjhwoNasWaNjx45p48aN+uKLLyRJr7zyik6dOqVhw4bp4MGD+vLLLzVx4kRFRkbKzc1NZcuW1fPPP6/Ro0fr22+/1d69ezVgwAC5uf3vbbJevXrq27ev+vXrp1WrVunYsWPatm2bpk+frnXr1t32/zJu3Dj98ssveuWVV7R7924dPHhQc+fO1blz51S+fHlVrFhR8+fP15EjR/Ttt98qMjLS6vYBAQEqVaqU1q9fr8TERCUnJ9u4RwAAAACgEBkA4ARms9mYOXOmUb9+fcPT09OoXLmyERERYWzatMkwDMP4v//7P6Nu3bqGt7e38cADDxiLFi0yJBkXL1609PHSSy8ZFStWNCQZEydOvO19Xrt2zRg5cqRRpUoVw8vLy6hbt66xaNEiy/aNGzca99xzj+Hl5WUEBQUZY8aMMTIyMizbL1++bDzzzDNG6dKljcDAQOPdd981HnzwQWP48OGWmPT0dGPChAlGzZo1DU9PT6NKlSrGY489Zuzevdum/8vGjRuNtm3bGt7e3oa/v78RERFhecyxsbHG3XffbXh7extNmzY1Nm7caEgyVq9ebbn9ggULjJCQEMPNzc148MEHbbpPAAAAAChMnO0OQJGwceNGPfTQQ5az3QEAAAAAigem3QEAAAAAAMBpKD4BcAnff/+9ypYtm+elKOjcuXOe+U2bNq2w0wMAAACAQsG0OwAu4dq1a/rzzz/z3F63bt07mE3u/vzzT127di3XbRUqVFCFChXucEYAAAAAUPgoPgEAAAAAAMBpmHYHAAAAAAAAp6H4BAAAAAAAAKeh+AQAAAAAAACnofgEAAAAAAAAp3Hp4tPmzZvVvXt3BQcHy2Qyac2aNbe9zcaNG9WiRQt5e3urbt26WrJkidPzBAAAKCr4/gQAAO40ly4+paamqlmzZpo9e7ZN8ceOHVPXrl310EMPKT4+XiNGjNCgQYP0zTffODlTAACAooHvTwAA4E4zGYZhFHYSjmAymbR69Wr16NEjz5gxY8Zo3bp12rt3r6Xt6aef1qVLl7R+/fo7kCUAAEDRwfcnAABwJ3gUdgJ30tatW9WxY0ertoiICI0YMSLP26SlpSktLc1y3Ww268KFC6pYsaJMJpOzUgUAAAVkGIYuX76s4OBgubm59GDvQsX3JwAASg5nfX8qUcWnhIQEBQYGWrUFBgYqJSVF165dU6lSpXLcZvr06Zo8efKdShEAADjYqVOnVK1atcJOw2Xx/QkAgJLH0d+fSlTxKT/GjRunyMhIy/Xk5GRVr15dp06dkq+vbyFmBgAAbiUlJUUhISEqV65cYadS4vD9CQAA1+Ss708lqvgUFBSkxMREq7bExET5+vrm+qudJHl7e8vb2ztHu6+vL1+eAABwAUzzKhi+PwEAUPI4+vtTiVoAoU2bNoqLi7Nqi42NVZs2bQopIwAAgKKN708AAKCgXLr4dOXKFcXHxys+Pl7SX6cCjo+P18mTJyX9NeS7X79+lviXXnpJR48e1euvv66DBw9qzpw5+uKLLzRy5MjCSB8AAOCO4/sTAAC401y6+LR9+3aFhoYqNDRUkhQZGanQ0FBNmDBBknTmzBnLFylJqlWrltatW6fY2Fg1a9ZMM2bM0D//+U9FREQUSv4AAAB3Gt+fAADAnWYyDMMo7CRcSUpKivz8/JScnMyaBQAAFGF8Zhcd7AsAAFyDsz6zXXrkEwAAAAAAAIo2ik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAHAaik8AAAAAAABwGopPAAAAAAAAcBqKTwAAAAAAAP+vvbuPrbO87wb+sx1sg4pNeLI4LzPNAx2lLZDQhLiGRqiTV0ugdPljqh+okiyiMNoUsVhbSSDEpbRxRgHlUTGNSGFUWlnSImBVY5kyr1FF8RQ1LxIdCYgGmqyqTbIudhpam9j380cfzurGobHxdV6cz0c6f/jivn1+h0vO/dX33D4mGeUTAAAAAMkonwAAAABIRvkEAAAAQDIlXz51dHTEvHnzorq6OhoaGmLXrl3vevzmzZvjgx/8YJx77rlRX18fa9asid/+9rd5mhYAoPDkJwAgn0q6fNq+fXu0trZGW1tb7NmzJ+bPnx/Nzc3x5ptvjnn8k08+GWvXro22trbYv39/PPbYY7F9+/a466678jw5AEBhyE8AQL6VdPn00EMPxS233BKrVq2KD3/4w7Fly5Y477zz4vHHHx/z+BdffDGuvfbauOmmm2LevHnxyU9+Mm688cY/+m4fAMBUIT8BAPlWsuXT0NBQ7N69O5qamnJr5eXl0dTUFD09PWOec80118Tu3btzYengwYPR2dkZ119/fV5mBgAoJPkJACiEaYUeYKKOHj0aw8PDUVdXN2q9rq4uDhw4MOY5N910Uxw9ejQ+/vGPR5ZlcfLkybjtttve9bbxwcHBGBwczH09MDAwOS8AACDP5CcAoBBK9s6nidi5c2ds3LgxHnnkkdizZ088/fTTsWPHjrjvvvtOe057e3vU1tbmHvX19XmcGACgsOQnAOC9KsuyLCv0EBMxNDQU5513Xjz11FOxbNmy3PrKlSvj2LFj8S//8i+nnLNkyZL42Mc+Fl/72tdya//0T/8Ut956a/z617+O8vJTu7ix3rmrr6+P/v7+qKmpmdwXBQBMmoGBgaitrXXN/j3yEwDwblLlp5K986mysjIWLlwY3d3dubWRkZHo7u6OxsbGMc956623TglIFRUVERFxug6uqqoqampqRj0AAEqR/AQAFELJfuZTRERra2usXLkyFi1aFIsXL47NmzfHiRMnYtWqVRERsWLFipg7d260t7dHRMTSpUvjoYceiquuuioaGhritddei3vuuSeWLl2aC1EAAFOZ/AQA5FtJl08tLS1x5MiR2LBhQ/T29saCBQuiq6sr9yGahw4dGvVO3fr166OsrCzWr18fv/jFL+JP/uRPYunSpfHVr361UC8BACCv5CcAIN9K9jOfCsXnRwBAaXDNLh72AgBKg898AgAAAKDkKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJIp+fKpo6Mj5s2bF9XV1dHQ0BC7du161+OPHTsWq1evjtmzZ0dVVVVceuml0dnZmadpAQAKT34CAPJpWqEHeC+2b98era2tsWXLlmhoaIjNmzdHc3NzvPLKKzFz5sxTjh8aGoq/+Iu/iJkzZ8ZTTz0Vc+fOjZ///OdxwQUX5H94AIACkJ8AgHwry7IsK/QQE9XQ0BBXX311PPzwwxERMTIyEvX19XH77bfH2rVrTzl+y5Yt8bWvfS0OHDgQ55xzzoSec2BgIGpra6O/vz9qamre0/wAQDqu2WOTnwCA00l1zS7ZX7sbGhqK3bt3R1NTU26tvLw8mpqaoqenZ8xzvve970VjY2OsXr066urq4vLLL4+NGzfG8PDwaZ9ncHAwBgYGRj0AAEqR/AQAFELJlk9Hjx6N4eHhqKurG7VeV1cXvb29Y55z8ODBeOqpp2J4eDg6OzvjnnvuiQcffDC+8pWvnPZ52tvbo7a2Nveor6+f1NcBAJAv8hMAUAglWz5NxMjISMycOTMeffTRWLhwYbS0tMTdd98dW7ZsOe0569ati/7+/tzj8OHDeZwYAKCw5CcA4L0q2Q8cnzFjRlRUVERfX9+o9b6+vpg1a9aY58yePTvOOeecqKioyK196EMfit7e3hgaGorKyspTzqmqqoqqqqrJHR4AoADkJwCgEEr2zqfKyspYuHBhdHd359ZGRkaiu7s7Ghsbxzzn2muvjddeey1GRkZya6+++mrMnj17zOAEADCVyE8AQCGUbPkUEdHa2hpbt26Nb33rW7F///743Oc+FydOnIhVq1ZFRMSKFSti3bp1ueM/97nPxa9+9au444474tVXX40dO3bExo0bY/Xq1YV6CQAAeSU/AQD5VrK/dhcR0dLSEkeOHIkNGzZEb29vLFiwILq6unIfonno0KEoL/+ffq2+vj6ee+65WLNmTVx55ZUxd+7cuOOOO+LOO+8s1EsAAMgr+QkAyLeyLMuyQg9RSgYGBqK2tjb6+/ujpqam0OMAAKfhml087AUAlIZU1+yS/rU7AAAAAIqb8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAkU/LlU0dHR8ybNy+qq6ujoaEhdu3adUbnbdu2LcrKymLZsmVpBwQAKDLyEwCQTyVdPm3fvj1aW1ujra0t9uzZE/Pnz4/m5uZ488033/W8N954I/7u7/4ulixZkqdJAQCKg/wEAORbSZdPDz30UNxyyy2xatWq+PCHPxxbtmyJ8847Lx5//PHTnjM8PByf+cxn4t57742LL744j9MCABSe/AQA5FvJlk9DQ0Oxe/fuaGpqyq2Vl5dHU1NT9PT0nPa8L3/5yzFz5sy4+eabz+h5BgcHY2BgYNQDAKAUyU8AQCGUbPl09OjRGB4ejrq6ulHrdXV10dvbO+Y5L7zwQjz22GOxdevWM36e9vb2qK2tzT3q6+vf09wAAIUiPwEAhVCy5dN4HT9+PJYvXx5bt26NGTNmnPF569ati/7+/tzj8OHDCacEACge8hMAMBmmFXqAiZoxY0ZUVFREX1/fqPW+vr6YNWvWKcf/7Gc/izfeeCOWLl2aWxsZGYmIiGnTpsUrr7wSl1xyySnnVVVVRVVV1SRPDwCQf/ITAFAIJXvnU2VlZSxcuDC6u7tzayMjI9Hd3R2NjY2nHH/ZZZfFSy+9FPv27cs9PvWpT8UnPvGJ2Ldvn9vBAYApT34CAAqhZO98iohobW2NlStXxqJFi2Lx4sWxefPmOHHiRKxatSoiIlasWBFz586N9vb2qK6ujssvv3zU+RdccEFExCnrAABTlfwEAORbSZdPLS0tceTIkdiwYUP09vbGggULoqurK/chmocOHYry8pK9uQsAYNLJTwBAvpVlWZYVeohSMjAwELW1tdHf3x81NTWFHgcAOA3X7OJhLwCgNKS6ZntbCwAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgmZIvnzo6OmLevHlRXV0dDQ0NsWvXrtMeu3Xr1liyZElMnz49pk+fHk1NTe96PADAVCQ/AQD5VNLl0/bt26O1tTXa2tpiz549MX/+/Ghubo4333xzzON37twZN954Y/zwhz+Mnp6eqK+vj09+8pPxi1/8Is+TAwAUhvwEAORbWZZlWaGHmKiGhoa4+uqr4+GHH46IiJGRkaivr4/bb7891q5d+0fPHx4ejunTp8fDDz8cK1asOKPnHBgYiNra2ujv74+ampr3ND8AkI5r9tjkJwDgdFJds0v2zqehoaHYvXt3NDU15dbKy8ujqakpenp6zuh7vPXWW/H222/HhRdemGpMAICiIT8BAIUwrdADTNTRo0djeHg46urqRq3X1dXFgQMHzuh73HnnnTFnzpxRAewPDQ4OxuDgYO7rgYGBiQ0MAFBg8hMAUAgle+fTe7Vp06bYtm1bPPPMM1FdXX3a49rb26O2tjb3qK+vz+OUAADFQ34CACaiZMunGTNmREVFRfT19Y1a7+vri1mzZr3ruQ888EBs2rQpfvCDH8SVV175rseuW7cu+vv7c4/Dhw+/59kBAApBfgIACqFky6fKyspYuHBhdHd359ZGRkaiu7s7GhsbT3ve/fffH/fdd190dXXFokWL/ujzVFVVRU1NzagHAEApkp8AgEIo2c98iohobW2NlStXxqJFi2Lx4sWxefPmOHHiRKxatSoiIlasWBFz586N9vb2iIj4h3/4h9iwYUM8+eSTMW/evOjt7Y2IiPe9733xvve9r2CvAwAgX+QnACDfSrp8amlpiSNHjsSGDRuit7c3FixYEF1dXbkP0Tx06FCUl//PzV3f+MY3YmhoKP7qr/5q1Pdpa2uLL33pS/kcHQCgIOQnACDfyrIsywo9RCkZGBiI2tra6O/vdws5ABQx1+ziYS8AoDSkumaX7Gc+AQAAAFD8lE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMmUfPnU0dER8+bNi+rq6mhoaIhdu3a96/Hf/e5347LLLovq6uq44oororOzM0+TAgAUB/kJAMinki6ftm/fHq2trdHW1hZ79uyJ+fPnR3Nzc7z55ptjHv/iiy/GjTfeGDfffHPs3bs3li1bFsuWLYuf/vSneZ4cAKAw5CcAIN/KsizLCj3ERDU0NMTVV18dDz/8cEREjIyMRH19fdx+++2xdu3aU45vaWmJEydOxPe///3c2sc+9rFYsGBBbNmy5Yyec2BgIGpra6O/vz9qamom54UAAJPONXts8hMAcDqprtnTJu075dnQ0FDs3r071q1bl1srLy+Ppqam6OnpGfOcnp6eaG1tHbXW3Nwczz777GmfZ3BwMAYHB3Nf9/f3R8TvNgQAKF7vXKtL+H22SSc/AQDvJlV+Ktny6ejRozE8PBx1dXWj1uvq6uLAgQNjntPb2zvm8b29vad9nvb29rj33ntPWa+vr5/A1ABAvv3Xf/1X1NbWFnqMoiA/AQBnYrLzU8mWT/mybt26Ue/2HTt2LN7//vfHoUOHBNkCGxgYiPr6+jh8+LBb+AvIPhQPe1E87EVx6O/vj4suuiguvPDCQo9y1pGfipd/n4qDfSge9qJ42IvikCo/lWz5NGPGjKioqIi+vr5R6319fTFr1qwxz5k1a9a4jo+IqKqqiqqqqlPWa2tr/UAUiZqaGntRBOxD8bAXxcNeFIfy8pL++yqTSn7iHf59Kg72oXjYi+JhL4rDZOenkk1jlZWVsXDhwuju7s6tjYyMRHd3dzQ2No55TmNj46jjIyKef/750x4PADCVyE8AQCGU7J1PERGtra2xcuXKWLRoUSxevDg2b94cJ06ciFWrVkVExIoVK2Lu3LnR3t4eERF33HFHXHfddfHggw/GDTfcENu2bYuf/OQn8eijjxbyZQAA5I38BADkW0mXTy0tLXHkyJHYsGFD9Pb2xoIFC6Krqyv3oZiHDh0adavYNddcE08++WSsX78+7rrrrvizP/uzePbZZ+Pyyy8/4+esqqqKtra2MW8lJ7/sRXGwD8XDXhQPe1Ec7MPY5Kezm70oDvaheNiL4mEvikOqfSjL/P1hAAAAABIp2c98AgAAAKD4KZ8AAAAASEb5BAAAAEAyyicAAAAAklE+jaGjoyPmzZsX1dXV0dDQELt27XrX47/73e/GZZddFtXV1XHFFVdEZ2dnniad+sazF1u3bo0lS5bE9OnTY/r06dHU1PRH944zM96fiXds27YtysrKYtmyZWkHPIuMdy+OHTsWq1evjtmzZ0dVVVVceuml/o2aJOPdi82bN8cHP/jBOPfcc6O+vj7WrFkTv/3tb/M07dT0ox/9KJYuXRpz5syJsrKyePbZZ//oOTt37oyPfvSjUVVVFR/4wAfiiSeeSD7n2UJ+Kh7yU3GQn4qH/FQcZKfiULD8lDHKtm3bssrKyuzxxx/P/uM//iO75ZZbsgsuuCDr6+sb8/gf//jHWUVFRXb//fdnL7/8crZ+/frsnHPOyV566aU8Tz71jHcvbrrppqyjoyPbu3dvtn///uyv//qvs9ra2uw///M/8zz51DLefXjH66+/ns2dOzdbsmRJ9pd/+Zf5GXaKG+9eDA4OZosWLcquv/767IUXXshef/31bOfOndm+ffvyPPnUM969+Pa3v51VVVVl3/72t7PXX389e+6557LZs2dna9asyfPkU0tnZ2d29913Z08//XQWEdkzzzzzrscfPHgwO++887LW1tbs5Zdfzr7+9a9nFRUVWVdXV34GnsLkp+IhPxUH+al4yE/FQXYqHoXKT8qnP7B48eJs9erVua+Hh4ezOXPmZO3t7WMe/+lPfzq74YYbRq01NDRkf/M3f5N0zrPBePfiD508eTI7//zzs29961upRjwrTGQfTp48mV1zzTXZN7/5zWzlypXC0yQZ71584xvfyC6++OJsaGgoXyOeNca7F6tXr87+/M//fNRaa2trdu211yad82xyJuHpi1/8YvaRj3xk1FpLS0vW3NyccLKzg/xUPOSn4iA/FQ/5qTjITsUpn/nJr939nqGhodi9e3c0NTXl1srLy6OpqSl6enrGPKenp2fU8RERzc3Npz2eMzORvfhDb731Vrz99ttx4YUXphpzypvoPnz5y1+OmTNnxs0335yPMc8KE9mL733ve9HY2BirV6+Ourq6uPzyy2Pjxo0xPDycr7GnpInsxTXXXBO7d+/O3V5+8ODB6OzsjOuvvz4vM/M7rtlpyE/FQ34qDvJT8ZCfioPsVNom65o9bTKHKnVHjx6N4eHhqKurG7VeV1cXBw4cGPOc3t7eMY/v7e1NNufZYCJ78YfuvPPOmDNnzik/KJy5iezDCy+8EI899ljs27cvDxOePSayFwcPHox/+7d/i8985jPR2dkZr732Wnz+85+Pt99+O9ra2vIx9pQ0kb246aab4ujRo/Hxj388siyLkydPxm233RZ33XVXPkbm/zvdNXtgYCB+85vfxLnnnlugyUqb/FQ85KfiID8VD/mpOMhOpW2y8pM7n5iSNm3aFNu2bYtnnnkmqqurCz3OWeP48eOxfPny2Lp1a8yYMaPQ45z1RkZGYubMmfHoo4/GwoULo6WlJe6+++7YsmVLoUc76+zcuTM2btwYjzzySOzZsyeefvrp2LFjR9x3332FHg0gR34qDPmpuMhPxUF2mnrc+fR7ZsyYERUVFdHX1zdqva+vL2bNmjXmObNmzRrX8ZyZiezFOx544IHYtGlT/Ou//mtceeWVKcec8sa7Dz/72c/ijTfeiKVLl+bWRkZGIiJi2rRp8corr8Qll1ySdugpaiI/E7Nnz45zzjknKioqcmsf+tCHore3N4aGhqKysjLpzFPVRPbinnvuieXLl8dnP/vZiIi44oor4sSJE3HrrbfG3XffHeXl3gvKh9Nds2tqatz19B7IT8VDfioO8lPxkJ+Kg+xU2iYrP9mx31NZWRkLFy6M7u7u3NrIyEh0d3dHY2PjmOc0NjaOOj4i4vnnnz/t8ZyZiexFRMT9998f9913X3R1dcWiRYvyMeqUNt59uOyyy+Kll16Kffv25R6f+tSn4hOf+ETs27cv6uvr8zn+lDKRn4lrr702XnvttVyAjYh49dVXY/bs2YLTezCRvXjrrbdOCUnvhNrffdYj+eCanYb8VDzkp+IgPxUP+ak4yE6lbdKu2eP6ePKzwLZt27KqqqrsiSeeyF5++eXs1ltvzS644IKst7c3y7IsW758ebZ27drc8T/+8Y+zadOmZQ888EC2f//+rK2tzZ8KniTj3YtNmzZllZWV2VNPPZX98pe/zD2OHz9eqJcwJYx3H/6Qv9Yyeca7F4cOHcrOP//87Atf+EL2yiuvZN///vezmTNnZl/5ylcK9RKmjPHuRVtbW3b++edn//zP/5wdPHgw+8EPfpBdcskl2ac//elCvYQp4fjx49nevXuzvXv3ZhGRPfTQQ9nevXuzn//851mWZdnatWuz5cuX545/508F//3f/322f//+rKOjY0J/KphTyU/FQ34qDvJT8ZCfioPsVDwKlZ+UT2P4+te/nl100UVZZWVltnjx4uzf//3fc//tuuuuy1auXDnq+O985zvZpZdemlVWVmYf+chHsh07duR54qlrPHvx/ve/P4uIUx5tbW35H3yKGe/PxO8TnibXePfixRdfzBoaGrKqqqrs4osvzr761a9mJ0+ezPPUU9N49uLtt9/OvvSlL2WXXHJJVl1dndXX12ef//zns//+7//O/+BTyA9/+MMx/91/5//9ypUrs+uuu+6UcxYsWJBVVlZmF198cfaP//iPeZ97qpKfiof8VBzkp+IhPxUH2ak4FCo/lWWZe9YAAAAASMNnPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIJmSLp9+9KMfxdKlS2POnDlRVlYWzz777B89Z+fOnfHRj340qqqq4gMf+EA88cQTyecEACgW8hMAkG8lXT6dOHEi5s+fHx0dHWd0/Ouvvx433HBDfOITn4h9+/bF3/7t38ZnP/vZeO655xJPCgBQHOQnACDfyrIsywo9xGQoKyuLZ555JpYtW3baY+68887YsWNH/PSnP82t/Z//83/i2LFj0dXVlYcpAQCKh/wEAORDSd/5NF49PT3R1NQ0aq25uTl6enoKNBEAQHGTnwCA92paoQfIp97e3qirqxu1VldXFwMDA/Gb3/wmzj333FPOGRwcjMHBwdzXIyMj8atf/Sr+1//6X1FWVpZ8ZgBgYrIsi+PHj8ecOXOivPyser9tUslPAHD2SJWfzqryaSLa29vj3nvvLfQYAMAEHT58OP70T/+00GOcVeQnAChtk52fzqryadasWdHX1zdqra+vL2pqasZ81y4iYt26ddHa2pr7ur+/Py666KI4fPhw1NTUJJ0XAJi4gYGBqK+vj/PPP7/Qo5Q0+QkAzh6p8tNZVT41NjZGZ2fnqLXnn38+GhsbT3tOVVVVVFVVnbJeU1MjPAFACfBrXu+N/AQAZ5/Jzk8l/QEIv/71r2Pfvn2xb9++iPjdnwLet29fHDp0KCJ+967bihUrcsffdtttcfDgwfjiF78YBw4ciEceeSS+853vxJo1awoxPgBA3slPAEC+lXT59JOf/CSuuuqquOqqqyIiorW1Na666qrYsGFDRET88pe/zAWpiIj//b//d+zYsSOef/75mD9/fjz44IPxzW9+M5qbmwsyPwBAvslPAEC+lWVZlhV6iFIyMDAQtbW10d/f77ZxAChirtnFw14AQGlIdc0u6TufAAAAAChuyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQTMmXTx0dHTFv3ryorq6OhoaG2LVr17sev3nz5vjgBz8Y5557btTX18eaNWvit7/9bZ6mBQAoPPkJAMinki6ftm/fHq2trdHW1hZ79uyJ+fPnR3Nzc7z55ptjHv/kk0/G2rVro62tLfbv3x+PPfZYbN++Pe666648Tw4AUBjyEwCQbyVdPj300ENxyy23xKpVq+LDH/5wbNmyJc4777x4/PHHxzz+xRdfjGuvvTZuuummmDdvXnzyk5+MG2+88Y++2wcAMFXITwBAvpVs+TQ0NBS7d++Opqam3Fp5eXk0NTVFT0/PmOdcc801sXv37lxYOnjwYHR2dsb111+fl5kBAApJfgIACmFaoQeYqKNHj8bw8HDU1dWNWq+rq4sDBw6Mec5NN90UR48ejY9//OORZVmcPHkybrvttne9bXxwcDAGBwdzXw8MDEzOCwAAyDP5CQAohJK982kidu7cGRs3boxHHnkk9uzZE08//XTs2LEj7rvvvtOe097eHrW1tblHfX19HicGACgs+QkAeK/KsizLCj3ERAwNDcV5550XTz31VCxbtiy3vnLlyjh27Fj8y7/8yynnLFmyJD72sY/F1772tdzaP/3TP8Wtt94av/71r6O8/NQubqx37urr66O/vz9qamom90UBAJNmYGAgamtrXbN/j/wEALybVPmpZO98qqysjIULF0Z3d3dubWRkJLq7u6OxsXHMc956661TAlJFRUVERJyug6uqqoqamppRDwCAUiQ/AQCFULKf+RQR0draGitXroxFixbF4sWLY/PmzXHixIlYtWpVRESsWLEi5s6dG+3t7RERsXTp0njooYfiqquuioaGhnjttdfinnvuiaVLl+ZCFADAVCY/AQD5VtLlU0tLSxw5ciQ2bNgQvb29sWDBgujq6sp9iOahQ4dGvVO3fv36KCsri/Xr18cvfvGL+JM/+ZNYunRpfPWrXy3USwAAyCv5CQDIt5L9zKdC8fkRAFAaXLOLh70AgNLgM58AAAAAKDnKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZEq+fOro6Ih58+ZFdXV1NDQ0xK5du971+GPHjsXq1atj9uzZUVVVFZdeeml0dnbmaVoAgMKTnwCAfJpW6AHei+3bt0dra2ts2bIlGhoaYvPmzdHc3ByvvPJKzJw585Tjh4aG4i/+4i9i5syZ8dRTT8XcuXPj5z//eVxwwQX5Hx4AoADkJwAg38qyLMsKPcRENTQ0xNVXXx0PP/xwRESMjIxEfX193H777bF27dpTjt+yZUt87WtfiwMHDsQ555wzoeccGBiI2tra6O/vj5qamvc0PwCQjmv22OQnAOB0Ul2zS/bX7oaGhmL37t3R1NSUWysvL4+mpqbo6ekZ85zvfe970djYGKtXr466urq4/PLLY+PGjTE8PHza5xkcHIyBgYFRDwCAUiQ/AQCFULLl09GjR2N4eDjq6upGrdfV1UVvb++Y5xw8eDCeeuqpGB4ejs7OzrjnnnviwQcfjK985SunfZ729vaora3NPerr6yf1dQAA5Iv8BAAUQsmWTxMxMjISM2fOjEcffTQWLlwYLS0tcffdd8eWLVtOe866deuiv78/9zh8+HAeJwYAKCz5CQB4r0r2A8dnzJgRFRUV0dfXN2q9r68vZs2aNeY5s2fPjnPOOScqKipyax/60Ieit7c3hoaGorKy8pRzqqqqoqqqanKHBwAoAPkJACiEkr3zqbKyMhYuXBjd3d25tZGRkeju7o7GxsYxz7n22mvjtddei5GRkdzaq6++GrNnzx4zOAEATCXyEwBQCCVbPkVEtLa2xtatW+Nb3/pW7N+/Pz73uc/FiRMnYtWqVRERsWLFili3bl3u+M997nPxq1/9Ku6444549dVXY8eOHbFx48ZYvXp1oV4CAEBeyU8AQL6V7K/dRUS0tLTEkSNHYsOGDdHb2xsLFiyIrq6u3IdoHjp0KMrL/6dfq6+vj+eeey7WrFkTV155ZcydOzfuuOOOuPPOOwv1EgAA8kp+AgDyrSzLsqzQQ5SSgYGBqK2tjf7+/qipqSn0OADAabhmFw97AQClIdU1u6R/7Q4AAACA4qZ8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMmUfPnU0dER8+bNi+rq6mhoaIhdu3ad0Xnbtm2LsrKyWLZsWdoBAQCKjPwEAORTSZdP27dvj9bW1mhra4s9e/bE/Pnzo7m5Od588813Pe+NN96Iv/u7v4slS5bkaVIAgOIgPwEA+VbS5dNDDz0Ut9xyS6xatSo+/OEPx5YtW+K8886Lxx9//LTnDA8Px2c+85m499574+KLL87jtAAAhSc/AQD5VrLl09DQUOzevTuamppya+Xl5dHU1BQ9PT2nPe/LX/5yzJw5M26++eZ8jAkAUDTkJwCgEKYVeoCJOnr0aAwPD0ddXd2o9bq6ujhw4MCY57zwwgvx2GOPxb59+874eQYHB2NwcDD39cDAwITmBQAoNPkJACiEkr3zabyOHz8ey5cvj61bt8aMGTPO+Lz29vaora3NPerr6xNOCQBQPOQnAGAylOydTzNmzIiKioro6+sbtd7X1xezZs065fif/exn8cYbb8TSpUtzayMjIxERMW3atHjllVfikksuOeW8devWRWtra+7rgYEBAQoAKEnyEwBQCCVbPlVWVsbChQuju7s79+d+R0ZGoru7O77whS+ccvxll10WL7300qi19evXx/Hjx+P//t//e9pAVFVVFVVVVZM+PwBAvslPAEAhlGz5FBHR2toaK1eujEWLFsXixYtj8+bNceLEiVi1alVERKxYsSLmzp0b7e3tUV1dHZdffvmo8y+44IKIiFPWAQCmKvkJAMi3ki6fWlpa4siRI7Fhw4bo7e2NBQsWRFdXV+5DNA8dOhTl5WfNx1oBAPxR8hMAkG9lWZZlhR6ilAwMDERtbW309/dHTU1NoccBAE7DNbt42AsAKA2prtne1gIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASKbky6eOjo6YN29eVFdXR0NDQ+zateu0x27dujWWLFkS06dPj+nTp0dTU9O7Hg8AMBXJTwBAPpV0+bR9+/ZobW2Ntra22LNnT8yfPz+am5vjzTffHPP4nTt3xo033hg//OEPo6enJ+rr6+OTn/xk/OIXv8jz5AAAhSE/AQD5VpZlWVboISaqoaEhrr766nj44YcjImJkZCTq6+vj9ttvj7Vr1/7R84eHh2P69Onx8MMPx4oVK87oOQcGBqK2tjb6+/ujpqbmPc0PAKTjmj02+QkAOJ1U1+ySvfNpaGgodu/eHU1NTbm18vLyaGpqip6enjP6Hm+99Va8/fbbceGFF6YaEwCgaMhPAEAhTCv0ABN19OjRGB4ejrq6ulHrdXV1ceDAgTP6HnfeeWfMmTNnVAD7Q4ODgzE4OJj7emBgYGIDAwAUmPwEABRCyd759F5t2rQptm3bFs8880xUV1ef9rj29vaora3NPerr6/M4JQBA8ZCfAICJKNnyacaMGVFRURF9fX2j1vv6+mLWrFnveu4DDzwQmzZtih/84Adx5ZVXvuux69ati/7+/tzj8OHD73l2AIBCkJ8AgEIo2fKpsrIyFi5cGN3d3bm1kZGR6O7ujsbGxtOed//998d9990XXV1dsWjRoj/6PFVVVVFTUzPqAQBQiuQnAKAQSvYznyIiWltbY+XKlbFo0aJYvHhxbN68OU6cOBGrVq2KiIgVK1bE3Llzo729PSIi/uEf/iE2bNgQTz75ZMybNy96e3sjIuJ973tfvO997yvY6wAAyBf5CQDIt5Iun1paWuLIkSOxYcOG6O3tjQULFkRXV1fuQzQPHToU5eX/c3PXN77xjRgaGoq/+qu/GvV92tra4ktf+lI+RwcAKAj5CQDIt7Isy7JCD1FKBgYGora2Nvr7+91CDgBFzDW7eNgLACgNqa7ZJfuZTwAAAAAUP+UTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyyicAAAAAklE+AQAAAJCM8gkAAACAZJRPAAAAACSjfAIAAAAgGeUTAAAAAMkonwAAAABIRvkEAAAAQDLKJwAAAACSUT4BAAAAkIzyCQAAAIBklE8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASEb5BAAAAEAyJV8+dXR0xLx586K6ujoaGhpi165d73r8d7/73bjsssuiuro6rrjiiujs7MzTpAAAxUF+AgDyqaTLp+3bt0dra2u0tbXFnj17Yv78+dHc3BxvvvnmmMe/+OKLceONN8bNN98ce/fujWXLlsWyZcvipz/9aZ4nBwAoDPkJAMi3sizLskIPMVENDQ1x9dVXx8MPPxwRESMjI1FfXx+33357rF279pTjW1pa4sSJE/H9738/t/axj30sFixYEFu2bDmj5xwYGIja2tro7++PmpqayXkhAMCkc80em/wEAJxOqmv2tEn7Tnk2NDQUu3fvjnXr1uXWysvLo6mpKXp6esY8p6enJ1pbW0etNTc3x7PPPnva5xkcHIzBwcHc1/39/RHxuw0BAIrXO9fqEn6fbdLJTwDAu0mVn0q2fDp69GgMDw9HXV3dqPW6uro4cODAmOf09vaOeXxvb+9pn6e9vT3uvffeU9br6+snMDUAkG//9V//FbW1tYUeoyjITwDAmZjs/FSy5VO+rFu3btS7fceOHYv3v//9cejQIUG2wAYGBqK+vj4OHz7sFv4Csg/Fw14UD3tRHPr7++Oiiy6KCy+8sNCjnHXkp+Ll36fiYB+Kh70oHvaiOKTKTyVbPs2YMSMqKiqir69v1HpfX1/MmjVrzHNmzZo1ruMjIqqqqqKqquqU9draWj8QRaKmpsZeFAH7UDzsRfGwF8WhvLyk/77KpJKfeId/n4qDfSge9qJ42IviMNn5qWTTWGVlZSxcuDC6u7tzayMjI9Hd3R2NjY1jntPY2Djq+IiI559//rTHAwBMJfITAFAIJXvnU0REa2trrFy5MhYtWhSLFy+OzZs3x4kTJ2LVqlUREbFixYqYO3dutLe3R0TEHXfcEdddd108+OCDccMNN8S2bdviJz/5STz66KOFfBkAAHkjPwEA+VbS5VNLS0scOXIkNmzYEL29vbFgwYLo6urKfSjmoUOHRt0qds0118STTz4Z69evj7vuuiv+7M/+LJ599tm4/PLLz/g5q6qqoq2tbcxbyckve1Ec7EPxsBfFw14UB/swNvnp7GYvioN9KB72onjYi+KQah/KMn9/GAAAAIBESvYznwAAAAAofsonAAAAAJJRPgEAAACQjPIJAAAAgGSUT2Po6OiIefPmRXV1dTQ0NMSuXbve9fjvfve7cdlll0V1dXVcccUV0dnZmadJp77x7MXWrVtjyZIlMX369Jg+fXo0NTX90b3jzIz3Z+Id27Zti7Kysli2bFnaAc8i492LY8eOxerVq2P27NlRVVUVl156qX+jJsl492Lz5s3xwQ9+MM4999yor6+PNWvWxG9/+9s8TTs1/ehHP4qlS5fGnDlzoqysLJ599tk/es7OnTvjox/9aFRVVcUHPvCBeOKJJ5LPebaQn4qH/FQc5KfiIT8VB9mpOBQsP2WMsm3btqyysjJ7/PHHs//4j//IbrnlluyCCy7I+vr6xjz+xz/+cVZRUZHdf//92csvv5ytX78+O+ecc7KXXnopz5NPPePdi5tuuinr6OjI9u7dm+3fvz/767/+66y2tjb7z//8zzxPPrWMdx/e8frrr2dz587NlixZkv3lX/5lfoad4sa7F4ODg9miRYuy66+/PnvhhRey119/Pdu5c2e2b9++PE8+9Yx3L7797W9nVVVV2be//e3s9ddfz5577rls9uzZ2Zo1a/I8+dTS2dmZ3X333dnTTz+dRUT2zDPPvOvxBw8ezM4777ystbU1e/nll7Ovf/3rWUVFRdbV1ZWfgacw+al4yE/FQX4qHvJTcZCdikeh8pPy6Q8sXrw4W716de7r4eHhbM6cOVl7e/uYx3/605/ObrjhhlFrDQ0N2d/8zd8knfNsMN69+EMnT57Mzj///Oxb3/pWqhHPChPZh5MnT2bXXHNN9s1vfjNbuXKl8DRJxrsX3/jGN7KLL744GxoayteIZ43x7sXq1auzP//zPx+11traml177bVJ5zybnEl4+uIXv5h95CMfGbXW0tKSNTc3J5zs7CA/FQ/5qTjIT8VDfioOslNxymd+8mt3v2doaCh2794dTU1NubXy8vJoamqKnp6eMc/p6ekZdXxERHNz82mP58xMZC/+0FtvvRVvv/12XHjhhanGnPImug9f/vKXY+bMmXHzzTfnY8yzwkT24nvf+140NjbG6tWro66uLi6//PLYuHFjDA8P52vsKWkie3HNNdfE7t27c7eXHzx4MDo7O+P666/Py8z8jmt2GvJT8ZCfioP8VDzkp+IgO5W2ybpmT5vMoUrd0aNHY3h4OOrq6kat19XVxYEDB8Y8p7e3d8zje3t7k815NpjIXvyhO++8M+bMmXPKDwpnbiL78MILL8Rjjz0W+/bty8OEZ4+J7MXBgwfj3/7t3+Izn/lMdHZ2xmuvvRaf//zn4+233462trZ8jD0lTWQvbrrppjh69Gh8/OMfjyzL4uTJk3HbbbfFXXfdlY+R+f9Od80eGBiI3/zmN3HuuecWaLLSJj8VD/mpOMhPxUN+Kg6yU2mbrPzkziempE2bNsW2bdvimWeeierq6kKPc9Y4fvx4LF++PLZu3RozZswo9DhnvZGRkZg5c2Y8+uijsXDhwmhpaYm77747tmzZUujRzjo7d+6MjRs3xiOPPBJ79uyJp59+Onbs2BH33XdfoUcDyJGfCkN+Ki7yU3GQnaYedz79nhkzZkRFRUX09fWNWu/r64tZs2aNec6sWbPGdTxnZiJ78Y4HHnggNm3aFP/6r/8aV155Zcoxp7zx7sPPfvazeOONN2Lp0qW5tZGRkYiImDZtWrzyyitxySWXpB16iprIz8Ts2bPjnHPOiYqKitzahz70oejt7Y2hoaGorKxMOvNUNZG9uOeee2L58uXx2c9+NiIirrjiijhx4kTceuutcffdd0d5ufeC8uF01+yamhp3Pb0H8lPxkJ+Kg/xUPOSn4iA7lbbJyk927PdUVlbGwoULo7u7O7c2MjIS3d3d0djYOOY5jY2No46PiHj++edPezxnZiJ7ERFx//33x3333RddXV2xaNGifIw6pY13Hy677LJ46aWXYt++fbnHpz71qfjEJz4R+/bti/r6+nyOP6VM5Gfi2muvjddeey0XYCMiXn311Zg9e7bg9B5MZC/eeuutU0LSO6H2d5/1SD64ZqchPxUP+ak4yE/FQ34qDrJTaZu0a/a4Pp78LLBt27asqqoqe+KJJ7KXX345u/XWW7MLLrgg6+3tzbIsy5YvX56tXbs2d/yPf/zjbNq0adkDDzyQ7d+/P2tra/OngifJePdi06ZNWWVlZfbUU09lv/zlL3OP48ePF+olTAnj3Yc/5K+1TJ7x7sWhQ4ey888/P/vCF76QvfLKK9n3v//9bObMmdlXvvKVQr2EKWO8e9HW1padf/752T//8z9nBw8ezH7wgx9kl1xySfbpT3+6UC9hSjh+/Hi2d+/ebO/evVlEZA899FC2d+/e7Oc//3mWZVm2du3abPny5bnj3/lTwX//93+f7d+/P+vo6JjQnwrmVPJT8ZCfioP8VDzkp+IgOxWPQuUn5dMYvv71r2cXXXRRVllZmS1evDj793//99x/u+6667KVK1eOOv473/lOdumll2aVlZXZRz7ykWzHjh15nnjqGs9evP/9788i4pRHW1tb/gefYsb7M/H7hKfJNd69ePHFF7OGhoasqqoqu/jii7OvfvWr2cmTJ/M89dQ0nr14++23sy996UvZJZdcklVXV2f19fXZ5z//+ey///u/8z/4FPLDH/5wzH/33/l/v3Llyuy666475ZwFCxZklZWV2cUXX5z94z/+Y97nnqrkp+IhPxUH+al4yE/FQXYqDoXKT2VZ5p41AAAAANLwmU8AAAAAJKN8AgAAACAZ5RMAAAAAySifAAAAAEhG+QQAAABAMsonAAAAAJJRPgEAAACQjPIJAAAAgGSUTwAAAAAko3wCAAAAIBnlEwAAAADJKJ8AAAAASOb/AcvnFinXw3MhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "features = [\n",
    "    \"venue\",\n",
    "    \"order_id\",\n",
    "    \"action\",\n",
    "    \"side\",\n",
    "    \"price\",\n",
    "    \"bid\",\n",
    "    \"ask\",\n",
    "    \"bid_size\",\n",
    "    \"ask_size\",\n",
    "    \"trade\",\n",
    "    \"flux\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_sample(df, features, label, group_col, name=\"train\"):\n",
    "    \"\"\"\n",
    "    Trace des boxplots pour un ensemble de colonnes.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame contenant les données.\n",
    "        features (list): Liste des colonnes à tracer.\n",
    "        label (str): Titre général pour les graphiques.\n",
    "        group_col (str): Colonne utilisée pour grouper les données (facultatif pour des stats avancées).\n",
    "        name (str): Nom de l'ensemble de données (e.g., 'train').\n",
    "    \"\"\"\n",
    "    # Configurer la figure\n",
    "    n_features = len(features)\n",
    "    ncols = 2\n",
    "    nrows = (n_features + 1) // ncols\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 4 * nrows))\n",
    "    axes = axes.flatten()  # Pour itérer facilement sur tous les axes\n",
    "    \n",
    "    # Supprimer les axes supplémentaires s'il y a un nombre impair de plots\n",
    "    for ax in axes[n_features:]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Tracer chaque feature\n",
    "    for i, feature in enumerate(features):\n",
    "        sns.boxplot(x=group_col, y=feature, data=df, ax=axes[i], palette=\"Set2\")\n",
    "        axes[i].set_title(f\"Feature: {feature}\", fontsize=12)\n",
    "        axes[i].set_ylabel(\"Valeur\")\n",
    "        axes[i].set_xlabel(group_col)\n",
    "\n",
    "    # Titre général pour la figure\n",
    "    plt.suptitle(f\"Label: {label} ({name})\", fontsize=16, y=1.02)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "features = [\n",
    "    \"price\", \"bid\", \"ask\", \"bid_size\", \"ask_size\", \"flux\",\n",
    "]\n",
    "plot_sample(df=X_train, features=features, label=\"Example Label\", group_col=\"eqt_code_cat\", name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     plot_sample(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, y_train[i])\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plot_sample(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasdeportzamparc/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def add_feature_engineering(df):\n",
    "    # Bid-ask ratio and imbalance\n",
    "    df['bid_ask_ratio'] = df['bid_size'] / (df['ask_size'] + 1e-6)\n",
    "    df['Imbalance'] = df['bid_size'] - df['ask_size']\n",
    "\n",
    "    # Price and spread features\n",
    "    df['price_change'] = df.groupby('obs_id')['price'].diff()\n",
    "    df['cumulative_price_change'] = df.groupby('obs_id')['price_change'].cumsum()\n",
    "    df['bid_ask_spread'] = df['ask'] - df['bid']\n",
    "    df['relative_spread'] = df['bid_ask_spread'] / (df['price'] + 1e-6)\n",
    "    df['price_zscore'] = (df['price'] - df['price'].mean()) / df['price'].std()\n",
    "\n",
    "    # Price position relative to bid and ask\n",
    "    df['price_bid_ratio'] = df['price'] / (df['bid'] + 1e-6)\n",
    "    df['price_ask_ratio'] = df['price'] / (df['ask'] + 1e-6)\n",
    "\n",
    "    # Log-transformed sizes\n",
    "    df['log_bid_size'] = np.log(df['bid_size'] + 1)\n",
    "    df['log_ask_size'] = np.log(df['ask_size'] + 1)\n",
    "    df['log_flux'] = np.log(np.abs(df['flux']) + 1) * np.sign(df['flux'])\n",
    "    df['log_flux_change'] = df.groupby('obs_id')['log_flux'].diff()\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "X_train = add_feature_engineering(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['obs_id', 'venue', 'order_id', 'action', 'side', 'price', 'bid', 'ask',\n",
       "       'bid_size', 'ask_size', 'trade', 'flux', 'bid_ask_ratio', 'Imbalance',\n",
       "       'price_change', 'cumulative_price_change', 'bid_ask_spread',\n",
       "       'relative_spread', 'price_zscore', 'price_bid_ratio', 'price_ask_ratio',\n",
       "       'log_bid_size', 'log_ask_size', 'log_flux', 'log_flux_change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['venue', 'action', 'trade', 'bid', 'ask', 'price', 'bid_ask_ratio', 'Imbalance',\n",
    "       'price_change','cumulative_price_change', 'bid_ask_spread','relative_spread', 'price_zscore', 'price_bid_ratio','price_ask_ratio','log_bid_size', 'log_ask_size', 'log_flux','log_flux_change']\n",
    "\n",
    "def group_by_observation(X_train, selected_columns, sequence_length=100):\n",
    "    grouped = X_train.groupby('obs_id')\n",
    "\n",
    "    # Préallocation d'un tableau pour stocker toutes les séquences\n",
    "    num_groups = len(grouped)\n",
    "    sequences = np.zeros((num_groups, sequence_length, len(selected_columns)))  # Shape: (num_groups, sequence_length, num_features)\n",
    "\n",
    "    for i, (_, group) in enumerate(grouped):\n",
    "        # Prendre les sequence_length premiers événements si plus\n",
    "        sequence = group[selected_columns].values[:sequence_length]\n",
    "\n",
    "        # Si moins de sequence_length événements, on applique du padding (remplissage avec des zéros)\n",
    "        if len(sequence) < sequence_length:\n",
    "            sequences[i, :len(sequence)] = sequence  # Remplir les lignes avec les données existantes\n",
    "            # Les lignes restantes sont déjà initialisées à zéro\n",
    "        else:\n",
    "            sequences[i] = sequence  # Remplacer par la séquence complète\n",
    "\n",
    "    return sequences\n",
    "\n",
    "\n",
    "\n",
    "# Utilisation de la fonction\n",
    "X_train = group_by_observation(X_train, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration is OK\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Définir un modèle avec LSTM, Attention et statistiques globales\n",
    "class MyLSTMModel(nn.Module):\n",
    "    def __init__(self, num_unique_venues, num_unique_actions, embedding_dim, lstm_units, num_classes):\n",
    "        super(MyLSTMModel, self).__init__()\n",
    "\n",
    "        # Embedding des catégories\n",
    "        self.venue_embedding = nn.Embedding(num_unique_venues, embedding_dim)\n",
    "        self.action_embedding = nn.Embedding(num_unique_actions, embedding_dim)\n",
    "        self.trade_embedding = nn.Embedding(2, embedding_dim)\n",
    "\n",
    "        # LSTM bidirectionnel avec plusieurs couches\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim * 3 + 16, hidden_size=lstm_units, num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=0.3)\n",
    "\n",
    "        # Mécanisme d'attention\n",
    "        self.attention = nn.Linear(lstm_units * 2, 1)\n",
    "\n",
    "        # Couches denses pour classification\n",
    "        self.fc1 = nn.Linear(lstm_units * 2, 64)  # Couche linéaire après LSTM\n",
    "        self.fc2 = nn.Linear(64, num_classes)  # Couche de sortie pour les classes\n",
    "\n",
    "    def attention_mechanism(self, lstm_output):\n",
    "        # Calculer les poids d'attention\n",
    "        attention_weights = torch.nn.functional.softmax(self.attention(lstm_output), dim=1)\n",
    "        # Appliquer les poids d'attention aux sorties LSTM\n",
    "        weighted_sum = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        return weighted_sum\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extraire les embeddings pour venue, action et trade\n",
    "        venue_emb = self.venue_embedding(x[:, :, 0].long())\n",
    "        action_emb = self.action_embedding(x[:, :, 1].long())\n",
    "        trade_emb = self.trade_embedding(x[:, :, 2].long())\n",
    "\n",
    "        # Extraire les caractéristiques continues (prix, volumes, etc.)\n",
    "        continuous_features = x[:, :, 3:]  # Assurez-vous que les dimensions correspondent\n",
    "        features = torch.cat((venue_emb, action_emb, trade_emb, continuous_features), dim=-1)\n",
    "\n",
    "        # Passer les données dans LSTM\n",
    "        lstm_out, _ = self.lstm(features)\n",
    "\n",
    "        # Appliquer le mécanisme d'attention\n",
    "        lstm_out_with_attention = self.attention_mechanism(lstm_out)\n",
    "\n",
    "        # Passer la sortie à travers les couches denses\n",
    "        output = self.fc1(lstm_out_with_attention)\n",
    "        output = torch.nn.functional.selu(output)  # Activation SeLU\n",
    "        output = self.fc2(output)  # Couches de sortie pour la classification\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# Paramètres du modèle\n",
    "embedding_dim = 8\n",
    "lstm_units = 64\n",
    "num_classes = 24\n",
    "\n",
    "# Initialiser le modèle\n",
    "model = MyLSTMModel(num_unique_venues=6, num_unique_actions=3, embedding_dim=embedding_dim,\n",
    "                    lstm_units=lstm_units, num_classes=num_classes)\n",
    "\n",
    "# Déplacer le modèle vers le GPU (si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Préparer les données\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "targets = torch.tensor(Y, dtype=torch.long).to(device)  # Utiliser long pour les labels en classification\n",
    "\n",
    "# Créer DataLoader pour le batching\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "# Configuration de l'optimiseur et de la fonction de perte\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Afficher la configuration du modèle\n",
    "print(\"Model configuration is OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_inputs, batch_targets \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Réinitialiser les gradients\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Passer les données dans le modèle\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Calculer la perte\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Rétropropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m, in \u001b[0;36mMyLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((venue_emb, action_emb, trade_emb, continuous_features), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Passer les données dans LSTM\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Appliquer le mécanisme d'attention\u001b[39;00m\n\u001b[1;32m     48\u001b[0m lstm_out_with_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_mechanism(lstm_out)\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoques = (10_000 * 1000) // num_observations\n",
    "for epoch in range(epoques):  # Exemple avec 10 époques\n",
    "    model.train()  # Mettre le modèle en mode entraînement\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()  # Réinitialiser les gradients\n",
    "        outputs = model(batch_inputs)  # Passer les données dans le modèle\n",
    "        loss = criterion(outputs, batch_targets.argmax(dim=1))  # Calculer la perte\n",
    "        loss.backward()  # Rétropropagation\n",
    "        optimizer.step()  # Mise à jour des poids\n",
    "    print(f'Epoch [{epoch+1}/{str(epoques)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = add_feature_engineering(X_test)\n",
    "X_test = group_by_observation(X_test, selected_columns)\n",
    "X_test_input = torch.tensor(X_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que `test_dataset` contienne vos données de test\n",
    "test_loader = DataLoader(X_test_input, batch_size=256, shuffle=False)\n",
    "\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_inputs in test_loader:  # Si vous avez besoin des cibles, sinon utilisez seulement batch_inputs\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "\n",
    "        # Faire la prédiction pour ce lot\n",
    "        outputs = model(batch_inputs)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        # Stocker les résultats\n",
    "        all_predictions.append(predicted_classes.cpu().numpy())\n",
    "        all_probabilities.append(probabilities.cpu().numpy())\n",
    "\n",
    "# Combiner tous les lots\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_probabilities = np.concatenate(all_probabilities)\n",
    "\n",
    "print(\"Prédictions pour tout le dataset :\", all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Generation \n",
    "df_prediction = pd.DataFrame(data = {'eqt_code_cat':all_predictions})\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('ypredic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class init done\n",
      "model configuration = OK \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Définir le modèle\n",
    "class MyGRUModel2(nn.Module):\n",
    "    def __init__(self, num_unique_venues, num_unique_actions, embedding_dim, gru_units, num_classes):\n",
    "        super(MyGRUModel2, self).__init__()\n",
    "        self.venue_embedding = nn.Embedding(num_unique_venues, embedding_dim)\n",
    "        self.action_embedding = nn.Embedding(num_unique_actions, embedding_dim)\n",
    "        self.gru = nn.GRU(input_size=embedding_dim * 2 + 7, hidden_size=gru_units, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(gru_units * 2, 64)  # 2 car c'est bidirectionnel\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        venue_emb = self.venue_embedding(x[:, :, 0].long())\n",
    "        action_emb = self.action_embedding(x[:, :, 1].long())\n",
    "        \n",
    "        # Concaténer les embeddings et les autres caractéristiques continues\n",
    "        continuous_features = x[:, :, 2:]  # Assurez-vous que les dimensions correspondent\n",
    "        features = torch.cat((venue_emb, action_emb, continuous_features), dim=-1)\n",
    "\n",
    "        # Passer les données dans GRU\n",
    "        gru_out, _ = self.gru(features)\n",
    "\n",
    "        # On peut prendre la sortie de la dernière étape ou faire une autre opération ici\n",
    "        output = self.fc1(gru_out[:, -1, :])\n",
    "        output = torch.nn.functional.selu(output)\n",
    "        output = self.fc2(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "print (\"class init done\")\n",
    "# Paramètres\n",
    "embedding_dim = 8\n",
    "gru_units = 64\n",
    "num_classes = 24\n",
    "\n",
    "# Instancier le modèle\n",
    "model = MyGRUModel2(num_unique_venues=6, num_unique_actions=3, embedding_dim=embedding_dim, \n",
    "                   gru_units=gru_units, num_classes=num_classes)\n",
    "\n",
    "# Déplacer le modèle vers le GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Préparer vos données\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "targets = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Créer DataLoader\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "# Configuration de l'optimiseur et de la fonction de perte\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"model configuration = OK \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "print (len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/thomasdeportzamparc/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages (1.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/62], Loss: 1.4806\n",
      "Epoch [2/62], Loss: 1.4487\n",
      "Epoch [3/62], Loss: 1.4453\n",
      "Epoch [4/62], Loss: 1.3432\n",
      "Epoch [5/62], Loss: 1.3676\n",
      "Epoch [6/62], Loss: 1.3422\n",
      "Epoch [7/62], Loss: 1.3667\n",
      "Epoch [8/62], Loss: 1.3044\n",
      "Epoch [9/62], Loss: 1.2901\n",
      "Epoch [10/62], Loss: 1.2835\n",
      "Epoch [11/62], Loss: 1.3083\n",
      "Epoch [12/62], Loss: 1.2440\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_inputs)  \u001b[38;5;66;03m# Passer les données dans le modèle\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Calculer la perte\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Rétropropagation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Mise à jour des poids\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(epoques)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoques = (10_000 * 1000) // num_observations\n",
    "for epoch in range(epoques):  # Exemple avec 10 époques\n",
    "    model.train()  # Mettre le modèle en mode entraînement\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        optimizer.zero_grad()  # Réinitialiser les gradients\n",
    "        outputs = model(batch_inputs)  # Passer les données dans le modèle\n",
    "        loss = criterion(outputs, batch_targets.argmax(dim=1))  # Calculer la perte\n",
    "        loss.backward()  # Rétropropagation\n",
    "        optimizer.step()  # Mise à jour des poids\n",
    "    print(f'Epoch [{epoch+1}/{str(epoques)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_bs = group_by_observation(X_test, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_input = torch.tensor(sequences_bs, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyGRUModel(\n",
       "  (venue_embedding): Embedding(6, 8)\n",
       "  (action_embedding): Embedding(3, 8)\n",
       "  (gru): GRU(23, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Faire une prédiction\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model(X_test_input)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Appliquer une fonction softmax pour obtenir les probabilités si le modèle n'a pas softmax dans sa dernière couche\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Faire une prédiction\n",
    "    predictions = model(X_test_input)\n",
    "\n",
    "# Appliquer une fonction softmax pour obtenir les probabilités si le modèle n'a pas softmax dans sa dernière couche\n",
    "probabilities = torch.nn.functional.softmax(predictions, dim=1)\n",
    "\n",
    "# Obtenir les classes avec la probabilité la plus élevée\n",
    "predicted_classes = probabilities.argmax(dim=1)\n",
    "\n",
    "# Déplacer les résultats sur le CPU si nécessaire\n",
    "predicted_classes = predicted_classes.cpu().numpy()\n",
    "\n",
    "print(predicted_classes)  # Affiche les prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyGRUModel' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(sequences_bs)\n\u001b[1;32m      2\u001b[0m y_predict_adjusted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_prediction \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meqt_code_cat\u001b[39m\u001b[38;5;124m'\u001b[39m:y_predict_adjusted})\n",
      "File \u001b[0;32m~/Desktop/Projects/1.Trading_bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyGRUModel' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(sequences_bs)\n",
    "y_predict_adjusted = np.argmax(predictions, axis=1)\n",
    "df_prediction = pd.DataFrame(data = {'eqt_code_cat':y_predict_adjusted})\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('ypredic.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
